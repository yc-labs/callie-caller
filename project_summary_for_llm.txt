================================================================================
PROJECT SUMMARY FOR LLM ANALYSIS
================================================================================

### Project File Structure ###

.
├── .dockerignore
├── .DS_Store
├── .env
├── .gitattributes
├── .github
│   └── workflows
│       └── ci-cd.yml
├── .gitignore
├── build.sh
├── call_log.txt
├── callie_caller
│   ├── __init__.py
│   ├── _version.py
│   ├── ai
│   │   ├── __init__.py
│   │   ├── client.py
│   │   ├── conversation_fixed.py
│   │   ├── conversation.py
│   │   ├── live_client_fixed.py
│   │   └── live_client.py
│   ├── config
│   │   ├── __init__.py
│   │   └── settings.py
│   ├── core
│   │   ├── __init__.py
│   │   ├── agent.py
│   │   ├── logging.py
│   │   └── web_agent.py
│   ├── handlers
│   ├── sip
│   │   ├── __init__.py
│   │   ├── audio_codec.py
│   │   ├── auth.py
│   │   ├── call.py
│   │   ├── client.py
│   │   ├── parser.py
│   │   ├── rtp_bridge.py
│   │   ├── rtp.py
│   │   └── sdp.py
│   └── utils
│       └── network.py
├── captured_audio
│   ├── caller_audio_1753207715.wav
│   ├── caller_audio_1753208158.wav
│   ├── caller_audio_1753208246.wav
│   ├── caller_audio_1753208430.wav
│   ├── caller_audio_1753208602.wav
│   ├── caller_audio_1753208751.wav
│   ├── caller_audio_1753208877.wav
│   ├── caller_audio_1753209019.wav
│   ├── caller_audio_1753209041.wav
│   ├── caller_audio_1753209178.wav
│   ├── caller_audio_1753209660.wav
│   ├── caller_audio_1753209762.wav
│   ├── caller_audio_1753209853.wav
│   ├── caller_audio_1753209952.wav
│   ├── caller_audio_1753210061.wav
│   ├── caller_audio_1753210178.wav
│   ├── caller_audio_1753210653.wav
│   ├── caller_audio_1753210800.wav
│   ├── caller_audio_1753210819.wav
│   ├── caller_audio_1753210881.wav
│   ├── caller_audio_1753210995.wav
│   ├── caller_audio_1753211129.wav
│   ├── caller_audio_1753211320.wav
│   ├── caller_audio_1753211507.wav
│   ├── caller_audio_1753211716.wav
│   ├── caller_audio_1753211756.wav
│   ├── caller_audio_1753211953.wav
│   ├── caller_audio_1753212010.wav
│   ├── caller_audio_1753212072.wav
│   ├── caller_audio_1753212332.wav
│   ├── caller_audio_1753212360.wav
│   ├── caller_audio_1753212395.wav
│   ├── caller_audio_1753212493.wav
│   ├── caller_audio_1753212630.wav
│   ├── caller_audio_1753212719.wav
│   ├── caller_audio_1753212759.wav
│   ├── caller_audio_1753212795.wav
│   ├── caller_audio_1753212867.wav
│   ├── caller_audio_1753212960.wav
│   ├── caller_audio_1753213010.wav
│   ├── caller_audio_1753213211.wav
│   ├── caller_audio_1753213417.wav
│   ├── caller_audio_1753213491.wav
│   ├── caller_audio_1753213596.wav
│   ├── caller_audio_1753213716.wav
│   ├── caller_audio_1753219004.wav
│   ├── caller_audio_1753219095.wav
│   ├── caller_audio_1753219330.wav
│   ├── caller_audio_1753219334.wav
│   ├── caller_audio_1753219370.wav
│   ├── caller_audio_1753219372.wav
│   ├── caller_audio_1753219458.wav
│   ├── caller_audio_1753219583.wav
│   ├── caller_audio_1753219843.wav
│   ├── caller_audio_1753219895.wav
│   ├── caller_audio_1753219971.wav
│   ├── caller_audio_1753220142.wav
│   ├── caller_audio_1753221121.wav
│   ├── caller_audio_1753221188.wav
│   ├── caller_audio_1753221551.wav
│   ├── caller_audio_1753221603.wav
│   ├── caller_audio_1753221909.wav
│   ├── caller_audio_1753222134.wav
│   ├── caller_audio_1753222417.wav
│   ├── caller_audio_1753222563.wav
│   ├── caller_audio_1753222660.wav
│   ├── remote_audio_1753207715.wav
│   ├── remote_audio_1753208158.wav
│   ├── remote_audio_1753208246.wav
│   ├── remote_audio_1753208430.wav
│   ├── remote_audio_1753208602.wav
│   ├── remote_audio_1753208751.wav
│   ├── remote_audio_1753208877.wav
│   ├── remote_audio_1753209019.wav
│   ├── remote_audio_1753209041.wav
│   ├── remote_audio_1753209178.wav
│   ├── remote_audio_1753209660.wav
│   ├── remote_audio_1753209762.wav
│   ├── remote_audio_1753209853.wav
│   ├── remote_audio_1753209952.wav
│   ├── remote_audio_1753210061.wav
│   ├── remote_audio_1753210178.wav
│   ├── remote_audio_1753210653.wav
│   ├── remote_audio_1753210800.wav
│   ├── remote_audio_1753210819.wav
│   ├── remote_audio_1753210881.wav
│   ├── remote_audio_1753210995.wav
│   ├── remote_audio_1753211129.wav
│   ├── remote_audio_1753211320.wav
│   ├── remote_audio_1753211507.wav
│   ├── remote_audio_1753211716.wav
│   ├── remote_audio_1753211756.wav
│   ├── remote_audio_1753211953.wav
│   ├── remote_audio_1753212010.wav
│   ├── remote_audio_1753212072.wav
│   ├── remote_audio_1753212332.wav
│   ├── remote_audio_1753212360.wav
│   ├── remote_audio_1753212395.wav
│   ├── remote_audio_1753212493.wav
│   ├── remote_audio_1753212630.wav
│   ├── remote_audio_1753212719.wav
│   ├── remote_audio_1753212759.wav
│   ├── remote_audio_1753212795.wav
│   ├── remote_audio_1753212867.wav
│   ├── remote_audio_1753212960.wav
│   ├── remote_audio_1753213010.wav
│   ├── remote_audio_1753213211.wav
│   ├── remote_audio_1753213417.wav
│   ├── remote_audio_1753213491.wav
│   ├── remote_audio_1753213596.wav
│   ├── remote_audio_1753213716.wav
│   ├── remote_audio_1753219004.wav
│   ├── remote_audio_1753219095.wav
│   ├── remote_audio_1753219330.wav
│   ├── remote_audio_1753219334.wav
│   ├── remote_audio_1753219370.wav
│   ├── remote_audio_1753219372.wav
│   ├── remote_audio_1753219458.wav
│   ├── remote_audio_1753219583.wav
│   ├── remote_audio_1753219843.wav
│   ├── remote_audio_1753219895.wav
│   ├── remote_audio_1753219971.wav
│   ├── remote_audio_1753220142.wav
│   ├── remote_audio_1753221121.wav
│   ├── remote_audio_1753221188.wav
│   ├── remote_audio_1753221551.wav
│   ├── remote_audio_1753221603.wav
│   ├── remote_audio_1753221909.wav
│   ├── remote_audio_1753222134.wav
│   ├── remote_audio_1753222417.wav
│   ├── remote_audio_1753222563.wav
│   └── remote_audio_1753222660.wav
├── cloudrun.yml
├── config.env.template
├── debug_audio.py
├── deploy-cloudrun-full.sh
├── deploy-cloudrun.sh
├── deploy.sh
├── docker-compose.debug.yml
├── docker-compose.prod.yml
├── docker-compose.yml
├── docker.env
├── Dockerfile
├── Dockerfile.cloudrun
├── Dockerfile.cloudrun-full
├── Dockerfile.cloudrun-full-fixed
├── docs
│   ├── Google Gen AI SDK documentation.pdf
│   └── Submodules - Google Gen AI SDK documentation.pdf
├── examples
├── main-cloudrun-full-debug.py
├── main-cloudrun-full-fixed.py
├── main-cloudrun-full.py
├── main-cloudrun.py
├── main.py
├── README.md
├── requirements.txt
├── scripts
│   ├── final_sip_call.py
│   ├── make_real_call.py
│   ├── real_sip_call.py
│   ├── sip_auth_call.py
│   ├── sip_call_sippy.py
│   ├── version.py
│   └── yealink_sip_call.py
├── start_debug.sh
├── summarize_project.py
├── test_audio_pipeline.py
├── test_final_call.py
├── test_fixed_audio.py
└── tests

15 directories, 199 files


================================================================================

### File Contents ###

----- FILE: Dockerfile -----

# Callie Caller - AI Voice Agent
# Production-ready Docker image

FROM python:3.13-slim

# Build arguments for version and metadata
ARG VERSION=1.0.0
ARG BUILD_DATE
ARG VCS_REF
ARG BUILD_NUMBER

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    DEBIAN_FRONTEND=noninteractive

# Labels for image metadata
LABEL maintainer="Troy Fortin" \
      version="${VERSION}" \
      description="AI Voice Agent with SIP calling capabilities" \
      org.opencontainers.image.title="Callie Caller" \
      org.opencontainers.image.description="Production-ready AI voice assistant with SIP integration" \
      org.opencontainers.image.version="${VERSION}" \
      org.opencontainers.image.created="${BUILD_DATE}" \
      org.opencontainers.image.revision="${VCS_REF}" \
      org.opencontainers.image.source="https://github.com/troyfortin/callie-caller" \
      org.opencontainers.image.licenses="MIT"

# Install system dependencies
RUN apt-get update && apt-get install -y \
    # Audio processing dependencies
    libasound2-dev \
    portaudio19-dev \
    # Network utilities
    miniupnpc \
    # Build tools (removed after pip install)
    gcc \
    g++ \
    make \
    pkg-config \
    # Cleanup in same layer
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Create non-root user for security
RUN groupadd -r callie && useradd -r -g callie -d /app callie

# Set work directory
WORKDIR /app

# Copy requirements first for better Docker layer caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt \
    # Remove build dependencies to reduce image size
    && apt-get purge -y gcc g++ make pkg-config \
    && apt-get autoremove -y

# Copy application code
COPY callie_caller/ ./callie_caller/
COPY main.py .
COPY config.env.template .

# Set version in the container
RUN sed -i "s/__version__ = \".*\"/__version__ = \"${VERSION}\"/" callie_caller/_version.py \
    && sed -i "s/__build__ = \".*\"/__build__ = \"docker\"/" callie_caller/_version.py \
    && sed -i "s/__commit__ = \".*\"/__commit__ = \"${VCS_REF}\"/" callie_caller/_version.py

# Create directories for logs and audio
RUN mkdir -p /app/logs /app/captured_audio \
    && chown -R callie:callie /app

# Switch to non-root user
USER callie

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8080/health')" || exit 1

# Expose port
EXPOSE 8080

# Default command
CMD ["python", "main.py"]

# Alternative entry points as examples:
# CMD ["python", "main.py", "--debug"]                    # Debug mode
# CMD ["python", "main.py", "--call", "+1234567890"]     # Test call
# CMD ["python", "main.py", "--config-check"]            # Config validation 

================================================================================

----- FILE: Dockerfile.cloudrun -----

# Callie Caller - Cloud Run Optimized Docker Image

FROM python:3.11-slim

# Build arguments for version and metadata
ARG VERSION=1.0.0
ARG BUILD_DATE
ARG VCS_REF
ARG BUILD_NUMBER

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    DEBIAN_FRONTEND=noninteractive \
    CLOUD_RUN_MODE=true

# Labels for image metadata
LABEL maintainer="Troy Fortin" \
      version="${VERSION}" \
      description="AI Voice Agent optimized for Cloud Run" \
      org.opencontainers.image.title="Callie Caller Cloud Run" \
      org.opencontainers.image.description="Cloud Run optimized AI voice assistant" \
      org.opencontainers.image.version="${VERSION}" \
      org.opencontainers.image.created="${BUILD_DATE}" \
      org.opencontainers.image.revision="${VCS_REF}"

# Install system dependencies (minimal set for Cloud Run)
RUN apt-get update && apt-get install -y \
    # Basic networking and utilities
    curl \
    # Audio processing dependencies (for local development)
    libasound2-dev \
    portaudio19-dev \
    # Build tools (removed after pip install)
    gcc \
    g++ \
    make \
    pkg-config \
    # Cleanup in same layer
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Create non-root user for security
RUN groupadd -r callie && useradd -r -g callie -d /app callie

# Set work directory
WORKDIR /app

# Copy requirements first for better Docker layer caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt \
    # Remove build dependencies to reduce image size
    && apt-get purge -y gcc g++ make pkg-config 2>/dev/null || true \
    && apt-get autoremove -y 2>/dev/null || true

# Copy application code
COPY callie_caller/ ./callie_caller/
COPY main-cloudrun.py .
COPY config.env.template .

# Set version in the container
RUN sed -i "s/__version__ = \".*\"/__version__ = \"${VERSION}\"/" callie_caller/_version.py \
    && sed -i "s/__build__ = \".*\"/__build__ = \"cloudrun\"/" callie_caller/_version.py \
    && sed -i "s/__commit__ = \".*\"/__commit__ = \"${VCS_REF}\"/" callie_caller/_version.py

# Create directories for logs and audio
RUN mkdir -p /app/logs /app/captured_audio \
    && chown -R callie:callie /app

# Switch to non-root user
USER callie

# Health check for Cloud Run
HEALTHCHECK --interval=30s --timeout=10s --start-period=15s --retries=3 \
    CMD curl -f http://localhost:$PORT/health || exit 1

# Expose port (Cloud Run will set PORT environment variable)
EXPOSE 8080

# Cloud Run optimized command
CMD ["python", "main-cloudrun.py"] 

================================================================================

----- FILE: Dockerfile.cloudrun-full -----

# Callie Caller - Cloud Run Full SIP Docker Image

FROM python:3.13-slim

# Build arguments for version and metadata
ARG VERSION=1.0.0
ARG BUILD_DATE
ARG VCS_REF
ARG BUILD_NUMBER

# Set environment variables for Cloud Run
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    DEBIAN_FRONTEND=noninteractive \
    USE_UPNP=false \
    CONTAINER_MODE=true \
    CLOUD_RUN_MODE=true

# Labels for image metadata
LABEL maintainer="Troy Fortin" \
      version="${VERSION}" \
      description="AI Voice Agent with full SIP capabilities for Cloud Run" \
      org.opencontainers.image.title="Callie Caller Cloud Run Full" \
      org.opencontainers.image.description="Cloud Run AI voice assistant with SIP calling" \
      org.opencontainers.image.version="${VERSION}" \
      org.opencontainers.image.created="${BUILD_DATE}" \
      org.opencontainers.image.revision="${VCS_REF}"

# Install system dependencies
RUN apt-get update && apt-get install -y \
    # Basic networking and utilities
    curl \
    netcat-traditional \
    # Audio processing dependencies
    libasound2-dev \
    portaudio19-dev \
    # UPnP tools (even though disabled, dependencies might need it)
    miniupnpc \
    # Build tools (removed after pip install)
    gcc \
    g++ \
    make \
    pkg-config \
    # Cleanup in same layer
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Create non-root user for security
RUN groupadd -r callie && useradd -r -g callie -d /app callie

# Set work directory
WORKDIR /app

# Copy requirements first for better Docker layer caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt \
    # Remove build dependencies to reduce image size
    && apt-get purge -y gcc g++ make pkg-config 2>/dev/null || true \
    && apt-get autoremove -y 2>/dev/null || true

# Copy application code
COPY callie_caller/ ./callie_caller/
COPY main-cloudrun-full.py .
COPY config.env.template .

# Set version in the container
RUN sed -i "s/__version__ = \".*\"/__version__ = \"${VERSION}\"/" callie_caller/_version.py \
    && sed -i "s/__build__ = \".*\"/__build__ = \"cloudrun-full\"/" callie_caller/_version.py \
    && sed -i "s/__commit__ = \".*\"/__commit__ = \"${VCS_REF}\"/" callie_caller/_version.py

# Create directories for logs and audio
RUN mkdir -p /app/logs /app/captured_audio \
    && chown -R callie:callie /app

# Switch to non-root user
USER callie

# Health check for Cloud Run
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:${PORT:-8080}/health || exit 1

# Expose port (Cloud Run will set PORT environment variable)
EXPOSE 8080

# Cloud Run optimized command with full SIP support
CMD ["python", "main-cloudrun-full.py"] 

================================================================================

----- FILE: callie_caller/__init__.py -----

"""
Callie Caller - AI Voice Agent
Production-ready AI voice assistant with SIP calling capabilities.

This package provides a complete solution for creating AI-powered phone conversations
using Google's Gemini Live API and SIP protocol integration.
"""

from callie_caller._version import __version__, get_version, get_version_info

__author__ = "Troy Fortin"
__description__ = "AI Voice Agent with SIP integration and real-time conversation capabilities"
__license__ = "MIT"

from callie_caller.core.agent import CallieAgent
from callie_caller.sip.client import SipClient
from callie_caller.ai.conversation import ConversationManager
from callie_caller.ai.conversation_fixed import AudioBridge

__all__ = [
    'CallieAgent', 
    'SipClient', 
    'ConversationManager', 
    'AudioBridge',
    '__version__',
    'get_version',
    'get_version_info'
] 

================================================================================

----- FILE: callie_caller/_version.py -----

"""
Version management for Callie Caller.
This file is the single source of truth for version information.
"""

__version__ = "1.0.0"

# Robust version parsing that handles non-standard version strings
def _parse_version(version_str):
    """Parse version string robustly, handling build suffixes."""
    try:
        # Split by '.' and take only numeric parts
        parts = version_str.split('.')
        numeric_parts = []
        for part in parts:
            # Extract only the numeric portion
            numeric_part = ""
            for char in part:
                if char.isdigit():
                    numeric_part += char
                else:
                    break
            if numeric_part:
                numeric_parts.append(int(numeric_part))
            else:
                break
        
        # Ensure we have at least 3 parts (major, minor, patch)
        while len(numeric_parts) < 3:
            numeric_parts.append(0)
            
        return tuple(numeric_parts[:3])  # Only take first 3 parts
    except (ValueError, AttributeError):
        # Fallback for any parsing errors
        return (1, 0, 0)

__version_info__ = _parse_version(__version__)

# Build metadata
__build__ = "production"
__commit__ = "unknown"

# Version components
MAJOR, MINOR, PATCH = __version_info__

def get_version(include_build=False):
    """Get the current version string."""
    version = __version__
    if include_build and __build__ != "production":
        version += f"-{__build__}"
    return version

def get_version_info():
    """Get detailed version information."""
    return {
        "version": __version__,
        "version_info": __version_info__,
        "major": MAJOR,
        "minor": MINOR,
        "patch": PATCH,
        "build": __build__,
        "commit": __commit__
    }

def bump_version(component="patch"):
    """
    Bump version component. Used by build scripts.
    
    Args:
        component: 'major', 'minor', or 'patch'
    """
    global __version__, __version_info__, MAJOR, MINOR, PATCH
    
    if component == "major":
        MAJOR += 1
        MINOR = 0
        PATCH = 0
    elif component == "minor":
        MINOR += 1
        PATCH = 0
    elif component == "patch":
        PATCH += 1
    else:
        raise ValueError(f"Invalid component: {component}")
    
    __version_info__ = (MAJOR, MINOR, PATCH)
    __version__ = f"{MAJOR}.{MINOR}.{PATCH}"
    
    return __version__ 

================================================================================

----- FILE: callie_caller/ai/__init__.py -----

"""
AI module for conversation generation and real-time audio.
"""

from .client import GeminiClient
from .conversation import ConversationManager
from .conversation_fixed import AudioBridge

__all__ = ['GeminiClient', 'ConversationManager', 'AudioBridge'] 

================================================================================

----- FILE: callie_caller/ai/client.py -----

"""
Google Gemini AI client for conversation generation.
Handles AI model communication and response generation.
"""

import logging
from typing import Optional, List, Dict, Any
from google import genai
from google.genai import types

from callie_caller.config import get_settings

logger = logging.getLogger(__name__)

class GeminiClient:
    """Client for Google Gemini AI model."""
    
    def __init__(self):
        """Initialize Gemini client with settings."""
        self.settings = get_settings()
        self.client = genai.Client(api_key=self.settings.ai.api_key)
        self._test_connection()
        
    def _test_connection(self) -> None:
        """Test connection to Gemini API."""
        try:
            response = self.client.models.generate_content(
                model=self.settings.ai.model,
                contents="Hello, this is a connection test. Please respond with 'OK'."
            )
            logger.info("Gemini AI connection tested successfully")
        except Exception as e:
            logger.error(f"Gemini AI connection test failed: {e}")
            raise RuntimeError(f"Failed to connect to Gemini AI: {e}")
    
    def generate_greeting(self, context: Optional[str] = None) -> str:
        """
        Generate a greeting message for calls.
        
        Args:
            context: Optional context about the call
            
        Returns:
            Generated greeting message
        """
        prompt = "Generate a brief, professional greeting for an AI voice assistant answering a phone call."
        
        if context:
            prompt += f" Context: {context}"
            
        prompt += " Keep it under 20 words and sound natural."
        
        try:
            response = self.client.models.generate_content(
                model=self.settings.ai.model,
                contents=prompt
            )
            
            greeting = response.text.strip()
            logger.debug(f"Generated greeting: {greeting}")
            return greeting
            
        except Exception as e:
            logger.error(f"Failed to generate greeting: {e}")
            return self.settings.calls.default_greeting
    
    def generate_response(self, message: str, conversation_history: Optional[List[Dict[str, str]]] = None) -> str:
        """
        Generate a response to a user message.
        
        Args:
            message: User's message to respond to
            conversation_history: Previous conversation messages
            
        Returns:
            Generated response
        """
        # Build conversation context
        context_messages = []
        
        if conversation_history:
            for entry in conversation_history[-5:]:  # Last 5 messages for context
                role = entry.get('role', 'user')
                content = entry.get('content', '')
                if role == 'user':
                    context_messages.append(f"User: {content}")
                elif role == 'assistant':
                    context_messages.append(f"Assistant: {content}")
        
        # Create prompt
        prompt = """You are a helpful AI voice assistant. Respond to the user's message in a natural, conversational way.
Keep your response concise (under 50 words) since this is a voice conversation.
Be friendly, professional, and helpful.

"""
        
        if context_messages:
            prompt += "Conversation history:\n" + "\n".join(context_messages) + "\n\n"
            
        prompt += f"User: {message}\n\nAssistant:"
        
        try:
            response = self.client.models.generate_content(
                model=self.settings.ai.model,
                contents=prompt
            )
            
            ai_response = response.text.strip()
            logger.debug(f"Generated response: {ai_response[:100]}...")
            return ai_response
            
        except Exception as e:
            logger.error(f"Failed to generate response: {e}")
            return "I'm sorry, I'm having trouble understanding right now. Could you please repeat that?"
    
    def generate_call_summary(self, conversation_history: List[Dict[str, str]]) -> str:
        """
        Generate a summary of the call conversation.
        
        Args:
            conversation_history: Complete conversation history
            
        Returns:
            Call summary
        """
        if not conversation_history:
            return "No conversation took place."
            
        # Build conversation text
        conversation_text = []
        for entry in conversation_history:
            role = entry.get('role', 'user')
            content = entry.get('content', '')
            if role == 'user':
                conversation_text.append(f"Caller: {content}")
            elif role == 'assistant':
                conversation_text.append(f"AI: {content}")
        
        prompt = f"""Summarize this phone conversation in 1-2 sentences:

{chr(10).join(conversation_text)}

Summary:"""
        
        try:
            response = self.client.models.generate_content(
                model=self.settings.ai.model,
                contents=prompt
            )
            
            summary = response.text.strip()
            logger.info(f"Generated call summary: {summary}")
            return summary
            
        except Exception as e:
            logger.error(f"Failed to generate summary: {e}")
            return "Call conversation summary unavailable."
    
    def analyze_sentiment(self, message: str) -> str:
        """
        Analyze sentiment of a message.
        
        Args:
            message: Message to analyze
            
        Returns:
            Sentiment (positive, negative, neutral)
        """
        prompt = f"""Analyze the sentiment of this message and respond with only one word: "positive", "negative", or "neutral".

Message: {message}

Sentiment:"""
        
        try:
            response = self.client.models.generate_content(
                model=self.settings.ai.model,
                contents=prompt
            )
            
            sentiment = response.text.strip().lower()
            if sentiment in ['positive', 'negative', 'neutral']:
                return sentiment
            else:
                return 'neutral'
                
        except Exception as e:
            logger.error(f"Failed to analyze sentiment: {e}")
            return 'neutral' 

async def test_gemini_connection() -> bool:
    """
    Test connection to Gemini API.
    
    Returns:
        True if connection successful, False otherwise
    """
    try:
        settings = get_settings()
        client = genai.Client(api_key=settings.ai.api_key)
        
        response = client.models.generate_content(
            model=settings.ai.model,
            contents="Hello, this is a connection test. Please respond with 'OK'."
        )
        
        if response and response.text:
            logger.info("Gemini AI connection test successful")
            return True
        else:
            logger.error("Gemini AI connection test failed - no response")
            return False
            
    except Exception as e:
        logger.error(f"Gemini AI connection test failed: {e}")
        return False 

================================================================================

----- FILE: callie_caller/ai/conversation.py -----

"""
Conversation Manager for AI chat capabilities.
Handles conversation state, history, and intelligent response generation.
"""

import time
import logging
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, field
from enum import Enum

from callie_caller.ai.client import GeminiClient

logger = logging.getLogger(__name__)

class ConversationState(Enum):
    """Conversation states."""
    IDLE = "idle"
    ACTIVE = "active"
    WAITING = "waiting"
    ENDED = "ended"

@dataclass
class ConversationMessage:
    """Individual conversation message."""
    role: str  # 'user' or 'assistant'
    content: str
    timestamp: float = field(default_factory=time.time)
    sentiment: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class Conversation:
    """Complete conversation context."""
    conversation_id: str
    phone_number: Optional[str] = None
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None
    state: ConversationState = ConversationState.IDLE
    messages: List[ConversationMessage] = field(default_factory=list)
    summary: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def duration(self) -> float:
        """Get conversation duration in seconds."""
        end = self.end_time or time.time()
        return end - self.start_time
        
    @property
    def message_count(self) -> int:
        """Get total message count."""
        return len(self.messages)
        
    @property
    def user_message_count(self) -> int:
        """Get user message count."""
        return len([m for m in self.messages if m.role == 'user'])
        
    @property
    def assistant_message_count(self) -> int:
        """Get assistant message count."""
        return len([m for m in self.messages if m.role == 'assistant'])

class ConversationManager:
    """Manages AI conversations and chat state."""
    
    def __init__(self):
        """Initialize conversation manager."""
        self.ai_client = GeminiClient()
        self.active_conversations: Dict[str, Conversation] = {}
        self.conversation_history: List[Conversation] = []
        
    def start_conversation(self, conversation_id: str, phone_number: Optional[str] = None) -> Conversation:
        """
        Start a new conversation.
        
        Args:
            conversation_id: Unique conversation identifier
            phone_number: Optional phone number for context
            
        Returns:
            New conversation object
        """
        conversation = Conversation(
            conversation_id=conversation_id,
            phone_number=phone_number,
            state=ConversationState.ACTIVE
        )
        
        self.active_conversations[conversation_id] = conversation
        logger.info(f"Started conversation {conversation_id} with {phone_number or 'unknown number'}")
        
        return conversation
        
    def end_conversation(self, conversation_id: str) -> Optional[Conversation]:
        """
        End an active conversation.
        
        Args:
            conversation_id: Conversation to end
            
        Returns:
            Ended conversation or None if not found
        """
        conversation = self.active_conversations.get(conversation_id)
        if not conversation:
            logger.warning(f"Attempted to end non-existent conversation {conversation_id}")
            return None
            
        conversation.state = ConversationState.ENDED
        conversation.end_time = time.time()
        
        # Generate conversation summary
        if conversation.messages:
            try:
                conversation.summary = self.ai_client.generate_call_summary(
                    [{'role': m.role, 'content': m.content} for m in conversation.messages]
                )
            except Exception as e:
                logger.error(f"Failed to generate conversation summary: {e}")
                conversation.summary = f"Conversation with {conversation.message_count} messages"
        
        # Move to history
        self.conversation_history.append(conversation)
        del self.active_conversations[conversation_id]
        
        logger.info(f"Ended conversation {conversation_id} after {conversation.duration:.1f}s with {conversation.message_count} messages")
        return conversation
        
    def add_user_message(self, conversation_id: str, message: str, metadata: Optional[Dict[str, Any]] = None) -> bool:
        """
        Add a user message to the conversation.
        
        Args:
            conversation_id: Target conversation
            message: User's message content
            metadata: Optional message metadata
            
        Returns:
            True if message added successfully
        """
        conversation = self.active_conversations.get(conversation_id)
        if not conversation:
            logger.error(f"Cannot add message to non-existent conversation {conversation_id}")
            return False
            
        # Analyze sentiment
        sentiment = None
        try:
            sentiment = self.ai_client.analyze_sentiment(message)
        except Exception as e:
            logger.warning(f"Failed to analyze sentiment: {e}")
            
        # Create message
        conv_message = ConversationMessage(
            role='user',
            content=message,
            sentiment=sentiment,
            metadata=metadata or {}
        )
        
        conversation.messages.append(conv_message)
        logger.debug(f"Added user message to {conversation_id}: {message[:50]}...")
        
        return True
        
    def generate_response(self, conversation_id: str, context: Optional[str] = None) -> Optional[str]:
        """
        Generate AI response for the conversation.
        
        Args:
            conversation_id: Target conversation
            context: Optional additional context
            
        Returns:
            Generated response or None if failed
        """
        conversation = self.active_conversations.get(conversation_id)
        if not conversation:
            logger.error(f"Cannot generate response for non-existent conversation {conversation_id}")
            return None
            
        if not conversation.messages:
            logger.warning(f"No messages in conversation {conversation_id}")
            return None
            
        # Get last user message
        user_messages = [m for m in conversation.messages if m.role == 'user']
        if not user_messages:
            logger.warning(f"No user messages in conversation {conversation_id}")
            return None
            
        last_message = user_messages[-1].content
        
        # Build conversation history for context
        history = [
            {'role': m.role, 'content': m.content} 
            for m in conversation.messages[-10:]  # Last 10 messages
        ]
        
        try:
            # Generate response
            response = self.ai_client.generate_response(last_message, history)
            
            # Add response to conversation
            conv_response = ConversationMessage(
                role='assistant',
                content=response,
                metadata={'context': context} if context else {}
            )
            
            conversation.messages.append(conv_response)
            logger.debug(f"Generated response for {conversation_id}: {response[:50]}...")
            
            return response
            
        except Exception as e:
            logger.error(f"Failed to generate response for {conversation_id}: {e}")
            return None
            
    def generate_greeting(self, conversation_id: str, context: Optional[str] = None) -> Optional[str]:
        """
        Generate a greeting for the conversation.
        
        Args:
            conversation_id: Target conversation
            context: Optional context about the call
            
        Returns:
            Generated greeting or None if failed
        """
        conversation = self.active_conversations.get(conversation_id)
        if not conversation:
            logger.error(f"Cannot generate greeting for non-existent conversation {conversation_id}")
            return None
            
        try:
            # Add phone number context if available
            full_context = context or ""
            if conversation.phone_number:
                full_context += f" Caller: {conversation.phone_number}"
                
            greeting = self.ai_client.generate_greeting(full_context)
            
            # Add greeting as assistant message
            conv_greeting = ConversationMessage(
                role='assistant',
                content=greeting,
                metadata={'type': 'greeting', 'context': context}
            )
            
            conversation.messages.append(conv_greeting)
            logger.debug(f"Generated greeting for {conversation_id}: {greeting}")
            
            return greeting
            
        except Exception as e:
            logger.error(f"Failed to generate greeting for {conversation_id}: {e}")
            return None
            
    def get_conversation(self, conversation_id: str) -> Optional[Conversation]:
        """Get active conversation by ID."""
        return self.active_conversations.get(conversation_id)
        
    def get_conversation_history(self, phone_number: Optional[str] = None, limit: int = 10) -> List[Conversation]:
        """
        Get conversation history.
        
        Args:
            phone_number: Optional filter by phone number
            limit: Maximum number of conversations to return
            
        Returns:
            List of historical conversations
        """
        conversations = self.conversation_history
        
        if phone_number:
            conversations = [c for c in conversations if c.phone_number == phone_number]
            
        # Sort by start time (most recent first)
        conversations.sort(key=lambda c: c.start_time, reverse=True)
        
        return conversations[:limit]
        
    def get_conversation_stats(self) -> Dict[str, Any]:
        """Get conversation statistics."""
        total_conversations = len(self.conversation_history) + len(self.active_conversations)
        total_messages = sum(c.message_count for c in self.conversation_history)
        total_messages += sum(c.message_count for c in self.active_conversations.values())
        
        avg_duration = 0
        if self.conversation_history:
            avg_duration = sum(c.duration for c in self.conversation_history) / len(self.conversation_history)
            
        return {
            'total_conversations': total_conversations,
            'active_conversations': len(self.active_conversations),
            'completed_conversations': len(self.conversation_history),
            'total_messages': total_messages,
            'average_duration': avg_duration
        }
        
    def cleanup_old_conversations(self, max_age_hours: int = 24) -> int:
        """
        Clean up old conversations from history.
        
        Args:
            max_age_hours: Maximum age of conversations to keep
            
        Returns:
            Number of conversations removed
        """
        cutoff_time = time.time() - (max_age_hours * 3600)
        old_conversations = [c for c in self.conversation_history if c.start_time < cutoff_time]
        
        for conversation in old_conversations:
            self.conversation_history.remove(conversation)
            
        logger.info(f"Cleaned up {len(old_conversations)} old conversations")
        return len(old_conversations) 

================================================================================

----- FILE: callie_caller/ai/live_client.py -----

"""
Google Gemini Live API client for real-time audio conversation.
Handles bidirectional audio streaming during SIP calls.
"""

import asyncio
import logging
import pyaudio
from typing import Optional, Callable, Any
from google import genai
from google.genai import types

from callie_caller.config import get_settings

logger = logging.getLogger(__name__)

# Audio configuration
FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

class AudioBridge:
    """Bridges SIP audio with Gemini Live API for real-time conversation."""
    
    def __init__(self):
        """Initialize audio bridge."""
        self.settings = get_settings()
        self.client = genai.Client(
            http_options={"api_version": "v1beta"},
            api_key=self.settings.ai.api_key,
        )
        
        # Audio queues
        self.audio_in_queue: Optional[asyncio.Queue] = None
        self.audio_out_queue: Optional[asyncio.Queue] = None
        self.sip_audio_queue: Optional[asyncio.Queue] = None
        
        # Session and tasks
        self.session: Optional[Any] = None
        self.tasks: list = []
        self.running = False
        
        # PyAudio
        self.pya = pyaudio.PyAudio()
        self.audio_stream: Optional[Any] = None
        
        # SIP audio callback
        self.sip_audio_callback: Optional[Callable] = None
        
        # VAD (Voice Activity Detection) to manage conversation turns
        self._loop: Optional[asyncio.AbstractEventLoop] = None
        self._silence_timer: Optional[asyncio.TimerHandle] = None
        self.silence_threshold_seconds: float = 1.0  # End turn after 1s of silence
        self.user_is_speaking: bool = False
        
        logger.info("AudioBridge initialized with VAD")
    
    @property
    def live_config(self) -> types.LiveSession.Config:
        """Return the live session config."""
        return types.LiveSession.Config(
            audio_input_format=types.AudioFormat(
                encoding="linear16",
                sample_rate_hertz=24000,
                channels=1
            ),
            audio_output_format=types.AudioFormat(
                encoding="linear16",
                sample_rate_hertz=24000,
                channels=1
            ),
        )
    
    def set_sip_audio_callback(self, callback) -> None:
        """Set callback function to send AI audio to SIP call."""
        self.sip_audio_callback = callback
        logger.info("SIP audio callback configured")
    
    async def start_conversation(self, initial_message: Optional[str] = None) -> None:
        """Start real-time conversation with AI."""
        if self.running:
            logger.warning("Conversation already running")
            return
            
        try:
            self.running = True
            logger.info("🚀 Starting Live API conversation...")
            logger.info(f"🔑 Using model: models/gemini-2.5-flash-live-preview")
            
            async with (
                self.client.aio.live.connect(
                    model="models/gemini-2.5-flash-live-preview",
                    config=self.live_config
                ) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                logger.info("✅ Connected to Gemini Live API successfully!")
                
                # Initialize queues
                self.audio_in_queue = asyncio.Queue()
                self.audio_out_queue = asyncio.Queue(maxsize=20)  # Increased buffer size
                self.sip_audio_queue = asyncio.Queue()
                
                # Send initial greeting if provided
                if initial_message:
                    logger.info(f"📤 Sending initial greeting to AI: {initial_message}")
                    await session.send(input=initial_message, end_of_turn=True)
                else:
                    # Send a test message to prime the AI
                    logger.info(f"📤 Sending conversation starter to AI...")
                    await session.send(input="Hello! I'm ready to have a live voice conversation with you. Please greet me warmly and ask how you can help me today. Speak naturally and feel free to elaborate in your responses.", end_of_turn=True)
                
                # Create background tasks
                self.tasks = [
                    tg.create_task(self._process_ai_messages()),
                    tg.create_task(self._send_audio_to_ai()),
                    tg.create_task(self._play_ai_audio()),
                ]
                
                logger.info("🎵 Live conversation started - AI is now listening...")
                logger.info("🔊 Audio processing tasks running:")
                logger.info("   📥 Receiving audio from AI")
                logger.info("   📤 Sending audio to AI") 
                logger.info("   🔈 Playing AI audio")
                
                # Wait until conversation is stopped
                while self.running:
                    await asyncio.sleep(0.1)
                    
        except asyncio.CancelledError:
            logger.info("🛑 Live conversation cancelled")
        except Exception as e:
            logger.error(f"💥 Live conversation error: {e}")
            import traceback
            logger.error(traceback.format_exc())
        finally:
            self.running = False
            logger.info("🔚 Live conversation ended")
    
    async def stop_conversation(self) -> None:
        """Stop the live conversation."""
        logger.info("Stopping live conversation...")
        self.running = False
        
        # Cancel all tasks
        for task in self.tasks:
            if not task.done():
                task.cancel()
        
        # Clear queues
        if self.audio_in_queue:
            while not self.audio_in_queue.empty():
                try:
                    self.audio_in_queue.get_nowait()
                except asyncio.QueueEmpty:
                    break
        
        logger.info("Live conversation stopped")
    
    def _signal_end_of_turn(self) -> None:
        """Signal end of user's speaking turn to the AI."""
        if not self.user_is_speaking:
            return

        logger.info("🤫 SILENCE DETECTED - Signaling end of user's turn")
        self.user_is_speaking = False
        if self._silence_timer:
            self._silence_timer.cancel()
            self._silence_timer = None
        
        # Send an explicit end-of-turn signal to Gemini
        if self.session and self._loop and self._loop.is_running():
            asyncio.run_coroutine_threadsafe(
                self.session.send(end_of_turn=True),
                self._loop
            )
            logger.info("✅ End-of-turn signal sent to AI")
    
    async def send_sip_audio(self, audio_data: bytes) -> None:
        """Send audio data from SIP call to AI, with VAD."""
        if not self.running or not self.audio_out_queue:
            return
            
        try:
            # Simple VAD: Check if audio has energy
            import struct
            samples = struct.unpack(f'<{len(audio_data)//2}h', audio_data)
            max_amplitude = max(abs(s) for s in samples) if samples else 0
            is_speech = max_amplitude > 250  # VAD threshold

            if is_speech:
                if not self.user_is_speaking:
                    logger.info("🗣️ VOICE DETECTED - User is speaking")
                    self.user_is_speaking = True
                
                # Reset silence timer on each new speech chunk
                if self._silence_timer:
                    self._silence_timer.cancel()
                
                if self._loop:
                    self._silence_timer = self._loop.call_later(
                        self.silence_threshold_seconds, self._signal_end_of_turn
                    )

                # Send speech audio to AI
                try:
                    self.audio_out_queue.put_nowait({
                        "data": audio_data,
                        "mime_type": "audio/pcm;rate=24000"
                    })
                except asyncio.QueueFull:
                    logger.warning("Audio out queue full, dropping oldest audio")
            
            elif self.user_is_speaking:
                # User was speaking, but this chunk is silence
                logger.debug("🎤 Silence received while user was speaking")
                
        except Exception as e:
            logger.error(f"Error processing SIP audio with VAD: {e}")

    def send_sip_audio_sync(self, audio_data: bytes) -> None:
        """Synchronous wrapper for sending audio from RTP thread."""
        if self._loop and self._loop.is_running():
            asyncio.run_coroutine_threadsafe(
                self.send_sip_audio(audio_data), 
                self._loop
            )
        else:
            logger.warning("⚠️ No event loop available for audio forwarding")

    async def _process_ai_messages(self) -> None:
        """Background task to process AI messages - follows Google sample pattern."""
        logger.info("AI message processing started with continuous session loop")
        audio_received_count = 0
        
        try:
            # CRITICAL: Continuous loop like Google sample to keep session alive
            while self.running:
                try:
                    # Get a turn from the session
                    turn = self.session.receive()
                    
                    # Process all responses in this turn
                    async for response in turn:
                        if not self.running:
                            logger.info("🛑 Stopping AI message processing (running=False)")
                            break
                        
                        # Handle audio data
                        if hasattr(response, 'data') and response.data:
                            # AI is speaking, so user's turn is over.
                            # Cancel any pending silence timer to prevent a race condition.
                            if self.user_is_speaking:
                                logger.debug("🤖 AI started speaking, cancelling user silence timer.")
                                if self._silence_timer:
                                    self._silence_timer.cancel()
                                    self._silence_timer = None
                                self.user_is_speaking = False

                            audio_received_count += 1
                            logger.info(f"🔊 Received AI audio #{audio_received_count}: {len(response.data)} bytes")
                            
                            # Put audio in queue immediately
                            try:
                                self.audio_in_queue.put_nowait(response.data)
                            except asyncio.QueueFull:
                                logger.warning("⚠️ Audio input queue full, dropping old audio")
                                try:
                                    self.audio_in_queue.get_nowait()  # Remove oldest
                                    self.audio_in_queue.put_nowait(response.data)  # Add newest
                                except asyncio.QueueEmpty:
                                    pass
                            continue
                        
                        # Handle text responses
                        if hasattr(response, 'text') and response.text:
                            logger.info(f"💬 AI text response: {response.text}")
                            continue
                    
                    # Turn completed - clear queued audio for smooth interruptions (like Google sample)
                    cleared_count = 0
                    while not self.audio_in_queue.empty():
                        try:
                            self.audio_in_queue.get_nowait()
                            cleared_count += 1
                        except asyncio.QueueEmpty:
                            break
                    
                    if cleared_count > 0:
                        logger.debug(f"🔄 Cleared {cleared_count} queued audio chunks for smooth turn transition")
                        
                except asyncio.CancelledError:
                    logger.info("🛑 AI message processing cancelled")
                    break
                except Exception as e:
                    logger.error(f"Error in AI turn processing: {e}")
                    import traceback
                    logger.debug(f"Stack trace: {traceback.format_exc()}")
                    # Continue to next turn instead of breaking
                    continue
                    
        except Exception as e:
            logger.error(f"Fatal error in AI message processing: {e}")
            import traceback
            logger.error(f"Stack trace: {traceback.format_exc()}")
        finally:
            logger.info(f"🏁 AI message processing ended (received {audio_received_count} total audio messages)")

    async def _send_audio_to_ai(self) -> None:
        """Background task to send audio to AI."""
        logger.info("Audio sending to AI started")
        audio_sent_count = 0
        
        while self.running:
            try:
                # Get audio data from queue
                audio_msg = await self.audio_out_queue.get()
                audio_sent_count += 1
                
                if audio_msg and self.session:
                    try:
                        await self.session.send(input=audio_msg)
                    except Exception as e:
                        logger.error(f"Error sending audio to AI: {e}")
                
            except Exception as e:
                logger.error(f"Error in audio sending task: {e}")
                break
                
        logger.info(f"Audio sending to AI ended (sent {audio_sent_count} messages)")

    async def _play_ai_audio(self) -> None:
        """Background task to play AI audio through SIP."""
        logger.info("Audio playback task started")
        audio_processed_count = 0
        audio_buffer = b''
        buffer_target_size = 1920  # ~40ms at 24kHz - more responsive, less choppy
        
        while self.running:
            try:
                # Wait for audio data with a timeout
                audio_data = await asyncio.wait_for(self.audio_in_queue.get(), timeout=0.05)  # Shorter timeout for responsiveness
                audio_processed_count += 1
                
                if audio_data and len(audio_data) > 0:
                    audio_buffer += audio_data
                
            except asyncio.TimeoutError:
                # Timeout means the queue is empty. If we have buffered audio, send it now.
                if audio_buffer:
                    logger.info(f"🔊 Sending buffered audio chunk after timeout ({len(audio_buffer)} bytes)")
                    if self.sip_audio_callback:
                        try:
                            self.sip_audio_callback(audio_buffer)
                        except Exception as e:
                            logger.error(f"❌ Error sending audio chunk: {e}")
                    audio_buffer = b''  # Clear buffer
                continue  # Continue waiting for new audio

            except asyncio.CancelledError:
                logger.info("🛑 AI audio playback cancelled")
                break
                
            except Exception as e:
                logger.error(f"❌ Error in audio playback task: {e}")
                import traceback
                logger.error(f"Stack trace: {traceback.format_exc()}")
                continue

            # Send buffer if it's full OR if the input queue is now empty (end of a phrase)
            if audio_buffer and (len(audio_buffer) >= buffer_target_size or self.audio_in_queue.empty()):
                logger.info(f"🔊 Processing buffered AI audio: {len(audio_buffer)} bytes (full: {len(audio_buffer) >= buffer_target_size}, empty_q: {self.audio_in_queue.empty()})")
                
                if self.sip_audio_callback:
                    try:
                        # Direct synchronous call - the callback is thread-safe
                        self.sip_audio_callback(audio_buffer)
                        logger.debug(f"✅ Buffered AI audio sent successfully")
                    except Exception as e:
                        logger.error(f"❌ Error sending buffered AI audio: {e}")
                        import traceback
                        logger.error(f"Stack trace: {traceback.format_exc()}")
                
                # CRITICAL: Clear buffer after sending
                audio_buffer = b''
        
        # Send any remaining buffered audio
        if audio_buffer and self.sip_audio_callback:
            logger.info(f"🔊 Sending final buffered audio: {len(audio_buffer)} bytes")
            try:
                self.sip_audio_callback(audio_buffer)
            except Exception as e:
                logger.error(f"❌ Error sending final buffer: {e}")
                
        logger.info(f"🏁 Audio playback task ended (processed {audio_processed_count} audio chunks)")
    
    def __del__(self):
        """Cleanup PyAudio."""
        if hasattr(self, 'pya'):
            self.pya.terminate() 

================================================================================

----- FILE: callie_caller/config/__init__.py -----

"""Configuration management for Callie Caller."""

from callie_caller.config.settings import Settings, get_settings

__all__ = ["Settings", "get_settings"] 

================================================================================

----- FILE: callie_caller/config/settings.py -----

"""
Settings and configuration management for Callie Caller.
Handles environment variables, validation, and default values.
"""

import os
from typing import Optional
from dataclasses import dataclass
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

@dataclass
class ZohoSettings:
    """Zoho Voice SIP configuration."""
    sip_server: str
    sip_username: str  
    sip_password: str
    sip_port: int = 5060
    backup_server: Optional[str] = None
    account_label: Optional[str] = None

@dataclass  
class DeviceSettings:
    """Yealink device emulation settings."""
    mac_address: str
    model: str = "SIP-T46S"
    firmware: str = "66.85.0.5"
    custom_user_agent: Optional[str] = None
    
    @property
    def user_agent(self) -> str:
        """Generate proper Yealink User-Agent string."""
        if self.custom_user_agent:
            return self.custom_user_agent
        return f"Yealink {self.model} {self.firmware} ~{self.mac_address}"

@dataclass
class AISettings:
    """Google Gemini AI configuration."""
    api_key: str
    model: str = "gemini-2.0-flash-001"
    max_tokens: int = 150
    temperature: float = 0.7

@dataclass
class ServerSettings:
    """Flask web server configuration."""
    host: str = "0.0.0.0"
    port: int = 8080
    debug: bool = False
    
@dataclass
class CallSettings:
    """Call handling settings."""
    default_greeting: str = "Hello! This is an AI assistant. How can I help you today?"
    max_call_duration: int = 1800  # 30 minutes
    answer_timeout: int = 30
    # RTP port configuration for NAT traversal
    rtp_port_min: int = 10000  # Start of RTP port range
    rtp_port_max: int = 10100  # End of RTP port range (100 ports available)
    use_fixed_rtp_port: bool = True  # Use fixed port instead of random

@dataclass
class Settings:
    """Main settings container."""
    zoho: ZohoSettings
    device: DeviceSettings  
    ai: AISettings
    server: ServerSettings
    calls: CallSettings
    
    @classmethod
    def from_env(cls) -> "Settings":
        """Create settings from environment variables."""
        
        # Zoho Voice settings (required)
        zoho = ZohoSettings(
            sip_server=_get_required_env("ZOHO_SIP_SERVER"),
            sip_username=_get_required_env("ZOHO_SIP_USERNAME"), 
            sip_password=_get_required_env("ZOHO_SIP_PASSWORD"),
            sip_port=int(os.getenv("SIP_PORT", "5060")),
            backup_server=os.getenv("ZOHO_SIP_BACKUP_SERVER"),
            account_label=os.getenv("ACCOUNT_LABEL")
        )
        
        # Device emulation settings (required MAC address)
        device = DeviceSettings(
            mac_address=_get_required_env("CUSTOM_USER_AGENT", "00:1a:2b:3c:4d:5e"),
            model=os.getenv("DEVICE_MODEL", "SIP-T46S"),
            firmware=os.getenv("DEVICE_FIRMWARE", "66.85.0.5"),
            custom_user_agent=os.getenv("CUSTOM_USER_AGENT_OVERRIDE")
        )
        
        # AI settings (required API key)
        ai = AISettings(
            api_key=_get_required_env("GEMINI_API_KEY"),
            model=os.getenv("GEMINI_MODEL", "gemini-2.0-flash-001"),
            max_tokens=int(os.getenv("GEMINI_MAX_TOKENS", "150")),
            temperature=float(os.getenv("GEMINI_TEMPERATURE", "0.7"))
        )
        
        # Server settings
        server = ServerSettings(
            host=os.getenv("FLASK_HOST", "0.0.0.0"),
            port=int(os.getenv("FLASK_PORT", "8080")),
            debug=os.getenv("FLASK_DEBUG", "false").lower() == "true"
        )
        
        # Call settings
        calls = CallSettings(
            default_greeting=os.getenv("DEFAULT_GREETING", "Hello! This is your AI voice assistant."),
            max_call_duration=int(os.getenv("MAX_CALL_DURATION", "300")),
            answer_timeout=int(os.getenv("ANSWER_TIMEOUT", "30")),
            rtp_port_min=int(os.getenv("RTP_PORT_MIN", "10000")),
            rtp_port_max=int(os.getenv("RTP_PORT_MAX", "10100")),
            use_fixed_rtp_port=os.getenv("USE_FIXED_RTP_PORT", "true").lower() == "true"
        )
        
        return cls(
            zoho=zoho,
            device=device,
            ai=ai, 
            server=server,
            calls=calls
        )
    
    def validate(self) -> None:
        """Validate all settings."""
        errors = []
        
        # Validate required fields are not empty
        if not self.zoho.sip_server:
            errors.append("ZOHO_SIP_SERVER is required")
        if not self.zoho.sip_username:
            errors.append("ZOHO_SIP_USERNAME is required")
        if not self.zoho.sip_password:
            errors.append("ZOHO_SIP_PASSWORD is required")
        if not self.device.mac_address:
            errors.append("CUSTOM_USER_AGENT (MAC address) is required")
        if not self.ai.api_key:
            errors.append("GEMINI_API_KEY is required")
            
        # Validate formats
        if self.device.mac_address and len(self.device.mac_address.replace(":", "")) != 12:
            errors.append("MAC address must be in format XX:XX:XX:XX:XX:XX")
            
        if self.zoho.sip_port < 1 or self.zoho.sip_port > 65535:
            errors.append("SIP port must be between 1 and 65535")
            
        if errors:
            raise ValueError(f"Configuration errors: {', '.join(errors)}")

def _get_required_env(key: str, default: Optional[str] = None) -> str:
    """Get required environment variable or raise error."""
    value = os.getenv(key, default)
    if not value:
        raise ValueError(f"Required environment variable {key} is not set")
    return value

# Global settings instance
_settings: Optional[Settings] = None

def get_settings() -> Settings:
    """Get global settings instance (singleton pattern)."""
    global _settings
    if _settings is None:
        _settings = Settings.from_env()
        _settings.validate()
    return _settings

def reload_settings() -> Settings:
    """Reload settings from environment (useful for testing)."""
    global _settings
    load_dotenv(override=True)  # Reload .env file
    _settings = Settings.from_env()
    _settings.validate()
    return _settings 

================================================================================

----- FILE: callie_caller/core/__init__.py -----

"""Core functionality for Callie Caller."""

from callie_caller.core.agent import CallieAgent
from callie_caller.core.logging import setup_logging

__all__ = ["CallieAgent", "setup_logging"] 

================================================================================

----- FILE: callie_caller/core/agent.py -----

"""
Main Callie Agent - AI Voice Assistant for Zoho Voice.
Coordinates SIP calling, AI conversation, and call management.
"""

import logging
import threading
import time
import asyncio
from typing import Optional, Dict, Any, Callable
from flask import Flask, request, Response, jsonify
import random

from callie_caller.config import get_settings
from callie_caller.sip.client import SipClient
from callie_caller.ai.conversation_fixed import AudioBridge
from callie_caller.sip.call import SipCall, CallState

logger = logging.getLogger(__name__)

class CallieAgent:
    """
    Main AI voice agent that coordinates all components.
    Handles incoming/outgoing calls with intelligent conversation.
    """
    
    def __init__(self):
        """Initialize Callie Agent."""
        self.settings = get_settings()
        
        # Initialize components
        # Initialize audio bridge with API key
        settings = get_settings()
        api_key = settings.ai.api_key
        self.audio_bridge = AudioBridge(api_key)
        self.sip_client = SipClient(on_incoming_call=self._handle_incoming_call)
        
        # Flask app for SMS and webhooks
        self.app = Flask(__name__)
        self._setup_flask_routes()
        
        # State management
        self.running = False
        self.threads: Dict[str, threading.Thread] = {}
        self.call_conversations: Dict[str, str] = {}  # call_id -> conversation_id
        
        # Event loop for async audio conversations
        self._loop: Optional[asyncio.AbstractEventLoop] = None
        self._loop_thread: Optional[threading.Thread] = None
        
        logger.info("Callie Agent initialized")
        
    def start(self) -> None:
        """Start the AI voice agent."""
        if self.running:
            logger.warning("Agent is already running")
            return
            
        logger.info("Starting Callie Agent...")
        self.running = True
        
        try:
            # Start SIP client
            self.sip_client.start()
            
            # CRITICAL: Connect audio bridge to SIP client for audio flow
            logger.info("🔗 Connecting audio bridge to SIP client...")
            
            # Set up audio callbacks for bidirectional flow
            def rtp_to_ai_callback(audio_data: bytes, source: str = "caller"):
                """Forward RTP audio to AI"""
                try:
                    asyncio.run_coroutine_threadsafe(
                        self.audio_bridge.send_sip_audio(audio_data),
                        self._loop
                    )
                    logger.debug(f"🎤 Forwarded {len(audio_data)} bytes from {source} to AI")
                except Exception as e:
                    logger.error(f"Error sending RTP to AI: {e}")
            
            def ai_to_rtp_callback(audio_data: bytes):
                """Forward AI audio back to RTP"""
                try:
                    if self.sip_client.rtp_bridge:
                        self.sip_client.rtp_bridge.send_ai_audio(audio_data, target="caller")
                        logger.debug(f"🔊 Sent {len(audio_data)} bytes of AI audio to caller")
                except Exception as e:
                    logger.error(f"Error sending AI audio to RTP: {e}")
            
            # Connect the callbacks  
            # Note: audio callback will be set when call starts
            self.rtp_to_ai_callback = rtp_to_ai_callback
            self.audio_bridge.set_sip_audio_callback(ai_to_rtp_callback)
            
            logger.info("✅ Audio bridge callbacks prepared")
            
            # Attempt registration (optional for outbound-only mode)
            try:
                self.sip_client.register()
            except Exception as e:
                logger.warning(f"SIP registration failed (continuing in outbound-only mode): {e}")
            
            # Start Flask server in background
            flask_thread = threading.Thread(
                target=self._run_flask_server,
                name="flask-server",
                daemon=True
            )
            flask_thread.start()
            self.threads["flask"] = flask_thread
            
            # Start event loop for audio conversations
            self._loop_thread = threading.Thread(
                target=self._start_event_loop,
                name="event-loop",
                daemon=True
            )
            self._loop_thread.start()
            self.threads["event-loop"] = self._loop_thread
            
            # Wait a moment for event loop to start
            time.sleep(0.5)
            
            # Start the audio bridge now that event loop is running
            asyncio.run_coroutine_threadsafe(
                self.audio_bridge.start("You are Callie, an AI voice assistant. Be helpful and conversational."),
                self._loop
            )
            logger.info("🎵 Audio bridge started in event loop")
            
            logger.info(f"Callie Agent started successfully")
            logger.info(f"- SIP client: {self.sip_client.local_ip}:{self.sip_client.local_port}")
            logger.info(f"- Device emulation: {self.settings.device.user_agent}")
            logger.info(f"- Web server: http://{self.settings.server.host}:{self.settings.server.port}")
            
        except Exception as e:
            logger.error(f"Failed to start agent: {e}")
            self.stop()
            raise
            
    def stop(self) -> None:
        """Stop the Callie Agent."""
        logger.info("Stopping Callie Agent...")
        
        # Stop SIP client
        if self.sip_client:
            self.sip_client.stop()
        
        # Stop event loop
        if self._loop and self._loop.is_running():
            self._loop.stop()
            logger.info("Event loop stopped")
    
    def enable_test_audio_mode(self, test_audio_file: str = None) -> bool:
        """Enable test audio mode to inject known audio instead of AI."""
        if self.sip_client:
            success = self.sip_client.enable_test_mode(test_audio_file)
            if success:
                logger.info("🧪 Test audio mode enabled for agent")
            return success
        logger.error("❌ Cannot enable test mode - SIP client not available")
        return False
        
    def make_call(self, phone_number: str, message: Optional[str] = None) -> bool:
        """
        Make an outbound call with AI conversation.
        
        Args:
            phone_number: Target phone number (E.164 format recommended)
            message: Optional initial AI message (max 1000 characters)
            
        Returns:
            bool: True if call was successful
            
        Raises:
            ValueError: If phone number format is invalid
            RuntimeError: If agent is not started
        """
        # Input validation
        if not self.running:
            raise RuntimeError("Agent must be started before making calls")
            
        if not phone_number:
            raise ValueError("Phone number cannot be empty")
            
        # Basic phone number validation
        import re
        # Remove common formatting characters
        clean_number = re.sub(r'[^\d+]', '', phone_number.strip())
        
        # Validate phone number format
        if not re.match(r'^\+?[1-9]\d{7,14}$', clean_number):
            raise ValueError(f"Invalid phone number format: {phone_number}")
            
        # Validate message length if provided
        if message is not None:
            if len(message) > 1000:
                raise ValueError("Message cannot exceed 1000 characters")
            if not message.strip():
                message = None  # Treat empty/whitespace as None
                
        logger.info(f"📞 Making call to {clean_number}")
        
        # Create a new call
        call = SipCall(
            call_id=f"call-{random.randint(100000, 999999)}-{int(time.time())}",
            local_ip=self.sip_client.local_ip,
            public_ip=self.sip_client.public_ip,
            local_port=self.sip_client.local_port,
            settings=self.sip_client.settings,
            authenticator=self.sip_client.authenticator,
            target_number=clean_number,
            ai_message=message
        )
        
        # Make the call
        success = self.sip_client.make_call(call)
        
        if success and call.state == CallState.CONNECTED:
            logger.info(f"🎉 Call {call.call_id} connected successfully!")
            
            # CRITICAL: Set up audio callback for this call's RTP bridge
            if hasattr(self, 'rtp_to_ai_callback') and self.sip_client.rtp_bridge:
                self.sip_client.rtp_bridge.set_audio_callback(self.rtp_to_ai_callback)
                logger.info("🔗 Audio callback connected to RTP bridge")
            
            # 🔧 FIX: Run async conversation in event loop
            try:
                if self._loop and self._loop.is_running():
                    # Schedule the conversation in the existing event loop
                    future = asyncio.run_coroutine_threadsafe(
                        self._handle_call_conversation(call),
                        self._loop
                    )
                    
                    # Wait for the conversation to complete
                    future.result()  # This will block until call ends
                    
                else:
                    # No event loop running, create a new one
                    logger.info("🔄 Creating new event loop for call conversation...")
                    asyncio.run(self._handle_call_conversation(call))
                    
            except Exception as e:
                logger.error(f"Error in async call handling: {e}")
                call.fail(f"Async error: {e}")
            
            logger.info(f"📞 Call {call.call_id} conversation completed")
            return True
            
        else:
            if not success:
                logger.error(f"❌ Call to {phone_number} failed to connect")
            elif call.state == CallState.RINGING:
                logger.info(f"📞 Call to {phone_number} is ringing but not answered")
                
                # 🔧 FIX: For ringing calls, still run conversation monitoring  
                try:
                    if self._loop and self._loop.is_running():
                        future = asyncio.run_coroutine_threadsafe(
                            self._handle_call_conversation(call),
                            self._loop
                        )
                        future.result()
                    else:
                        asyncio.run(self._handle_call_conversation(call))
                except Exception as e:
                    logger.error(f"Error in ringing call handling: {e}")
                    
            return False
        
    def _handle_incoming_call(self, call: SipCall) -> None:
        """Handle incoming SIP call."""
        logger.info(f"Incoming call from {call.target_number}")
        
        # Start conversation
        conversation_id = f"incoming-{int(time.time())}-{call.target_number}"
        self.conversation_manager.start_conversation(
            conversation_id=conversation_id,
            phone_number=call.target_number
        )
        
        # Link call and conversation
        self.call_conversations[call.call_id] = conversation_id
        
        # Generate greeting
        greeting = self.conversation_manager.generate_greeting(
            conversation_id,
            context=f"Incoming call from {call.target_number}"
        )
        
        # Answer call
        call.answer()
        logger.info(f"Answered call {call.call_id} with greeting: {greeting}")
        
        if call.state == CallState.CONNECTED:
            # 🔧 FIX: Properly handle async conversation for incoming calls
            try:
                if self._loop and self._loop.is_running():
                    # Schedule the conversation in the existing event loop
                    future = asyncio.run_coroutine_threadsafe(
                        self._handle_call_conversation(call),
                        self._loop
                    )
                    logger.info(f"🔄 Incoming call conversation scheduled in event loop")
                    # Don't wait here - let it run asynchronously
                else:
                    # No event loop running, this shouldn't happen but handle gracefully
                    logger.error("⚠️  No event loop available for incoming call conversation")
                    call.hangup()
                    
            except Exception as e:
                logger.error(f"Error starting incoming call conversation: {e}")
                call.hangup()

    # The _monitor_call method is no longer needed as the SIP client now blocks
    # until a call is connected or fails. We can remove it.
        
    async def _handle_call_conversation(self, call: SipCall) -> None:
        """Handle conversation for a connected call."""
        logger.info(f"🎤 Starting conversation for call {call.call_id}")
        
        try:
            # Add initial delay to ensure call is fully established
            logger.info(f"⏳ Allowing 2 seconds for call to fully establish...")
            await asyncio.sleep(2.0)
            
            # Check if call is actually answered or went to voicemail
            if call.state == CallState.CONNECTED:
                # Additional check - wait a moment and see if we get actual audio
                logger.info(f"🔍 Checking if call is truly answered or voicemail...")
                await asyncio.sleep(3.0)  # Wait 3 seconds
                
                # Check for voicemail indicators
                if self._is_voicemail_call(call):
                    logger.info(f"📞 Call {call.call_id} appears to be voicemail - hanging up")
                    call.hangup()
                    return
                
                logger.info(f"🎯 Initializing audio conversation for {call.call_id}")
                await self.sip_client.start_audio_conversation(
                    call,
                    initial_message=call.ai_message
                )
                logger.info(f"✅ Audio conversation started for {call.call_id}")
            else:
                logger.warning(f"⚠️  Call {call.call_id} not connected when starting conversation (state: {call.state.value})")
                return
            
            # 🔔 Monitor call state and exit when call ends
            logger.info(f"🔔 Monitoring call {call.call_id} - will exit when call ends...")
            
            # Keep the conversation active while call is connected
            conversation_time = 0
            no_audio_time = 0
            last_audio_packets = 0
            
            while call.state == CallState.CONNECTED:
                await asyncio.sleep(1.0)  # Check every second
                conversation_time += 1
                
                # Check for audio activity to detect if call is actually active
                if self.sip_client.rtp_bridge:
                    # Use packets_to_ai as the indicator of active conversation (user speaking)
                    current_packets = self.sip_client.rtp_bridge.packets_to_ai + self.sip_client.rtp_bridge.packets_from_ai
                    if current_packets == last_audio_packets:
                        no_audio_time += 1
                    else:
                        no_audio_time = 0  # Reset if we got audio (either direction)
                    last_audio_packets = current_packets
                    
                    # Only hang up if there's ZERO RTP traffic for extended period (dead connection)
                    if no_audio_time > 60 and conversation_time > 60:  # No audio for 60+ seconds after 1 minute
                        logger.warning(f"⚠️  No RTP traffic for {no_audio_time}s - possible dead connection")
                        if no_audio_time > 120:  # 2 minutes of complete silence = dead connection
                            logger.info(f"📞 Hanging up due to dead connection (no RTP traffic for 2+ minutes)")
                            call.hangup()
                            break
                
                # Auto hangup after reasonable conversation time limit  
                if conversation_time > 1800:  # 30 minutes max for natural conversations
                    logger.info(f"⏰ Call {call.call_id} reached maximum duration (30 min), hanging up")
                    call.hangup()
                    break
                
                # Log periodic status
                duration = call.duration
                if conversation_time % 10 == 0:  # Every 10 seconds
                    logger.info(f"📞 Call active for {duration:.0f} seconds - state: {call.state.value}")
                    
                    # Enhanced bridge statistics
                    if self.sip_client.rtp_bridge:
                        bridge_stats = {
                            'packets_received': self.sip_client.rtp_bridge.packets_forwarded,
                            'packets_to_ai': self.sip_client.rtp_bridge.packets_to_ai,
                            'packets_from_ai': self.sip_client.rtp_bridge.packets_from_ai,
                            'caller_packets_recorded': self.sip_client.rtp_bridge.caller_packets_recorded,
                            'remote_packets_recorded': self.sip_client.rtp_bridge.remote_packets_recorded
                        }
                        
                        total_conversation_packets = bridge_stats['packets_to_ai'] + bridge_stats['packets_from_ai']
                        logger.info(f"🌉 Bridge stats: {bridge_stats['packets_received']} received, {bridge_stats['packets_to_ai']} to AI, {bridge_stats['packets_from_ai']} from AI")
                        logger.info(f"🎙️  Conversation activity: {total_conversation_packets} total packets, silence: {no_audio_time}s")
                        
                        if total_conversation_packets == 0 and conversation_time > 30:
                            # Only warn about no conversation activity after 30 seconds
                            logger.warning("⚠️  No conversation activity detected - check audio pipeline")
                            logger.info("🔧 Troubleshooting:")
                            logger.info(f"   • Bridge listening on: ALL INTERFACES:{self.sip_client.rtp_bridge.local_port}")
                            if self.sip_client.rtp_bridge.remote_endpoint:
                                logger.info(f"   • Remote endpoint: {self.sip_client.rtp_bridge.remote_endpoint.ip}:{self.sip_client.rtp_bridge.remote_endpoint.port}")
                        elif total_conversation_packets > 0:
                            logger.info(f"✅ Active conversation! Recording: {bridge_stats['caller_packets_recorded']} caller, {bridge_stats['remote_packets_recorded']} remote packets")
                    else:
                        logger.warning("⚠️  No RTP bridge active - this shouldn't happen during a call")
                
                # Additional early logging for first few seconds
                elif conversation_time <= 5:
                    logger.info(f"🕐 Call conversation active for {conversation_time} seconds")
            
            # Call ended - log the reason
            logger.info(f"📞 Call {call.call_id} ended with state: {call.state.value}")
            logger.info(f"⏱️  Total call duration: {call.duration:.1f} seconds")
            
        except Exception as e:
            logger.error(f"💥 Error in call conversation: {e}")
            import traceback
            logger.error(f"📋 Stack trace: {traceback.format_exc()}")
            call.fail(f"Conversation error: {e}")
        finally:
            # Ensure proper cleanup
            try:
                logger.info(f"🧹 Cleaning up call {call.call_id}")
                
                # Stop audio conversation
                await self.sip_client.stop_audio_conversation()
                logger.info(f"🔇 Audio conversation stopped for {call.call_id}")
                
                # Properly terminate the call if not already ended
                if call.state not in [CallState.ENDED, CallState.FAILED]:
                    self.sip_client.terminate_call(call)
                    logger.info(f"📞 Call {call.call_id} properly terminated")
                    
            except Exception as cleanup_error:
                logger.error(f"💥 Error during call cleanup: {cleanup_error}")
    
    def _is_voicemail_call(self, call: SipCall) -> bool:
        """Detect if call went to voicemail based on various indicators."""
        # Check call duration - if "connected" immediately, likely voicemail
        if call.state == CallState.CONNECTED and call.duration < 2:
            logger.info("🔍 Call connected very quickly - checking for voicemail...")
            
            # Check if we have RTP bridge with conversation patterns
            if self.sip_client.rtp_bridge:
                # Wait longer for natural conversation patterns to emerge
                time.sleep(5)
                
                # Check for realistic voicemail patterns (very rare in modern calls)
                packets_to_ai = self.sip_client.rtp_bridge.packets_to_ai
                packets_from_ai = self.sip_client.rtp_bridge.packets_from_ai
                
                # Only consider voicemail if we get sustained one-way audio for 10+ seconds
                # AND no AI response generated (which would indicate interaction)
                if packets_to_ai > 100 and packets_from_ai == 0:
                    logger.info("🔍 Sustained incoming audio with no AI response - possible voicemail")
                    return True
        
        return False
        
    async def _test_live_api(self) -> None:
        """Test Live API connection independently."""
        try:
            # Ensure audio bridge is initialized
            if not self.sip_client.audio_bridge:
                 self.sip_client.audio_bridge = self.sip_client.get_audio_bridge()

            if self.sip_client.audio_bridge:
                logger.info("🔬 Testing Live API connection...")
                result = await self.sip_client.audio_bridge.test_live_api_connection()
                if result:
                    logger.info("✅ Live API connection test successful!")
                else:
                    logger.error("❌ Live API connection test failed!")
        except Exception as e:
            logger.error(f"💥 Live API test error: {e}")
            
    def _start_event_loop(self) -> None:
        """Start asyncio event loop for audio conversations."""
        try:
            self._loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self._loop)
            logger.info("Event loop started for audio conversations")
            self._loop.run_forever()
        except Exception as e:
            logger.error(f"Error in event loop: {e}")
        finally:
            logger.info("Event loop stopped")
            
    def _setup_flask_routes(self) -> None:
        """Setup Flask routes for webhooks and API."""
        
        @self.app.route('/health', methods=['GET'])
        def health_check():
            """Health check endpoint."""
            return jsonify({
                'status': 'healthy',
                'agent_running': self.running,
                'sip_registered': getattr(self.sip_client, 'registered', False),
                'active_calls': len(getattr(self.sip_client, 'active_calls', {})),
                'active_conversations': len(self.conversation_manager.active_conversations)
            })
            
        @self.app.route('/sms', methods=['POST'])
        def handle_sms():
            """Handle incoming SMS from Zoho Voice."""
            try:
                from_number = request.form.get('from', 'unknown')
                message_body = request.form.get('text', '')
                
                logger.info(f"SMS from {from_number}: {message_body}")
                
                # Start conversation for SMS
                conversation_id = f"sms-{int(time.time())}-{from_number}"
                conversation = self.conversation_manager.start_conversation(
                    conversation_id=conversation_id,
                    phone_number=from_number
                )
                
                # Add user message
                self.conversation_manager.add_user_message(
                    conversation_id, 
                    message_body,
                    metadata={'type': 'sms'}
                )
                
                # Generate AI response
                response = self.conversation_manager.generate_response(conversation_id)
                
                if response:
                    logger.info(f"SMS AI response: {response}")
                    # In a real implementation, send SMS response via Zoho API
                    
                # End SMS conversation
                self.conversation_manager.end_conversation(conversation_id)
                
                return Response(status=200)
                
            except Exception as e:
                logger.error(f"Error handling SMS: {e}")
                return Response("Error processing SMS", status=500)
                
        @self.app.route('/call', methods=['POST'])
        def make_call_api():
            """API endpoint to make outbound calls."""
            try:
                data = request.get_json()
                number = data.get('number')
                message = data.get('message')
                
                if not number:
                    return jsonify({'error': 'Phone number required'}), 400
                    
                call = self.make_call(number, message)
                
                if call:
                    return jsonify({
                        'success': True,
                        'call_id': call.call_id,
                        'target': call.target_number,
                        'state': call.state.value
                    })
                else:
                    return jsonify({'error': 'Failed to make call'}), 500
                    
            except Exception as e:
                logger.error(f"Error in call API: {e}")
                return jsonify({'error': str(e)}), 500
                
        @self.app.route('/conversations', methods=['GET'])
        def get_conversations():
            """Get conversation history."""
            try:
                phone_number = request.args.get('phone_number')
                limit = int(request.args.get('limit', 10))
                
                conversations = self.conversation_manager.get_conversation_history(
                    phone_number=phone_number,
                    limit=limit
                )
                
                return jsonify({
                    'conversations': [
                        {
                            'id': c.conversation_id,
                            'phone_number': c.phone_number,
                            'start_time': c.start_time,
                            'duration': c.duration,
                            'message_count': c.message_count,
                            'summary': c.summary
                        }
                        for c in conversations
                    ]
                })
                
            except Exception as e:
                logger.error(f"Error getting conversations: {e}")
                return jsonify({'error': str(e)}), 500
                
        @self.app.route('/stats', methods=['GET'])
        def get_stats():
            """Get agent statistics."""
            try:
                stats = self.conversation_manager.get_conversation_stats()
                stats.update({
                    'agent_running': self.running,
                    'sip_registered': getattr(self.sip_client, 'registered', False),
                    'device_emulation': self.settings.device.user_agent
                })
                
                return jsonify(stats)
                
            except Exception as e:
                logger.error(f"Error getting stats: {e}")
                return jsonify({'error': str(e)}), 500
                
    def _run_flask_server(self) -> None:
        """Run Flask server in thread."""
        try:
            self.app.run(
                host=self.settings.server.host,
                port=self.settings.server.port,
                debug=self.settings.server.debug,
                use_reloader=False  # Disable reloader in thread
            )
        except Exception as e:
            logger.error(f"Flask server error: {e}")
            
    def get_status(self) -> Dict[str, Any]:
        """Get current agent status."""
        return {
            'running': self.running,
            'sip_registered': getattr(self.sip_client, 'registered', False),
            'local_endpoint': f"{getattr(self.sip_client, 'local_ip', 'unknown')}:{getattr(self.sip_client, 'local_port', 'unknown')}",
            'device_emulation': self.settings.device.user_agent,
            'active_calls': len(getattr(self.sip_client, 'active_calls', {})),
            'active_conversations': len(self.conversation_manager.active_conversations),
            'total_conversations': len(self.conversation_manager.conversation_history)
        } 

    def is_call_active(self) -> bool:
        """Check if there is an active call."""
        if not self.sip_client or not self.sip_client.current_call:
            return False
        
        call_state = self.sip_client.current_call.state
        is_active = call_state not in [CallState.ENDED, CallState.FAILED]
        logger.debug(f"Checking call status: {call_state}, Is active: {is_active}")
        return is_active 

================================================================================

----- FILE: callie_caller/core/logging.py -----

"""
Logging configuration for Callie Caller.
Provides structured, production-ready logging with proper formatting.
"""

import logging
import logging.handlers
import sys
from pathlib import Path
from typing import Optional


def setup_logging(
    level: str = "INFO",
    log_file: Optional[str] = None,
    max_bytes: int = 10 * 1024 * 1024,  # 10MB
    backup_count: int = 5
) -> None:
    """
    Setup production logging configuration.
    
    Args:
        level: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        log_file: Optional log file path
        max_bytes: Max size per log file before rotation
        backup_count: Number of backup files to keep
    """
    # Convert string level to logging constant
    numeric_level = getattr(logging, level.upper(), logging.INFO)
    
    # Create formatter
    formatter = logging.Formatter(
        fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Remove existing handlers
    root_logger = logging.getLogger()
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    
    # Console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(numeric_level)
    console_handler.setFormatter(formatter)
    root_logger.addHandler(console_handler)
    
    # File handler (if specified)
    if log_file:
        log_path = Path(log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)
        
        file_handler = logging.handlers.RotatingFileHandler(
            filename=log_file,
            maxBytes=max_bytes,
            backupCount=backup_count,
            encoding='utf-8'
        )
        file_handler.setLevel(numeric_level)
        file_handler.setFormatter(formatter)
        root_logger.addHandler(file_handler)
    
    # Set root logger level
    root_logger.setLevel(numeric_level)
    
    # Reduce noise from external libraries
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('requests').setLevel(logging.WARNING)
    logging.getLogger('werkzeug').setLevel(logging.WARNING)
    
    logging.info(f"Logging configured - Level: {level}, File: {log_file or 'console only'}")


def get_logger(name: str) -> logging.Logger:
    """Get a logger instance for a module."""
    return logging.getLogger(name) 

================================================================================

----- FILE: callie_caller/core/web_agent.py -----

"""
Web-only Callie Agent for Cloud Run deployment.
Provides REST API functionality without SIP calling capabilities.
"""

import logging
import threading
import time
from typing import Optional, Dict, Any
from flask import Flask, request, Response, jsonify

from callie_caller.config import get_settings
from callie_caller.ai.conversation import ConversationManager

logger = logging.getLogger(__name__)

class WebCallieAgent:
    """
    Web-only AI voice agent for Cloud Run.
    Provides REST API without SIP calling functionality.
    """
    
    def __init__(self):
        """Initialize Web-only Callie Agent."""
        self.settings = get_settings()
        
        # Initialize only non-SIP components
        self.conversation_manager = ConversationManager()
        
        # Flask app for API
        self.app = Flask(__name__)
        self._setup_flask_routes()
        
        # State management
        self.running = False
        
        logger.info("Web Callie Agent initialized (Cloud Run mode)")
        
    def start(self) -> None:
        """Start the web agent."""
        if self.running:
            logger.warning("Web agent is already running")
            return
            
        logger.info("Starting Web Callie Agent...")
        self.running = True
        
        logger.info("Web Callie Agent started successfully")
        logger.info("📋 Cloud Run Mode - SIP calling not available in this environment")
        logger.info("🌐 Use external SIP infrastructure for actual calling")
            
    def stop(self) -> None:
        """Stop the Web Callie Agent."""
        logger.info("Stopping Web Callie Agent...")
        self.running = False
        
    def _setup_flask_routes(self) -> None:
        """Setup Flask routes for webhooks and API."""
        
        @self.app.route('/', methods=['GET'])
        def root():
            """Root endpoint with API information."""
            return jsonify({
                'service': 'Callie Caller AI Voice Agent',
                'mode': 'Cloud Run (Web API Only)',
                'version': '1.0.0',
                'status': 'healthy' if self.running else 'stopped',
                'endpoints': {
                    'health': '/health',
                    'call': '/call (POST)',
                    'conversations': '/conversations',
                    'stats': '/stats',
                    'sms': '/sms (POST)'
                },
                'limitations': [
                    'Direct SIP calling not available in Cloud Run',
                    'Use external SIP services for voice calls',
                    'AI conversation and API functionality available'
                ]
            })
        
        @self.app.route('/health', methods=['GET'])
        def health_check():
            """Health check endpoint."""
            return jsonify({
                'status': 'healthy',
                'mode': 'cloud_run_web_only',
                'agent_running': self.running,
                'sip_available': False,
                'active_conversations': len(self.conversation_manager.active_conversations),
                'timestamp': time.time()
            })
            
        @self.app.route('/sms', methods=['POST'])
        def handle_sms():
            """Handle incoming SMS from Zoho Voice."""
            try:
                from_number = request.form.get('from', 'unknown')
                message_body = request.form.get('text', '')
                
                logger.info(f"SMS from {from_number}: {message_body}")
                
                # Start conversation for SMS
                conversation_id = f"sms-{int(time.time())}-{from_number}"
                conversation = self.conversation_manager.start_conversation(
                    conversation_id=conversation_id,
                    phone_number=from_number
                )
                
                # Add user message
                self.conversation_manager.add_user_message(
                    conversation_id, 
                    message_body,
                    metadata={'type': 'sms'}
                )
                
                # Generate AI response
                response = self.conversation_manager.generate_response(conversation_id)
                
                if response:
                    logger.info(f"SMS AI response: {response}")
                    # In a real implementation, send SMS response via Zoho API
                    
                # End SMS conversation
                self.conversation_manager.end_conversation(conversation_id)
                
                return jsonify({
                    'success': True,
                    'response': response,
                    'conversation_id': conversation_id
                })
                
            except Exception as e:
                logger.error(f"Error handling SMS: {e}")
                return jsonify({'error': str(e)}), 500
                
        @self.app.route('/call', methods=['POST'])
        def make_call_api():
            """API endpoint for call requests (Cloud Run limitation noted)."""
            try:
                data = request.get_json()
                number = data.get('number')
                message = data.get('message')
                
                if not number:
                    return jsonify({'error': 'Phone number required'}), 400
                
                logger.info(f"Call request received for {number} with message: {message}")
                
                # In Cloud Run, we can't make direct SIP calls
                # Return information about external calling options
                return jsonify({
                    'success': False,
                    'error': 'Direct SIP calling not available in Cloud Run',
                    'alternatives': {
                        'voice_api': 'Use Zoho Voice API for outbound calls',
                        'sip_service': 'Deploy SIP functionality to external service',
                        'twilio': 'Use Twilio Voice API for calling',
                        'message': 'AI conversation features available via SMS endpoint'
                    },
                    'requested_number': number,
                    'requested_message': message
                })
                    
            except Exception as e:
                logger.error(f"Error in call API: {e}")
                return jsonify({'error': str(e)}), 500
                
        @self.app.route('/conversations', methods=['GET'])
        def get_conversations():
            """Get conversation history."""
            try:
                phone_number = request.args.get('phone_number')
                limit = int(request.args.get('limit', 10))
                
                conversations = self.conversation_manager.get_conversation_history(
                    phone_number=phone_number,
                    limit=limit
                )
                
                return jsonify({
                    'conversations': [
                        {
                            'id': c.conversation_id,
                            'phone_number': c.phone_number,
                            'start_time': c.start_time,
                            'duration': c.duration,
                            'message_count': c.message_count,
                            'summary': c.summary
                        }
                        for c in conversations
                    ]
                })
                
            except Exception as e:
                logger.error(f"Error getting conversations: {e}")
                return jsonify({'error': str(e)}), 500
                
        @self.app.route('/stats', methods=['GET'])
        def get_stats():
            """Get agent statistics."""
            try:
                stats = self.conversation_manager.get_conversation_stats()
                stats.update({
                    'mode': 'cloud_run_web_only',
                    'agent_running': self.running,
                    'sip_available': False,
                    'deployment': 'Cloud Run'
                })
                
                return jsonify(stats)
                
            except Exception as e:
                logger.error(f"Error getting stats: {e}")
                return jsonify({'error': str(e)}), 500
        
        @self.app.route('/ai/chat', methods=['POST'])
        def ai_chat():
            """Direct AI chat endpoint for testing."""
            try:
                data = request.get_json()
                message = data.get('message')
                phone_number = data.get('phone_number', 'web_chat')
                
                if not message:
                    return jsonify({'error': 'Message required'}), 400
                
                # Create temporary conversation
                conversation_id = f"chat-{int(time.time())}-{phone_number}"
                conversation = self.conversation_manager.start_conversation(
                    conversation_id=conversation_id,
                    phone_number=phone_number
                )
                
                # Add user message
                self.conversation_manager.add_user_message(
                    conversation_id, 
                    message,
                    metadata={'type': 'web_chat'}
                )
                
                # Generate AI response
                response = self.conversation_manager.generate_response(conversation_id)
                
                # End conversation
                self.conversation_manager.end_conversation(conversation_id)
                
                return jsonify({
                    'success': True,
                    'response': response,
                    'conversation_id': conversation_id
                })
                
            except Exception as e:
                logger.error(f"Error in AI chat: {e}")
                return jsonify({'error': str(e)}), 500
            
    def get_status(self) -> Dict[str, Any]:
        """Get current agent status."""
        return {
            'mode': 'cloud_run_web_only',
            'running': self.running,
            'sip_available': False,
            'deployment': 'Cloud Run',
            'active_conversations': len(self.conversation_manager.active_conversations),
            'total_conversations': len(self.conversation_manager.conversation_history)
        }

def create_app() -> Flask:
    """Create Flask app for Cloud Run deployment."""
    agent = WebCallieAgent()
    agent.start()
    return agent.app 

================================================================================

----- FILE: callie_caller/sip/__init__.py -----

"""
This package handles the Session Initiation Protocol (SIP) communication
for emulating a Yealink desk phone and connecting to Zoho Voice.
"""

from .client import SipClient
from .call import SipCall, CallState
from .sdp import SdpParser, AudioParams, extract_audio_params_from_sip_response
from .rtp import RtpHandler, RtpPacket
from .rtp_bridge import RtpBridge
from .parser import SipResponse, parse_sip_response

__all__ = [
    "SipClient",
    "SipCall",
    "CallState",
    "SdpParser",
    "AudioParams",
    "extract_audio_params_from_sip_response",
    "RtpHandler",
    "RtpPacket",
    "RtpBridge",
    "SipResponse",
    "parse_sip_response"
] 

================================================================================

----- FILE: callie_caller/sip/audio_codec.py -----

"""
Audio codec conversion functions for G.711 and PCM formats.
Replaces audioop functionality for Python 3.13+ compatibility.
"""

import struct
import logging
from typing import Optional
import numpy as np
from scipy.signal import resample

logger = logging.getLogger(__name__)

# G.711 μ-law encoding/decoding tables
ULAW_BIAS = 0x84
ULAW_CLIP = 32635

def ulaw_to_linear(ulaw_byte: int) -> int:
    """Convert single μ-law byte to 16-bit linear PCM sample."""
    ulaw_byte = ~ulaw_byte
    sign = (ulaw_byte & 0x80)
    exponent = (ulaw_byte >> 4) & 0x07
    mantissa = ulaw_byte & 0x0F
    
    sample = mantissa << (exponent + 3)
    if exponent > 0:
        sample += (1 << (exponent + 2))
    
    if sign:
        sample = -sample
        
    return sample

def linear_to_ulaw(sample: int) -> int:
    """Convert 16-bit linear PCM sample to μ-law byte."""
    # Clamp sample to valid range
    if sample > ULAW_CLIP:
        sample = ULAW_CLIP
    elif sample < -ULAW_CLIP:
        sample = -ULAW_CLIP
    
    # Get sign and magnitude
    sign = 0x80 if sample < 0 else 0x00
    if sample < 0:
        sample = -sample
    
    sample += ULAW_BIAS
    
    # Find exponent
    exponent = 0
    for i in range(8):
        if sample <= (0x1FFF << i):
            exponent = i
            break
    
    # Extract mantissa
    mantissa = (sample >> (exponent + 3)) & 0x0F
    
    # Combine and invert
    ulaw = ~(sign | (exponent << 4) | mantissa)
    return ulaw & 0xFF

def ulaw_to_pcm(ulaw_data: bytes) -> bytes:
    """Convert μ-law encoded audio to 16-bit PCM using standard G.711 μ-law."""
    try:
        pcm_samples = []
        for byte in ulaw_data:
            # Use standard G.711 μ-law decompression - no artificial gain needed
            linear_sample = ulaw_to_linear(byte)
            # Clamp to 16-bit range (should already be in range, but safety check)
            linear_sample = max(-32768, min(32767, linear_sample))
            pcm_samples.append(linear_sample)
        
        # Pack as 16-bit signed integers
        pcm_data = struct.pack(f'<{len(pcm_samples)}h', *pcm_samples)
        logger.debug(f"Converted {len(ulaw_data)} μ-law bytes to {len(pcm_data)} PCM bytes (standard G.711)")
        return pcm_data
        
    except Exception as e:
        logger.error(f"Error converting μ-law to PCM: {e}")
        return b''

def resample_simple(audio_data: bytes, from_rate: int, to_rate: int, sample_width: int = 2) -> bytes:
    """
    High-quality audio resampling using scipy for voice applications.
    Ensures proper anti-aliasing to prevent distortion and static.
    
    Args:
        audio_data: Input audio data
        from_rate: Source sample rate
        to_rate: Target sample rate  
        sample_width: Bytes per sample (2 for 16-bit)
    """
    try:
        if from_rate == to_rate:
            return audio_data
            
        if len(audio_data) < sample_width:
            logger.warning(f"Audio data too short for resampling: {len(audio_data)} bytes")
            return audio_data
            
        # Convert byte data to numpy array for processing
        sample_count = len(audio_data) // sample_width
        if sample_count == 0:
            return b''
            
        # Unpack as 16-bit signed integers
        samples = np.frombuffer(audio_data, dtype=np.int16)
        
        # Calculate the number of samples in the output signal
        num_samples_out = int(len(samples) * to_rate / from_rate)
        
        logger.debug(f"🎵 High-quality resampling {len(samples)} samples from {from_rate}Hz to {to_rate}Hz → {num_samples_out} samples")

        # Use scipy's high-quality Fourier-based resampler with enhanced filtering
        # Apply pre-filtering for voice frequencies and reduce aliasing artifacts
        from scipy.signal import butter, filtfilt
        
        # For voice applications, pre-filter to remove sub-audible noise and high-freq artifacts
        if from_rate >= 16000:  # Only filter high-sample-rate audio
            # Design a voice-optimized bandpass filter (300Hz - 3400Hz for telephony)
            nyquist = from_rate / 2
            low_freq = 300 / nyquist    # Remove low-frequency rumble
            high_freq = 3400 / nyquist  # Remove high-frequency noise
            
            try:
                # Create a 4th-order Butterworth bandpass filter
                b, a = butter(4, [low_freq, high_freq], btype='band')
                # Apply zero-phase filtering (no delay)
                filtered_samples = filtfilt(b, a, samples.astype(np.float64))
                logger.debug(f"🎵 Applied voice-optimized bandpass filter (300-3400Hz)")
            except Exception as filter_error:
                logger.debug(f"⚠️ Filter failed, using original: {filter_error}")
                filtered_samples = samples.astype(np.float64)
        else:
            filtered_samples = samples.astype(np.float64)
        
        # High-quality resampling with the filtered audio
        resampled_samples = resample(filtered_samples, num_samples_out)
        
        # Convert back to 16-bit integers with proper rounding and clamping
        resampled_samples = np.round(resampled_samples).astype(np.int32)
        resampled_samples = np.clip(resampled_samples, -32768, 32767).astype(np.int16)
        
        # Pack back to bytes
        resampled_data = resampled_samples.tobytes()
            
        logger.debug(f"✅ Professional resampling completed: {len(audio_data)} bytes → {len(resampled_data)} bytes")
        return resampled_data
        
    except Exception as e:
        logger.error(f"💥 Error in high-quality resampling: {e}")
        return audio_data

# A-law support (ITU-T G.711 standard)
ALAW_CLIP = 32767  # Full 16-bit range

def alaw_to_linear(alaw_byte: int) -> int:
    """Convert single A-law byte to 16-bit linear PCM sample using ITU-T G.711 standard."""
    # XOR with 0x55 to undo even-bit inversion
    alaw_byte ^= 0x55
    
    # Extract sign bit
    sign = alaw_byte & 0x80
    
    # Extract exponent (3 bits) and mantissa (4 bits)
    exponent = (alaw_byte >> 4) & 0x07
    mantissa = alaw_byte & 0x0F
    
    # Decode according to ITU-T G.711 A-law specification
    if exponent == 0:
        # Linear segment (exponent 0)
        linear = (mantissa << 1) | 1
    else:
        # Logarithmic segments (exponents 1-7)
        linear = ((mantissa << 1) | 0x21) << (exponent - 1)
    
    # Apply sign
    if sign:
        linear = -linear
    
    # Scale to full 16-bit range to prevent volume loss
    # A-law has a maximum output of ~4096, so we need to scale up
    linear = linear << 3  # Multiply by 8 to reach near full range
    
    # Clamp to prevent overflow
    linear = max(-32767, min(32767, linear))
        
    return linear

def alaw_to_pcm(alaw_data: bytes) -> bytes:
    """Convert A-law encoded audio to 16-bit PCM using standard G.711 A-law."""
    try:
        pcm_samples = []
        for byte in alaw_data:
            # Use standard G.711 A-law decompression - no artificial gain needed
            linear_sample = alaw_to_linear(byte)
            # Clamp to 16-bit range (should already be in range, but safety check) 
            linear_sample = max(-32768, min(32767, linear_sample))
            pcm_samples.append(linear_sample)
        
        pcm_data = struct.pack(f'<{len(pcm_samples)}h', *pcm_samples)
        logger.debug(f"Converted {len(alaw_data)} A-law bytes to {len(pcm_data)} PCM bytes (standard G.711)")
        return pcm_data
        
    except Exception as e:
        logger.error(f"Error converting A-law to PCM: {e}")
        return b'' 

def linear_to_alaw(sample: int) -> int:
    """Convert 16-bit linear PCM sample to A-law byte using ITU-T G.711 standard."""
    # Scale down from full 16-bit range to A-law input range
    # Since we scale up by 8 in decoding, scale down by 8 in encoding
    sample = sample >> 3
    
    # Clamp sample to valid A-law input range
    if sample > 4095:
        sample = 4095
    elif sample < -4095:
        sample = -4095
    
    # Get sign and magnitude
    sign = 0x80 if sample < 0 else 0x00
    if sample < 0:
        sample = -sample
    
    # Find exponent and mantissa according to ITU-T G.711
    if sample < 16:
        # Linear segment (exponent 0)
        exponent = 0
        mantissa = (sample >> 1) & 0x0F
    else:
        # Logarithmic segments (exponents 1-7)
        exponent = 1
        temp = sample >> 5  # Start with sample/32
        while temp > 0 and exponent < 7:
            temp >>= 1
            exponent += 1
        
        # Calculate mantissa for this exponent
        mantissa = (sample >> (exponent + 1)) & 0x0F
    
    # Combine components
    alaw = sign | (exponent << 4) | mantissa
    
    # XOR with 0x55 to invert even bits (A-law specification)
    alaw ^= 0x55
    
    return alaw & 0xFF

def pcm_to_alaw(pcm_data: bytes) -> bytes:
    """Convert 16-bit PCM to A-law using standard G.711 A-law."""
    try:
        # Unpack PCM data
        sample_count = len(pcm_data) // 2
        pcm_samples = struct.unpack(f'<{sample_count}h', pcm_data)
        
        alaw_bytes = []
        for sample in pcm_samples:
            # Use standard G.711 A-law compression - no pre-attenuation needed
            # Just clamp to valid range
            sample = max(-32768, min(32767, sample))
            alaw_byte = linear_to_alaw(sample)
            alaw_bytes.append(alaw_byte)
        
        alaw_data = bytes(alaw_bytes)
        logger.debug(f"Converted {len(pcm_data)} PCM bytes to {len(alaw_data)} A-law bytes (standard G.711)")
        return alaw_data
        
    except Exception as e:
        logger.error(f"Error converting PCM to A-law: {e}")
        return b'' 

def pcm_to_ulaw(pcm_data: bytes) -> bytes:
    """Convert 16-bit PCM to μ-law using standard G.711 μ-law."""
    try:
        # Unpack PCM data
        sample_count = len(pcm_data) // 2
        pcm_samples = struct.unpack(f'<{sample_count}h', pcm_data)
        
        ulaw_bytes = []
        for sample in pcm_samples:
            # Use standard G.711 μ-law compression - no pre-attenuation needed
            # Just clamp to valid range
            sample = max(-32768, min(32767, sample))
            ulaw_byte = linear_to_ulaw(sample)
            ulaw_bytes.append(ulaw_byte)
        
        ulaw_data = bytes(ulaw_bytes)
        logger.debug(f"Converted {len(pcm_data)} PCM bytes to {len(ulaw_data)} μ-law bytes (standard G.711)")
        return ulaw_data
        
    except Exception as e:
        logger.error(f"Error converting PCM to μ-law: {e}")
        return b''

def pcm_to_g722(pcm_data: bytes) -> bytes:
    """
    Convert 16-bit PCM (16kHz) to G.722 using proper library implementation.
    G.722 is the wideband codec used by Zoho Voice for superior audio.
    """
    try:
        # Import the proper G.722 library
        import G722
        
        # Convert bytes to numpy array for the library
        sample_count = len(pcm_data) // 2
        pcm_samples = struct.unpack(f'<{sample_count}h', pcm_data)
        pcm_array = np.array(pcm_samples, dtype=np.int16)
        
        # Create G.722 encoder and encode
        encoder = G722.Encoder()
        g722_data = encoder.encode(pcm_array)
        
        logger.debug(f"🎯 PROPER G.722 encode: {len(pcm_data)} PCM bytes (16kHz) → {len(g722_data)} G.722 bytes (HD Voice)")
        return bytes(g722_data)
        
    except Exception as e:
        logger.error(f"Error converting PCM to G.722: {e}")
        # Fallback to A-law if G.722 fails
        logger.warning("Falling back to A-law encoding")
        sample_count = len(pcm_data) // 2
        pcm_samples = struct.unpack(f'<{sample_count}h', pcm_data)
        # Downsample to 8kHz for A-law
        pcm_8khz = resample_simple(pcm_data, from_rate=16000, to_rate=8000)
        return pcm_to_alaw(pcm_8khz)

def g722_to_pcm(g722_data: bytes) -> bytes:
    """
    Convert G.722 back to 16-bit PCM (16kHz) using proper library implementation.
    """
    try:
        # Import the proper G.722 library
        import G722
        
        # Create G.722 decoder and decode
        decoder = G722.Decoder()
        pcm_array = decoder.decode(np.frombuffer(g722_data, dtype=np.uint8))
        
        # Convert numpy array back to bytes
        pcm_data = struct.pack(f'<{len(pcm_array)}h', *pcm_array.astype(np.int16))
        
        logger.debug(f"🎯 PROPER G.722 decode: {len(g722_data)} G.722 bytes → {len(pcm_data)} PCM bytes (16kHz)")
        return pcm_data
        
    except Exception as e:
        logger.error(f"Error converting G.722 to PCM: {e}")
        # Fallback - return silence
        return b'\x00\x00' * (len(g722_data) * 2) 

================================================================================

----- FILE: callie_caller/sip/auth.py -----

"""
SIP Authentication for digest authentication with Zoho Voice.
Handles MD5 digest calculation and authentication header parsing.
"""

import hashlib
import random
import logging
from typing import Optional, Dict

from callie_caller.config.settings import Settings

logger = logging.getLogger(__name__)

class SipAuthenticator:
    """
    Handles SIP Digest Authentication for Zoho Voice.
    """
    
    def __init__(self, settings: Settings):
        self.settings = settings
        
    def create_register_request(self, local_ip: str, public_ip: Optional[str], local_port: int, call_id: str, from_tag: str, cseq: int, auth_header: Optional[str] = None) -> str:
        """
        Create a full REGISTER request, either initial or authenticated.
        """
        branch = f"z9hG4bK-{random.randint(100000, 999999)}"
        
        # Use the public IP in the 'received' part of the Via header if available.
        # The 'rport' parameter asks the server to respond to the port it received the request from.
        via_header = f"Via: SIP/2.0/UDP {local_ip}:{local_port};branch={branch};rport"
        if public_ip:
            via_header += f";received={public_ip}"

        contact_ip = public_ip or local_ip
        
        headers = [
            f"REGISTER sip:{self.settings.zoho.sip_server} SIP/2.0",
            via_header,
            "Max-Forwards: 70",
            f"Contact: <sip:{self.settings.zoho.sip_username}@{contact_ip}:{local_port}>",
            f"To: <sip:{self.settings.zoho.sip_username}@{self.settings.zoho.sip_server}>",
            f"From: <sip:{self.settings.zoho.sip_username}@{self.settings.zoho.sip_server}>;tag={from_tag}",
            f"Call-ID: {call_id}",
            f"CSeq: {cseq} REGISTER",
            "Expires: 3600",
            f"User-Agent: {self.settings.device.user_agent}"
        ]

        if auth_header:
            auth_response = self.calculate_auth_response(
                method="REGISTER",
                uri=f"sip:{self.settings.zoho.sip_server}",
                auth_header=auth_header
            )
            auth_header_name = "Proxy-Authorization" if "proxy-authenticate" in auth_header.lower() else "Authorization"
            headers.append(f"{auth_header_name}: {auth_response}")
            
        headers.append("Content-Length: 0")
        
        return "\r\n".join(headers) + "\r\n\r\n"

    def calculate_auth_response(self, method: str, uri: str, auth_header: str) -> str:
        """
        Calculate the Digest authentication response.
        """
        params = self._parse_auth_header(auth_header)
        realm = params.get("realm")
        nonce = params.get("nonce")
        
        if not realm or not nonce:
            raise ValueError("Realm or nonce not found in auth header")
            
        ha1 = self._calculate_ha1(realm)
        ha2 = self._calculate_ha2(method, uri)
        response = self._calculate_response(ha1, nonce, ha2)
        
        auth_parts = {
            "username": f'"{self.settings.zoho.sip_username}"',
            "realm": f'"{realm}"',
            "nonce": f'"{nonce}"',
            "uri": f'"{uri}"',
            "response": f'"{response}"',
            "algorithm": "MD5"
        }
        
        return "Digest " + ", ".join(f'{k}={v}' for k, v in auth_parts.items())

    def _parse_auth_header(self, header: str) -> Dict[str, str]:
        """Parse the WWW-Authenticate or Proxy-Authenticate header."""
        # Remove "Digest " prefix
        if header.strip().lower().startswith("digest "):
            header = header.strip()[7:]
            
        parts = [p.strip() for p in header.split(',')]
        return {key: value.strip('"') for key, value in (p.split('=', 1) for p in parts)}
        
    def _calculate_ha1(self, realm: str) -> str:
        """Calculate HA1 for Digest authentication."""
        return hashlib.md5(f"{self.settings.zoho.sip_username}:{realm}:{self.settings.zoho.sip_password}".encode()).hexdigest()
        
    def _calculate_ha2(self, method: str, uri: str) -> str:
        """Calculate HA2 for Digest authentication."""
        return hashlib.md5(f"{method}:{uri}".encode()).hexdigest()
        
    def _calculate_response(self, ha1: str, nonce: str, ha2: str) -> str:
        """Calculate the final response for Digest authentication."""
        return hashlib.md5(f"{ha1}:{nonce}:{ha2}".encode()).hexdigest() 

================================================================================

----- FILE: callie_caller/sip/call.py -----

"""
SIP Call management for individual voice calls.
Handles call state, SIP message generation, and call lifecycle.
"""

import time
import random
import logging
from enum import Enum
from typing import Optional, Dict
from dataclasses import dataclass, field

from callie_caller.config.settings import Settings
from .sdp import AudioParams
from .auth import SipAuthenticator


logger = logging.getLogger(__name__)

class CallState(Enum):
    """SIP call states."""
    IDLE = "idle"
    CALLING = "calling" 
    RINGING = "ringing"
    CONNECTED = "connected"
    ENDED = "ended"
    FAILED = "failed"

@dataclass
class SipCall:
    """Represents a single SIP call."""
    call_id: str
    local_ip: str
    public_ip: Optional[str]
    local_port: int
    settings: Settings
    authenticator: SipAuthenticator
    target_number: str
    ai_message: Optional[str] = None
    state: CallState = CallState.IDLE
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    tag: Optional[str] = None
    branch: Optional[str] = None
    rtp_port: Optional[int] = None
    cseq: int = 1
    headers: Dict[str, str] = field(default_factory=dict)
    remote_audio_params: Optional[AudioParams] = None
    
    def __post_init__(self):
        """Initialize call after creation."""
        self.tag = f"tag-{random.randint(1000, 9999)}"
        self.branch = f"z9hG4bK-{random.randint(100000, 999999)}"
        self.start_time = time.time()
        self.state = CallState.CALLING
        
    @property
    def duration(self) -> float:
        """Get call duration in seconds."""
        if self.start_time:
            end = self.end_time or time.time()
            return end - self.start_time
        return 0.0
        
    @property
    def invite_uri(self) -> str:
        """Get the INVITE URI for this call."""
        return f"sip:{self.target_number}@{self.settings.zoho.sip_server}"
        
    @property
    def from_header(self) -> str:
        """Get the From header for this call."""
        display_name = self.settings.zoho.account_label or "AI Agent"
        return f'"{display_name}" <sip:{self.settings.zoho.sip_username}@{self.settings.zoho.sip_server}>;tag={self.tag}'
        
    @property
    def to_header(self) -> str:
        """Get the To header for this call."""
        return f"<sip:{self.target_number}@{self.settings.zoho.sip_server}>"
        
    @property
    def contact_header(self) -> str:
        """Get the Contact header for this call."""
        contact_ip = self.public_ip or self.local_ip
        return f"<sip:{self.settings.zoho.sip_username}@{contact_ip}:{self.local_port}>"
        
    def create_sdp_content(self) -> str:
        """
        Create SDP (Session Description Protocol) content for audio.
        Crucially, this uses the PUBLIC IP so the remote party knows where to send audio.
        """
        audio_port = self.rtp_port if self.rtp_port else (self.local_port + 1000)
        session_id = int(time.time())
        sdp_ip = self.public_ip or self.local_ip
        
        sdp = f"""v=0
o=- {session_id} {session_id} IN IP4 {sdp_ip}
s=Yealink SIP Session
c=IN IP4 {sdp_ip}
t=0 0
m=audio {audio_port} RTP/AVP 18 0 8 101
a=rtpmap:18 G729/8000
a=rtpmap:0 PCMU/8000
a=rtpmap:8 PCMA/8000
a=rtpmap:101 telephone-event/8000
a=fmtp:101 0-15
a=sendrecv
"""
        return sdp
        
    def create_invite_message(self) -> str:
        """Create initial SIP INVITE message."""
        sdp_content = self.create_sdp_content()
        
        via_header = f"Via: SIP/2.0/UDP {self.local_ip}:{self.local_port};branch={self.branch};rport"
        if self.public_ip:
            via_header += f";received={self.public_ip}"
        
        return f"""INVITE {self.invite_uri} SIP/2.0
{via_header}
Max-Forwards: 70
Contact: {self.contact_header}
To: {self.to_header}
From: {self.from_header}
Call-ID: {self.call_id}
CSeq: {self.cseq} INVITE
Allow: INVITE,ACK,OPTIONS,CANCEL,BYE,SUBSCRIBE,NOTIFY,INFO,REFER,UPDATE
Content-Type: application/sdp
Accept: application/sdp
User-Agent: {self.settings.device.user_agent}
Supported: timer,replaces
Content-Length: {len(sdp_content)}

{sdp_content}"""
        
    def create_authenticated_invite_message(self, auth_header: str, is_proxy_auth: bool = False) -> str:
        """
        Create authenticated SIP INVITE message.
        """
        sdp_content = self.create_sdp_content()
        auth_header_name = "Proxy-Authorization" if is_proxy_auth else "Authorization"
        
        auth_response = self.authenticator.calculate_auth_response(
            method="INVITE",
            uri=self.invite_uri,
            auth_header=auth_header
        )

        via_header = f"Via: SIP/2.0/UDP {self.local_ip}:{self.local_port};branch={self.branch}-auth;rport"
        if self.public_ip:
            via_header += f";received={self.public_ip}"

        return f"""INVITE {self.invite_uri} SIP/2.0
{via_header}
Max-Forwards: 70
Contact: {self.contact_header}
To: {self.to_header}
From: {self.from_header}
Call-ID: {self.call_id}
CSeq: {self.cseq} INVITE
{auth_header_name}: {auth_response}
Allow: INVITE,ACK,OPTIONS,CANCEL,BYE,SUBSCRIBE,NOTIFY,INFO,REFER,UPDATE
Content-Type: application/sdp
Accept: application/sdp
User-Agent: {self.settings.device.user_agent}
Supported: timer,replaces
Content-Length: {len(sdp_content)}

{sdp_content}"""
        
    def create_ack_message(self) -> str:
        """Create ACK message to complete call setup."""
        # CSeq for ACK should match the INVITE it's acknowledging
        return f"""ACK {self.invite_uri} SIP/2.0
Via: SIP/2.0/UDP {self.local_ip}:{self.local_port};branch={self.branch}-ack
Max-Forwards: 70
To: {self.to_header}
From: {self.from_header}
Call-ID: {self.call_id}
CSeq: {self.cseq} ACK
User-Agent: {self.settings.device.user_agent}
Content-Length: 0

"""
        
    def create_bye_message(self) -> str:
        """Create BYE message to end the call."""
        self.cseq += 1
        return f"""BYE {self.invite_uri} SIP/2.0
Via: SIP/2.0/UDP {self.local_ip}:{self.local_port};branch={self.branch}-bye
Max-Forwards: 70
To: {self.to_header}
From: {self.from_header}
Call-ID: {self.call_id}
CSeq: {self.cseq} BYE
User-Agent: {self.settings.device.user_agent}
Content-Length: 0

"""
        
    def hangup(self) -> None:
        """End the call and update state."""
        if self.state not in [CallState.ENDED, CallState.FAILED]:
            logger.info(f"📞 Hanging up call {self.call_id}")
            self.state = CallState.ENDED
            self.end_time = time.time()
            logger.info(f"Call {self.call_id} ended after {self.duration:.1f} seconds")
            
    def answer(self) -> None:
        """Mark call as answered/connected."""
        if self.state in [CallState.CALLING, CallState.RINGING]:
            self.state = CallState.CONNECTED
            logger.info(f"Call {self.call_id} answered")
            
    def fail(self, reason: str = "Unknown") -> None:
        """Mark call as failed."""
        if self.state != CallState.FAILED:
            self.state = CallState.FAILED
            self.end_time = time.time()
            logger.error(f"Call {self.call_id} failed: {reason}")
        
    def set_ringing(self) -> None:
        """Mark call as ringing."""
        if self.state == CallState.CALLING:
            self.state = CallState.RINGING
            logger.info(f"Call {self.call_id} is ringing")
            
    def get_ai_message(self) -> str:
        """Get the AI message for this call."""
        return self.ai_message or self.settings.calls.default_greeting 

================================================================================

----- FILE: callie_caller/sip/client.py -----

"""
SIP Client for Yealink phone emulation.
Handles SIP registration, call management, and authentication with Zoho Voice.
"""

import socket
import time
import random
import logging
import asyncio
import threading
from typing import Optional, Callable, Dict, Any, List

from callie_caller.config import get_settings
from callie_caller.utils.network import get_public_ip
from callie_caller.sip.auth import SipAuthenticator
from callie_caller.sip.call import SipCall, CallState
from callie_caller.sip.sdp import extract_audio_params_from_sip_response
from callie_caller.sip.rtp import RtpHandler
from callie_caller.sip.rtp_bridge import RtpBridge
from callie_caller.ai import AudioBridge
from .parser import SipResponse, parse_sip_response

logger = logging.getLogger(__name__)

class SipClient:
    """
    Main SIP client for Yealink phone emulation.
    Handles registration, authentication, call management, and RTP audio.
    """
    
    def __init__(self, on_incoming_call: Optional[Callable[[SipCall], None]] = None):
        """
        Initialize SIP client.
        
        Args:
            on_incoming_call: Callback for handling incoming calls
        """
        self.settings = get_settings()
        self.authenticator = SipAuthenticator(self.settings)
        self.on_incoming_call = on_incoming_call
        
        self.socket: Optional[socket.socket] = None
        self.local_ip: Optional[str] = None
        self.public_ip: Optional[str] = None
        self.local_port: Optional[int] = None
        self.running = False
        self.registered = False
        self.active_calls: Dict[str, SipCall] = {}
        
        # Threading for message handling
        self._listener_thread: Optional[threading.Thread] = None
        self._response_events: Dict[str, threading.Event] = {}
        self._received_responses: Dict[str, SipResponse] = {}
        
        # RTP and audio handling
        self.rtp_bridge: Optional[RtpBridge] = None
        self.audio_bridge: Optional[AudioBridge] = None
        self._conversation_task: Optional[asyncio.Task] = None
        
    async def start_audio_conversation(self, call: SipCall, initial_message: Optional[str] = None) -> None:
        """
        Start real-time audio conversation for a connected call.
        
        Args:
            call: The active SIP call
            initial_message: Optional initial AI message
        """
        if call.state not in [CallState.CONNECTED, CallState.RINGING]:
            logger.warning(f"Cannot start conversation for call in state: {call.state}")
            return
            
        logger.info(f"🎤 Starting AI audio conversation for call {call.call_id}")
        
        try:
            # Initialize audio bridge if not already done
            if not self.audio_bridge:
                self.audio_bridge = AudioBridge()
                # Store reference to current event loop for sync callbacks
                self.audio_bridge._loop = asyncio.get_event_loop()
                
            # Connect the RTP bridge to the AI audio bridge
            if self.rtp_bridge:
                logger.info("🔗 Connecting RTP Bridge to AI...")
                
                # Connect audio pipeline  
                def rtp_to_ai_callback(audio_data: bytes, source: str):
                    """Callback to send RTP audio to AI"""
                    if self.audio_bridge and source == "caller":
                        self.audio_bridge.send_sip_audio_sync(audio_data)
                
                def ai_to_rtp_callback(ai_audio: bytes):
                    """Callback to send AI audio to RTP"""
                    logger.info(f"🤖 AI callback received {len(ai_audio)} bytes - forwarding to RTP bridge")
                    if self.rtp_bridge:
                        # Check if we're in test mode
                        if hasattr(self.rtp_bridge, 'test_mode') and self.rtp_bridge.test_mode:
                            # Inject test audio instead of AI audio
                            test_packet = self.rtp_bridge.get_test_audio_packet()
                            if test_packet:
                                logger.info(f"🧪 Injecting test audio packet instead of AI audio")
                                self.rtp_bridge.send_ai_audio(test_packet, target="caller")
                            return
                        
                        self.rtp_bridge.send_ai_audio(ai_audio, target="caller")
                    else:
                        logger.error("❌ No RTP bridge available for AI audio")
                
                # Set up RTP Bridge → AI callback (user's voice to AI)
                self.rtp_bridge.set_audio_callback(rtp_to_ai_callback)
                
                # Set up AI → RTP Bridge callback (AI's voice to user)
                if self.audio_bridge:
                    self.audio_bridge.set_sip_audio_callback(ai_to_rtp_callback)
                logger.info("✅ Audio pipeline connected: RTP Bridge ↔ AI ↔ RTP Bridge")

            # Start the conversation
            self._conversation_task = asyncio.create_task(
                self.audio_bridge.start_conversation(initial_message)
            )
            
            logger.info("🎵 Live AI conversation started!")
            
        except Exception as e:
            logger.error(f"Failed to start audio conversation: {e}")
    
    async def stop_audio_conversation(self) -> None:
        """Stop the active audio conversation."""
        if self.audio_bridge:
            await self.audio_bridge.stop_conversation()
            
        if self._conversation_task and not self._conversation_task.done():
            self._conversation_task.cancel()
            
        logger.info("🔇 Audio conversation stopped")

    def start(self) -> bool:
        """Start the SIP client and its message listener."""
        try:
            # Discover public IP for NAT traversal
            self.public_ip = get_public_ip()
            
            # Create UDP socket
            self.socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            
            # Get local IP and bind to dynamic port
            self.local_ip = self._get_local_ip()
            self.socket.bind((self.local_ip, 0))
            self.local_port = self.socket.getsockname()[1]
            
            logger.info(f"SIP client started on {self.local_ip}:{self.local_port} (Public: {self.public_ip})")
            logger.info(f"Emulating: {self.settings.device.user_agent}")
            
            # Start the background listener thread
            self.running = True
            self._listener_thread = threading.Thread(target=self._message_listener_loop, daemon=True)
            self._listener_thread.start()
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to start SIP client: {e}")
            return False
    
    def register(self) -> bool:
        """Register with SIP server with authentication."""
        logger.info(f"Registering with {self.settings.zoho.sip_server}")
        
        # Create initial REGISTER message
        call_id = f"reg-{random.randint(100000, 999999)}-{int(time.time())}"
        from_tag = f"tag-{random.randint(1000, 9999)}"
        cseq = 1
        
        register_msg = self.authenticator.create_register_request(
            local_ip=self.local_ip,
            public_ip=self.public_ip,
            local_port=self.local_port,
            call_id=call_id,
            from_tag=from_tag,
            cseq=cseq
        )
        
        try:
            # Send initial REGISTER and wait for 401/407 response
            response = self._send_request_and_wait(f"{cseq} REGISTER", register_msg)
            
            if not response:
                logger.error("No response to initial REGISTER request")
                return False
                
            if response.status_code not in [401, 407]:
                logger.error(f"Unexpected response to REGISTER: {response.status_code} {response.status_text}")
                return False

            # We received a challenge, now create and send an authenticated REGISTER
            logger.info("Authentication required, sending authenticated REGISTER...")
            cseq += 1
            auth_header = response.headers.get('www-authenticate') or response.headers.get('proxy-authenticate')
            
            auth_register_msg = self.authenticator.create_register_request(
                local_ip=self.local_ip,
                public_ip=self.public_ip,
                local_port=self.local_port,
                call_id=call_id,
                from_tag=from_tag,
                cseq=cseq,
                auth_header=auth_header
            )
            
            # Send authenticated REGISTER and wait for 200 OK
            final_response = self._send_request_and_wait(f"{cseq} REGISTER", auth_register_msg)
            
            if final_response and final_response.status_code == 200:
                logger.info("✅ SIP registration successful!")
                self.registered = True
                return True
            else:
                status = f"{final_response.status_code} {final_response.status_text}" if final_response else "No Response"
                logger.error(f"❌ SIP registration failed. Final response: {status}")
                return False
                
        except Exception as e:
            logger.error(f"Registration failed: {e}", exc_info=True)
            return False

    def make_call(self, call: SipCall) -> bool:
        """
        Make an outbound call. This is a blocking operation until the call is
        connected or fails.
        
        Args:
            call: SipCall object with call details
            
        Returns:
            bool: True if call was successfully connected, False otherwise
        """
        logger.info(f"Making call to {call.target_number}")
        self.active_calls[call.call_id] = call
        
        try:
            # Step 1: Start RTP bridge BEFORE sending INVITE
            logger.info("🌉 Starting RTP bridge for media relay...")
            self.rtp_bridge = RtpBridge(self.local_ip)
            bridge_port = self.rtp_bridge.start_bridge()
            if not bridge_port:
                logger.error("❌ Failed to start RTP bridge")
                return False
            logger.info(f"🌉 RTP bridge listening on {self.local_ip}:{bridge_port}")
            
            # Step 2: Configure call to use bridge port in SDP
            call.rtp_port = bridge_port
            
            # Step 3: Send initial INVITE
            invite_msg = call.create_invite_message()
            response = self._send_request_and_wait(f"{call.cseq} INVITE", invite_msg)
            
            # Step 4: Handle authentication if required
            if response and response.status_code in [401, 407]:
                logger.info("Authentication required for call, sending authenticated INVITE...")
                call.cseq += 1
                auth_header = response.headers.get('www-authenticate') or response.headers.get('proxy-authenticate')
                
                auth_invite = call.create_authenticated_invite_message(
                    auth_header=auth_header,
                    is_proxy_auth=(response.status_code == 407)
                )
                # Don't wait here, the response will be handled by the main listener
                self._send_message(auth_invite)

            elif response and response.status_code >= 400:
                logger.error(f"Call failed with initial response: {response.status_code} {response.status_text}")
                call.fail(f"Initial error: {response.status_code}")
                return False
                
            # Step 5: Wait for the call to be connected
            return self._wait_for_call_to_connect(call)

        except Exception as e:
            logger.error(f"Call initiation failed: {e}", exc_info=True)
            call.fail(f"Initiation error: {e}")
            if self.rtp_bridge:
                self.rtp_bridge.stop_bridge()
                self.rtp_bridge = None
            return False

    def _wait_for_call_to_connect(self, call: SipCall) -> bool:
        """Waits for a 18x or 200 response to an INVITE."""
        call_setup_timeout = 60 
        start_time = time.time()

        logger.info("⏳ Waiting for call to connect...")
        while time.time() - start_time < call_setup_timeout:
            if call.state == CallState.CONNECTED:
                break
            if call.state in [CallState.FAILED, CallState.ENDED]:
                logger.error(f"❌ Call entered terminal state {call.state.value} while waiting to connect.")
                return False
            time.sleep(0.2) # <-- CRUCIAL: Give listener thread time to process messages

        if call.state == CallState.CONNECTED:
            logger.info("🎉 Call Answered and Connected!")
            
            # Send ACK for the 200 OK
            ack_msg = call.create_ack_message()
            self._send_message(ack_msg)
            
            # Configure RTP bridge with remote endpoint from 200 OK's SDP
            if call.remote_audio_params and self.rtp_bridge:
                logger.info(f"🎤 Remote audio endpoint: {call.remote_audio_params.ip_address}:{call.remote_audio_params.port}")
                self.rtp_bridge.set_remote_endpoint(call.remote_audio_params)
                bridge_port = self.rtp_bridge.get_bridge_port()
                logger.info(f"🌉 RTP bridge configured for media path: Phone ↔️ Bridge ({bridge_port}) ↔️ Remote")
                
                # Log SDP configuration for debugging
                logger.info(f"📋 SDP Configuration Summary:")
                logger.info(f"   • Bridge listening on: ALL INTERFACES:{bridge_port}")
                logger.info(f"   • SDP advertised: {call.public_ip or call.local_ip}:{bridge_port}")
                logger.info(f"   • Remote sends to: {call.remote_audio_params.ip_address}:{call.remote_audio_params.port}")
                logger.info(f"   • NAT Traversal: {'ENABLED' if call.public_ip else 'LOCAL ONLY'}")
                
                # Start test audio injection if test mode is enabled
                self._start_test_audio_injection_when_connected()
            else:
                logger.warning("⚠️ No remote audio params found, RTP bridge may not work.")
                
            return True
        else:
            logger.error(f"❌ Call failed to connect. Final state: {call.state.value}")
            return False

    def stop(self) -> None:
        """Stop the SIP client and cleanup."""
        logger.info("Stopping SIP client...")
        self.running = False
        
        if self.rtp_bridge:
            self.rtp_bridge.stop_bridge()
        
        if self.socket:
            self.socket.close()
            
        if self._listener_thread and self._listener_thread.is_alive():
            self._listener_thread.join(timeout=2)
        
        logger.info("SIP client stopped")

    def _send_request_and_wait(self, cseq_key: str, message: str, timeout: float = 5.0) -> Optional[SipResponse]:
        """Send a request and wait for its corresponding response."""
        event = threading.Event()
        self._response_events[cseq_key] = event
        
        self._send_message(message)
        
        event_was_set = event.wait(timeout)
        
        # Cleanup
        self._response_events.pop(cseq_key, None)
        
        if not event_was_set:
            logger.warning(f"Timeout waiting for response to '{cseq_key}'")
            return None
            
        return self._received_responses.pop(cseq_key, None)

    def _message_listener_loop(self) -> None:
        """Background thread for listening to SIP messages."""
        logger.info("👂 SIP message listener started")
        
        while self.running:
            try:
                self.socket.settimeout(1.0)  # Allow periodic checks
                data, addr = self.socket.recvfrom(4096)
                message = data.decode('utf-8')
                
                logger.debug(f"📨 Received from {addr}: {message[:200]}...")
                
                # Parse the message
                response = parse_sip_response(message)
                if response:
                    # Handle responses to our requests
                    cseq_key = response.headers.get('cseq', 'unknown')
                    logger.debug(f"📨 Response: {response.status_code} {response.status_text} for {cseq_key}")
                    
                    # Store the response for waiting threads
                    if cseq_key in self._response_events:
                        self._received_responses[cseq_key] = response
                        self._response_events[cseq_key].set()
                    
                    # Update call states
                    call_id = response.headers.get('call-id')
                    if call_id and call_id in self.active_calls:
                        call = self.active_calls[call_id]
                        self._handle_response_for_call(call, response)
                else:
                    # Check if it's a BYE request (call termination)
                    if message.startswith('BYE '):
                        logger.info("📞 Received BYE - call terminated by remote party")
                        self._handle_bye_request(message)
                    elif message.startswith('CANCEL '):
                        logger.info("📞 Received CANCEL - call cancelled by remote party")
                        self._handle_cancel_request(message)
                    else:
                        logger.debug(f"📨 Non-response message: {message[:50]}...")
                
            except socket.timeout:
                # Check for dead calls periodically
                self._check_call_states()
                continue
            except Exception as e:
                if self.running:
                    logger.error(f"Error in message listener: {e}")
                break
        
        logger.info("👂 SIP message listener stopped")
    
    def _check_call_states(self) -> None:
        """Check for calls that should be considered ended."""
        current_time = time.time()
        dead_calls = []
        
        for call_id, call in self.active_calls.items():
            # Mark calls as ended if they've been in limbo too long
            if call.state == CallState.CONNECTED:
                # Check if call has been silent too long (no recent activity)
                if current_time - call.start_time > 300:  # 5 minutes max call
                    logger.warning(f"⏰ Call {call_id} exceeded maximum duration, marking as ended")
                    call.state = CallState.ENDED
                    dead_calls.append(call_id)
            elif call.state in [CallState.CALLING, CallState.RINGING]:
                # Timeout hanging calls
                if current_time - call.start_time > 60:  # 1 minute timeout
                    logger.warning(f"⏰ Call {call_id} timed out, marking as failed")
                    call.state = CallState.FAILED
                    dead_calls.append(call_id)
        
        # Clean up dead calls
        for call_id in dead_calls:
            del self.active_calls[call_id]
    
    def _handle_bye_request(self, message: str) -> None:
        """Handle incoming BYE request."""
        try:
            # Extract Call-ID from BYE message
            lines = message.split('\n')
            call_id = None
            for line in lines:
                if line.startswith('Call-ID:'):
                    call_id = line.split(':', 1)[1].strip()
                    break
            
            if call_id and call_id in self.active_calls:
                call = self.active_calls[call_id]
                call.state = CallState.ENDED
                call.end_time = time.time()
                logger.info(f"📞 Call {call_id} ended by remote party")
                
                # Send 200 OK response to BYE
                bye_response = f"""SIP/2.0 200 OK
Via: SIP/2.0/UDP {self.local_ip}:{self.local_port}
Call-ID: {call_id}
Content-Length: 0

"""
                self._send_message(bye_response)
                
        except Exception as e:
            logger.error(f"Error handling BYE request: {e}")
    
    def _handle_cancel_request(self, message: str) -> None:
        """Handle incoming CANCEL request."""
        try:
            # Extract Call-ID from CANCEL message
            lines = message.split('\n')
            call_id = None
            for line in lines:
                if line.startswith('Call-ID:'):
                    call_id = line.split(':', 1)[1].strip()
                    break
            
            if call_id and call_id in self.active_calls:
                call = self.active_calls[call_id]
                call.state = CallState.ENDED
                call.end_time = time.time()
                logger.info(f"📞 Call {call_id} cancelled by remote party")
                
        except Exception as e:
            logger.error(f"Error handling CANCEL request: {e}")

    def _dispatch_message(self, message: str, addr: tuple) -> None:
        """Parse and route incoming SIP messages."""
        # Only log full messages in debug mode
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(f"--- INCOMING SIP MESSAGE from {addr} ---\n{message}\n--------------------")
        
        first_line = message.split('\r\n')[0]
        
        # Log message type in production
        if not logger.isEnabledFor(logging.DEBUG):
            logger.info(f"Received SIP: {first_line.split()[0] if first_line else 'Unknown'} from {addr[0]}")
        
        if first_line.startswith('SIP/2.0'):
            # This is a response
            self._handle_sip_response(message, addr)
        else:
            # This is a request
            self._handle_sip_request(message, addr)

    def _handle_sip_response(self, message: str, addr: tuple) -> None:
        """Handle SIP response messages."""
        response = parse_sip_response(message)
        if not response:
            return
            
        cseq_header = response.headers.get("cseq", "")
        
        # Wake up the thread waiting for this response
        if cseq_header in self._response_events:
            self._received_responses[cseq_header] = response
            self._response_events[cseq_header].set()
        
        # Handle responses that also change call state (e.g., 200 OK to INVITE)
        call_id = response.headers.get("call-id")
        if call_id and call_id in self.active_calls:
            self._handle_response_for_call(self.active_calls[call_id], response)

    def _handle_sip_request(self, message: str, addr: tuple) -> None:
        """Handle SIP request messages."""
        response = parse_sip_response(message)  # Use the same parser for requests
        if not response: 
            return  # It will fail parsing the status line, but that's ok
        
        call_id = response.headers.get("call-id")
        call = self.active_calls.get(call_id)
        if not call: 
            return

        first_line = message.split('\r\n')[0]
        method = first_line.split()[0]
        if method == "BYE":
            self._handle_bye(call, response.headers)
        elif method == "CANCEL":
            self._handle_cancel(call, response.headers)

    def _handle_response_for_call(self, call: SipCall, response: SipResponse):
        """Update call state based on a SIP response."""
        if response.status_code == 180 or response.status_code == 183:
            logger.info(f"Phone is ringing ({response.status_code} {response.status_text})...")
            call.set_ringing()
        
        elif response.status_code == 200 and "INVITE" in response.headers.get("cseq", ""):
            if response.body:
                call.remote_audio_params = extract_audio_params_from_sip_response(response.body)
            call.answer()
            
        elif response.status_code >= 400:
            # IMPORTANT: Don't fail the call if it's an auth challenge,
            # as the main thread will handle re-sending with auth.
            if response.status_code not in [401, 407]:
                logger.error(f"Call failed with status: {response.status_code} {response.status_text}")
                call.fail(f"{response.status_code} {response.status_text}")
            else:
                logger.info(f"Received auth challenge ({response.status_code}), letting main thread handle it.")
    
    def _handle_bye(self, call: SipCall, headers: Dict[str, str]):
        """Handle an incoming BYE request."""
        logger.info(f"📞 Call terminated by remote party (BYE received) for call {call.call_id}")
        
        # Acknowledge the BYE with a 200 OK
        try:
            # Use the headers from the incoming BYE to construct the response
            to_header = headers.get("from")
            from_header = headers.get("to")
            
            # Create a basic response
            response = [
                "SIP/2.0 200 OK",
                headers.get("via", ""),
                f"To: {to_header}",
                f"From: {from_header}",
                f"Call-ID: {call.call_id}",
                f"CSeq: {headers.get('cseq')}",
                "Content-Length: 0",
                ""
            ]
            
            self._send_message("\r\n".join(response))
            logger.info("✅ Sent 200 OK for BYE")
            
        except Exception as e:
            logger.error(f"Failed to send 200 OK for BYE: {e}")
            
        # Finally, end the call internally
        call.hangup()
        
    def _handle_cancel(self, call: SipCall, headers: Dict[str, str]):
        """Handle an incoming CANCEL request."""
        logger.info(f"📞 Call cancelled by remote party (CANCEL received) for call {call.call_id}")
        call.hangup()
        # A full implementation would also send a 487 Request Terminated to the original INVITE
        # and a 200 OK to the CANCEL. For now, hanging up is sufficient.

    def _send_message(self, message: str) -> None:
        """Send a SIP message."""
        if not self.socket or not self.running:
            raise RuntimeError("SIP client not started or is stopped")
        
        # Only log full messages in debug mode
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(f"--- OUTGOING SIP MESSAGE to {self.settings.zoho.sip_server} ---\n{message}\n--------------------")
        else:
            # In production, just log the message type
            first_line = message.split('\n')[0] if message else ''
            logger.info(f"Sending SIP: {first_line}")
            
        self.socket.sendto(
            message.encode(),
            (self.settings.zoho.sip_server, self.settings.zoho.sip_port)
        )
        
    def _get_local_ip(self) -> str:
        """Get local IP address that can reach the SIP server."""
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
                s.connect((self.settings.zoho.sip_server, self.settings.zoho.sip_port))
                return s.getsockname()[0]
        except Exception:
            return "127.0.0.1" 

    def terminate_call(self, call: SipCall) -> bool:
        """Properly terminate a call by sending BYE message."""
        try:
            if call.state in [CallState.CONNECTED, CallState.RINGING]:
                logger.info(f"📞 Terminating call {call.call_id}")
                
                # Create and send BYE message
                bye_msg = call.send_bye()
                if bye_msg:
                    self._send_message(bye_msg)
                    logger.info(f"📤 Sent BYE for call {call.call_id}")
                
                # Remove from active calls
                if call.call_id in self.active_calls:
                    del self.active_calls[call.call_id]
                
                # Stop RTP bridge if this was the last call
                if not self.active_calls and self.rtp_bridge:
                    self.rtp_bridge.stop_bridge()
                    self.rtp_bridge = None
                    logger.info("🔇 RTP bridge stopped - no active calls")
                
                return True
            else:
                logger.warning(f"⚠️  Cannot terminate call {call.call_id} in state {call.state.value}")
                return False
                
        except Exception as e:
            logger.error(f"❌ Error terminating call {call.call_id}: {e}")
            return False 

    def stop_client(self) -> None:
        """Stop the SIP client and clean up resources."""
        logger.info("Stopping SIP client...")
        
        # Stop RTP bridge first
        if self.rtp_bridge:
            self.rtp_bridge.stop_bridge()
            self.rtp_bridge = None
        
        # Close socket and stop listener
        self.running = False
        if self.socket:
            self.socket.close()
            
        logger.info("SIP client stopped")
    
    def enable_test_mode(self, test_audio_file: str = None) -> bool:
        """Enable test mode to inject known audio instead of AI audio."""
        if self.rtp_bridge:
            success = self.rtp_bridge.enable_test_mode(test_audio_file)
            if success:
                # Don't start injection here - wait for call to connect
                logger.info("🧪 Test mode enabled - will inject audio when call connects")
            return success
        return False
    
    def _start_test_audio_injection_when_connected(self) -> None:
        """Start test audio injection once the call is connected."""
        if (self.rtp_bridge and 
            hasattr(self.rtp_bridge, 'test_mode') and 
            self.rtp_bridge.test_mode):
            
            logger.info("🧪 Call connected - starting test audio injection")
            self.rtp_bridge.start_test_audio_injection()
        else:
            logger.warning("❌ Cannot start test audio - requirements not met") 

    @property
    def current_call(self) -> Optional[SipCall]:
        """Return the currently active call, if any."""
        if self.active_calls:
            # Return the first active call
            return next(iter(self.active_calls.values()), None)
        return None 

================================================================================

----- FILE: callie_caller/sip/parser.py -----

import logging
from typing import Optional, Dict

logger = logging.getLogger(__name__)

# A simple dataclass-like structure would be better, but avoiding new deps for now.
class SipResponse:
    """A simple container for parsed SIP responses."""
    def __init__(self, status_code: int, status_text: str, headers: Dict[str, str], body: str, raw: str):
        self.status_code = status_code
        self.status_text = status_text
        self.headers = headers
        self.body = body
        self.raw = raw

def parse_sip_response(response_str: str) -> Optional[SipResponse]:
    """
    Parse a raw SIP message string (which can be a response or a request)
    into a SipResponse object.
    """
    try:
        lines = response_str.splitlines()
        if not lines:
            return None
            
        # Parse first line (status line for responses, request line for requests)
        first_line = lines[0]
        parts = first_line.split(' ', 2)
        
        status_code = 0
        status_text = ""

        # Check if it's a response (e.g., "SIP/2.0 200 OK")
        if first_line.startswith("SIP/2.0"):
            if len(parts) >= 2:
                status_code = int(parts[1])
                status_text = parts[2] if len(parts) > 2 else ""
        # It's a request (e.g., "BYE sip:...")
        else:
            status_text = first_line # Store the full request line here
        
        # Parse headers
        headers = {}
        body_start_index = 1
        for i, line in enumerate(lines[1:], 1):
            if not line:
                body_start_index = i + 1
                break
            if ':' in line:
                key, value = line.split(':', 1)
                # Standardize header keys to lowercase for consistent access
                headers[key.strip().lower()] = value.strip()
        
        # Extract body
        body = "\r\n".join(lines[body_start_index:])
        
        return SipResponse(
            status_code=status_code,
            status_text=status_text,
            headers=headers,
            body=body,
            raw=response_str
        )
    except Exception as e:
        logger.error(f"Failed to parse SIP message: {e}\n--- Message was ---\n{response_str}\n----------------------", exc_info=True)
        return None 

================================================================================

----- FILE: callie_caller/sip/rtp.py -----

"""
RTP (Real-time Transport Protocol) handler for audio capture and playback.
Handles RTP packet parsing, audio codec conversion, and streaming.
"""

import asyncio
import logging
import socket
import struct
import threading
import time
from typing import Optional, Callable, Dict, Any
from dataclasses import dataclass

from callie_caller.sip.sdp import AudioParams
from callie_caller.sip.audio_codec import ulaw_to_pcm, alaw_to_pcm, pcm_to_ulaw, resample_simple

logger = logging.getLogger(__name__)

@dataclass
class RtpPacket:
    """Parsed RTP packet structure."""
    version: int
    padding: bool
    extension: bool
    csrc_count: int
    marker: bool
    payload_type: int
    sequence_number: int
    timestamp: int
    ssrc: int
    payload: bytes

class RtpHandler:
    """Handles RTP audio stream capture and playback."""
    
    def __init__(self, audio_params: AudioParams):
        """
        Initialize RTP handler.
        
        Args:
            audio_params: Audio parameters from SDP negotiation
        """
        self.audio_params = audio_params
        self.logger = logging.getLogger(__name__)
        
        # RTP sockets
        self.receive_socket: Optional[socket.socket] = None
        self.send_socket: Optional[socket.socket] = None
        
        # Audio processing
        self.audio_callback: Optional[Callable[[bytes], None]] = None
        self.running = False
        
        # Threading
        self.receive_thread: Optional[threading.Thread] = None
        
        # Statistics
        self.packets_received = 0
        self.packets_sent = 0
        self.bytes_received = 0
        self.bytes_sent = 0
        
        # IMPROVED: Audio buffer for jitter handling
        self.audio_buffer = []
        self.buffer_size = 5  # Buffer 5 packets (100ms at 20ms per packet)
        self.last_played_timestamp = 0
        
        # IMPROVED: Proper timestamp tracking
        self._send_timestamp_base = 0
        self._send_samples_sent = 0
        
        self.logger.info(f"RTP handler initialized for {audio_params.ip_address}:{audio_params.port}")
        self.logger.info(f"Available codecs: {[c['codec'] for c in audio_params.codecs]}")
        self.logger.info(f"🔊 Audio buffer enabled: {self.buffer_size} packets (jitter compensation)")
    
    def set_audio_callback(self, callback: Callable[[bytes], None]) -> None:
        """Set callback function for received audio data."""
        self.audio_callback = callback
        self.logger.debug("Audio callback set")
    
    def start(self) -> bool:
        """Start RTP audio capture."""
        if self.running:
            self.logger.warning("RTP handler already running")
            return True
            
        try:
            # Create receive socket
            self.receive_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            self.receive_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            
            # Bind to local port for receiving RTP
            # We'll use a dynamic port since we're sending RTP to the remote side
            self.receive_socket.bind(('', 0))  # Bind to any available port
            local_port = self.receive_socket.getsockname()[1]
            
            self.logger.info(f"🎵 RTP receive socket bound to port {local_port}")
            
            # Create send socket
            self.send_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            
            # Start receive thread
            self.running = True
            self.receive_thread = threading.Thread(
                target=self._receive_loop,
                name="rtp-receiver",
                daemon=True
            )
            self.receive_thread.start()
            
            self.logger.info("🎤 RTP handler started successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to start RTP handler: {e}")
            self.stop()
            return False
    
    def stop(self) -> None:
        """Stop RTP audio capture."""
        self.logger.info("🛑 Stopping RTP handler...")
        self.running = False
        
        if self.receive_socket:
            self.receive_socket.close()
            self.receive_socket = None
            
        if self.send_socket:
            self.send_socket.close()
            self.send_socket = None
            
        if self.receive_thread and self.receive_thread.is_alive():
            self.receive_thread.join(timeout=2)
            
        self.logger.info("✅ RTP handler stopped")
    
    def _receive_loop(self) -> None:
        """Background thread for receiving RTP packets."""
        self.logger.info("🎧 RTP receive loop started")
        
        stats_counter = 0
        
        while self.running and self.receive_socket:
            try:
                # Set timeout to allow for graceful shutdown
                self.receive_socket.settimeout(1.0)
                
                # Receive RTP packet
                data, addr = self.receive_socket.recvfrom(2048)
                self.packets_received += 1
                self.bytes_received += len(data)
                
                # Log first few packets and periodic stats
                if self.packets_received <= 5:
                    self.logger.info(f"🎵 RTP PACKET #{self.packets_received}: {len(data)} bytes from {addr}")
                
                if len(data) < 12:  # Minimum RTP header size
                    self.logger.warning(f"Received short RTP packet: {len(data)} bytes")
                    continue
                
                # Parse RTP packet
                packet = self._parse_rtp_packet(data)
                if not packet:
                    continue
                    
                self.logger.debug(f"📨 RTP packet: PT={packet.payload_type}, seq={packet.sequence_number}, "
                                f"ts={packet.timestamp}, {len(packet.payload)} bytes")
                
                # IMPROVED: Add to buffer for jitter compensation
                if self.audio_callback and packet.payload:
                    self._add_to_audio_buffer(packet)
                    self._process_audio_buffer()
                
            except socket.timeout:
                # Periodic statistics during timeout
                stats_counter += 1
                if stats_counter % 10 == 0:  # Every 10 seconds
                    self.logger.info(f"📊 RTP Stats: {self.packets_received} packets, {self.bytes_received} bytes received")
                    if self.packets_received == 0:
                        self.logger.warning("⚠️  NO RTP PACKETS RECEIVED YET - Audio may not be flowing to our client")
                continue
            except Exception as e:
                if self.running:
                    self.logger.error(f"Error in RTP receive loop: {e}")
                break
        
        self.logger.info(f"🏁 RTP receive loop ended - Final stats: {self.packets_received} packets, {self.bytes_received} bytes")
    
    def _parse_rtp_packet(self, data: bytes) -> Optional[RtpPacket]:
        """Parse RTP packet from raw bytes."""
        try:
            # RTP header is 12 bytes minimum
            if len(data) < 12:
                return None
                
            # Parse fixed header (first 12 bytes)
            header = struct.unpack('!BBHII', data[:12])
            
            byte0 = header[0]
            version = (byte0 >> 6) & 0x3
            padding = bool((byte0 >> 5) & 0x1)
            extension = bool((byte0 >> 4) & 0x1)
            csrc_count = byte0 & 0xF
            
            byte1 = header[1]
            marker = bool((byte1 >> 7) & 0x1)
            payload_type = byte1 & 0x7F
            
            sequence_number = header[2]
            timestamp = header[3]
            ssrc = header[4]
            
            # Skip CSRC identifiers if present
            header_length = 12 + (csrc_count * 4)
            
            # Extract payload
            payload = data[header_length:]
            
            return RtpPacket(
                version=version,
                padding=padding,
                extension=extension,
                csrc_count=csrc_count,
                marker=marker,
                payload_type=payload_type,
                sequence_number=sequence_number,
                timestamp=timestamp,
                ssrc=ssrc,
                payload=payload
            )
            
        except Exception as e:
            self.logger.error(f"Error parsing RTP packet: {e}")
            return None
    
    def _convert_to_pcm(self, audio_data: bytes, payload_type: int) -> Optional[bytes]:
        """Convert audio data to PCM format for AI processing."""
        try:
            # Find codec for this payload type
            codec_info = None
            for codec in self.audio_params.codecs:
                if int(codec["payload"]) == payload_type:
                    codec_info = codec
                    break
            
            if not codec_info:
                self.logger.warning(f"Unknown payload type: {payload_type}")
                return None
            
            codec_name = codec_info["codec"].upper()
            
            # Convert based on codec
            if codec_name == "PCMU":
                # G.711 μ-law to linear PCM
                pcm_data = ulaw_to_pcm(audio_data)
                
            elif codec_name == "PCMA":
                # G.711 A-law to linear PCM  
                pcm_data = alaw_to_pcm(audio_data)
                
            else:
                self.logger.warning(f"Unsupported codec for conversion: {codec_name}")
                return None
            
            # Resample from 8kHz to 16kHz for AI
            resampled = resample_simple(pcm_data, 8000, 16000, 2)
            
            self.logger.debug(f"Converted {len(audio_data)} bytes {codec_name} to {len(resampled)} bytes PCM")
            return resampled
            
        except Exception as e:
            self.logger.error(f"Error converting audio: {e}")
            return None
    
    def send_audio(self, pcm_data: bytes) -> bool:
        """Send PCM audio data as RTP packets."""
        try:
            if not self.send_socket or not self.running:
                return False
            
            # Convert PCM to G.711 μ-law (payload type 0)
            # Resample from 16kHz to 8kHz first
            resampled = resample_simple(pcm_data, 16000, 8000, 2)
            ulaw_data = pcm_to_ulaw(resampled)
            
            # Create RTP packet
            rtp_packet = self._create_rtp_packet(ulaw_data, payload_type=0)
            
            # Send to remote audio endpoint
            self.send_socket.sendto(rtp_packet, (self.audio_params.ip_address, self.audio_params.port))
            
            self.packets_sent += 1
            self.bytes_sent += len(rtp_packet)
            
            self.logger.debug(f"📤 Sent RTP packet: {len(rtp_packet)} bytes")
            return True
            
        except Exception as e:
            self.logger.error(f"Error sending RTP audio: {e}")
            return False
    
    def _create_rtp_packet(self, payload: bytes, payload_type: int = 0) -> bytes:
        """Create RTP packet with audio payload."""
        # IMPROVED: Proper timestamp handling
        if self._send_timestamp_base == 0:
            self._send_timestamp_base = int(time.time() * 8000) % (2**32)
            self._send_samples_sent = 0
            
        # RTP header fields
        version = 2
        padding = 0
        extension = 0
        csrc_count = 0
        marker = 0
        sequence_number = getattr(self, '_sequence_number', 0)
        
        # FIXED: Use sample-based timestamp instead of wall-clock
        timestamp = (self._send_timestamp_base + self._send_samples_sent) & 0xFFFFFFFF
        self._send_samples_sent += len(payload)  # Track samples for accurate timing
        
        ssrc = getattr(self, '_ssrc', 0x12345678)
        
        # Update sequence number
        self._sequence_number = (sequence_number + 1) & 0xFFFF
        
        # Pack RTP header
        byte0 = (version << 6) | (padding << 5) | (extension << 4) | csrc_count
        byte1 = (marker << 7) | payload_type
        
        header = struct.pack('!BBHII', byte0, byte1, sequence_number, timestamp, ssrc)
        
        return header + payload
    
    def _add_to_audio_buffer(self, packet: RtpPacket) -> None:
        """Add RTP packet to jitter buffer."""
        try:
            # Add packet to buffer with timestamp for ordering
            self.audio_buffer.append({
                'packet': packet,
                'arrival_time': time.time(),
                'timestamp': packet.timestamp
            })
            
            # Sort buffer by RTP timestamp to handle out-of-order packets
            self.audio_buffer.sort(key=lambda x: x['timestamp'])
            
            # Remove old packets if buffer is too large
            if len(self.audio_buffer) > self.buffer_size * 2:
                self.audio_buffer = self.audio_buffer[-self.buffer_size:]
                
        except Exception as e:
            self.logger.error(f"Error adding to audio buffer: {e}")
    
    def _process_audio_buffer(self) -> None:
        """Process buffered audio packets to reduce jitter."""
        try:
            # Wait until we have minimum buffer size
            if len(self.audio_buffer) < self.buffer_size:
                return
                
            # Process oldest packet in buffer
            buffered_item = self.audio_buffer.pop(0)
            packet = buffered_item['packet']
            
            # Convert audio format and send to callback
            pcm_audio = self._convert_to_pcm(packet.payload, packet.payload_type)
            if pcm_audio and self.audio_callback:
                self.audio_callback(pcm_audio)
                self.last_played_timestamp = packet.timestamp
                
        except Exception as e:
            self.logger.error(f"Error processing audio buffer: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Get RTP statistics."""
        return {
            "packets_received": self.packets_received,
            "packets_sent": self.packets_sent,
            "bytes_received": self.bytes_received,
            "bytes_sent": self.bytes_sent,
            "running": self.running,
            "audio_params": {
                "ip": self.audio_params.ip_address,
                "port": self.audio_params.port,
                "codecs": self.audio_params.codecs
            }
        } 

================================================================================

----- FILE: callie_caller/sip/rtp_bridge.py -----

"""
RTP Bridge for bidirectional audio forwarding and AI integration.
Acts as a media proxy to capture and forward audio streams.
"""

import socket
import threading
import time
import logging
import os
import atexit
import struct
import wave
from dataclasses import dataclass
from typing import Optional, Callable, Any
from .sdp import AudioParams

logger = logging.getLogger(__name__)

@dataclass
class AudioEndpoint:
    """Represents an audio endpoint for RTP forwarding."""
    ip: str
    port: int
    socket: Optional[Any] = None

class WavRecorder:
    """Helper class for recording audio to WAV files."""
    
    def __init__(self, filename: str, sample_rate: int = 8000, channels: int = 1, sample_width: int = 2):
        self.filename = filename
        self.sample_rate = sample_rate
        self.channels = channels
        self.sample_width = sample_width
        self.wav_file = None
        self.packets_written = 0
        
    def open(self):
        """Open the WAV file for writing."""
        try:
            self.wav_file = wave.open(self.filename, 'wb')
            self.wav_file.setnchannels(self.channels)
            self.wav_file.setsampwidth(self.sample_width)
            self.wav_file.setframerate(self.sample_rate)
            logger.info(f"🎵 Opened WAV file: {self.filename} ({self.sample_rate}Hz, {self.channels}ch)")
        except Exception as e:
            logger.error(f"❌ Failed to open WAV file {self.filename}: {e}")
            
    def write_rtp_packet(self, rtp_data: bytes) -> bool:
        """Decode RTP packet and write PCM audio to WAV file."""
        try:
            if not self.wav_file or len(rtp_data) < 12:
                return False
                
            # Parse RTP header to get payload
            payload_type = rtp_data[1] & 0x7F
            payload = rtp_data[12:]  # Skip 12-byte RTP header
            
            if not payload:
                return False
                
            # Convert RTP payload to PCM
            pcm_data = self._convert_rtp_payload_to_pcm(payload, payload_type)
            if pcm_data:
                self.wav_file.writeframes(pcm_data)
                self.packets_written += 1
                return True
                
        except Exception as e:
            logger.error(f"❌ Error writing RTP to WAV: {e}")
            
        return False
        
    def _convert_rtp_payload_to_pcm(self, payload: bytes, payload_type: int) -> Optional[bytes]:
        """Convert RTP audio payload to PCM format with automatic gain control."""
        try:
            from .audio_codec import ulaw_to_pcm, alaw_to_pcm
            
            # Convert using standard G.711
            if payload_type == 0:  # PCMU (μ-law)
                pcm_data = ulaw_to_pcm(payload)
            elif payload_type == 8:  # PCMA (A-law)  
                pcm_data = alaw_to_pcm(payload)
            else:
                logger.warning(f"Unsupported payload type {payload_type} for WAV recording")
                return None
                
            if not pcm_data:
                return None
                
            # ENHANCED: Apply Automatic Gain Control (AGC) for audible WAV recordings
            pcm_data = self._apply_agc_to_pcm(pcm_data)
            return pcm_data
                
        except Exception as e:
            logger.error(f"Error converting RTP payload: {e}")
            return None
            
    def _apply_agc_to_pcm(self, pcm_data: bytes) -> bytes:
        """Apply Automatic Gain Control (AGC) to make audio audible."""
        try:
            import struct
            import math
            
            if len(pcm_data) < 2:
                return pcm_data
                
            # Unpack samples
            sample_count = len(pcm_data) // 2
            samples = list(struct.unpack(f'<{sample_count}h', pcm_data))
            
            if not samples:
                return pcm_data
                
            # Calculate current audio levels
            max_amplitude = max(abs(s) for s in samples)
            rms = math.sqrt(sum(s*s for s in samples) / len(samples))
            
            # Only apply AGC if audio is too quiet (typical for G.711)
            if max_amplitude < 100:  # Very quiet, boost significantly
                gain = 150.0  # Increased from 50.0
            elif max_amplitude < 500:  # Quiet, boost moderately  
                gain = 60.0   # Increased from 20.0
            elif max_amplitude < 2000:  # Low but audible, boost gently
                gain = 20.0   # Increased from 8.0
            elif max_amplitude < 8000:  # Acceptable level, small boost
                gain = 5.0    # Increased from 3.0
            else:  # Already loud enough
                gain = 1.0
                
            # Apply gain with soft limiting to prevent harsh clipping
            boosted_samples = []
            for sample in samples:
                # Apply gain
                boosted = int(sample * gain)
                
                # Soft limiting to prevent harsh clipping
                if boosted > 20000:  # Soft limit at ~60% of max
                    boosted = 20000 + int((boosted - 20000) * 0.3)
                elif boosted < -20000:
                    boosted = -20000 + int((boosted + 20000) * 0.3)
                    
                # Hard limit to prevent overflow
                boosted = max(-32767, min(32767, boosted))
                boosted_samples.append(boosted)
            
            # Log AGC activity for debugging (only for first few packets)
            if not hasattr(self, '_agc_log_count'):
                self._agc_log_count = 0
            
            final_max = max(abs(s) for s in boosted_samples)
            if gain > 1.0 and self._agc_log_count < 3:
                logger.debug(f"🔊 AGC applied: {max_amplitude} → {final_max} (gain: {gain:.1f}x)")
                self._agc_log_count += 1
            
            # Pack back to bytes
            return struct.pack(f'<{len(boosted_samples)}h', *boosted_samples)
            
        except Exception as e:
            logger.error(f"❌ AGC error: {e}")
            return pcm_data  # Return original if AGC fails
            
    def close(self):
        """Close the WAV file."""
        if self.wav_file:
            try:
                self.wav_file.close()
                logger.info(f"🎵 Closed WAV file: {self.filename} ({self.packets_written} packets written)")
            except Exception as e:
                logger.error(f"❌ Error closing WAV file: {e}")
            finally:
                self.wav_file = None

class RtpBridge:
    """
    RTP bridge that forwards audio between two endpoints and captures for AI.
    Acts as a true media relay to intercept RTP packets.
    """
    
    def __init__(self, local_ip: str):
        self.local_ip = local_ip
        self.local_port = None
        self.socket = None
        self.running = False
        self.upnp_enabled = False
        
        # Test mode for debugging audio pipeline
        self.test_mode = False
        self.test_audio_file = None
        self.test_audio_data = None
        self.test_audio_packets = []
        self.test_packet_index = 0
        
        # AI audio streaming state - fixed for proper RTP timing
        self._ai_sequence_number = 0
        self._ai_timestamp_base = 0
        self._ai_samples_sent = 0  # Track samples sent for current stream
        self._is_first_ai_chunk = True # NEW: Flag to handle initial audio chunk
        
        # Endpoints - learned dynamically
        self.caller_endpoint: Optional[AudioEndpoint] = None  # Phone
        self.remote_endpoint: Optional[AudioEndpoint] = None  # Zoho server
        
        # Audio callbacks
        self.audio_callback: Optional[Callable[[bytes, str], None]] = None
        
        # Audio recording for verification - now using WAV format
        self.record_audio = True
        self.audio_dir = "captured_audio"
        self.caller_wav_recorder: Optional[WavRecorder] = None
        self.remote_wav_recorder: Optional[WavRecorder] = None
        self.max_recording_packets = 500  # Increased limit for WAV files
        
        # Statistics
        self.packets_forwarded = 0
        self.packets_to_ai = 0
        self.packets_from_ai = 0
        self.caller_packets_recorded = 0
        self.remote_packets_recorded = 0
        
        # Setup recording directory
        if self.record_audio:
            os.makedirs(self.audio_dir, exist_ok=True)
        
        # Register cleanup function
        atexit.register(self._cleanup_upnp)
        
        logger.info(f"🌉 RTP Bridge initialized for {local_ip}")
        if self.record_audio:
            logger.info(f"🎵 WAV audio recording enabled - will save to {self.audio_dir}/")
    
    def start_bridge(self, remote_audio: Optional[AudioParams] = None) -> Optional[int]:
        """Start the RTP bridge and return the local listening port."""
        try:
            # Create UDP socket for RTP
            self.socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            
            # Try to bind to a specific port range for NAT traversal
            port_assigned = False
            from ..config import get_settings
            from ..utils.network import upnp_manager
            settings = get_settings()
            
            # Initialize UPnP if enabled
            try:
                if upnp_manager.initialize():
                    self.upnp_enabled = True
                    logger.info("🎯 UPnP enabled - will automatically configure port forwarding")
                else:
                    logger.warning("⚠️  UPnP not available - manual port forwarding required")
            except Exception as e:
                logger.warning(f"⚠️  UPnP initialization failed: {e}")
            
            if hasattr(settings.calls, 'use_fixed_rtp_port') and settings.calls.use_fixed_rtp_port:
                # Try ports in the configured range
                port_min = getattr(settings.calls, 'rtp_port_min', 10000)
                port_max = getattr(settings.calls, 'rtp_port_max', 10100)
                
                logger.info(f"🔧 NAT TRAVERSAL: Trying fixed port range {port_min}-{port_max}")
                
                for port in range(port_min, port_max + 1):
                    try:
                        self.socket.bind(("0.0.0.0", port))
                        self.local_port = port
                        port_assigned = True
                        
                        # Try UPnP port forwarding
                        if self.upnp_enabled:
                            if upnp_manager.forward_port(port, 'UDP', f'Callie RTP {port}'):
                                logger.info(f"🎯 RTP Bridge bound to FIXED PORT: 0.0.0.0:{port} (UPnP forwarded)")
                            else:
                                logger.info(f"🎯 RTP Bridge bound to FIXED PORT: 0.0.0.0:{port} (UPnP failed)")
                                logger.info(f"📋 MANUAL NAT SETUP: Forward UDP port {port} to {self.local_ip}:{port}")
                        else:
                            logger.info(f"🎯 RTP Bridge bound to FIXED PORT: 0.0.0.0:{port}")
                            logger.info(f"📋 MANUAL NAT SETUP: Forward UDP port {port} to {self.local_ip}:{port}")
                        break
                    except OSError:
                        continue  # Port in use, try next one
                        
                if not port_assigned:
                    logger.warning(f"⚠️  All ports {port_min}-{port_max} in use, falling back to random port")
            
            if not port_assigned:
                # Fallback to random port (original behavior)
                self.socket.bind(("0.0.0.0", 0))  # Bind to all interfaces on any available port
                self.local_port = self.socket.getsockname()[1]
                
                # Try UPnP on random port
                if self.upnp_enabled:
                    if upnp_manager.forward_port(self.local_port, 'UDP', f'Callie RTP {self.local_port}'):
                        logger.info(f"🌉 RTP Bridge on random port {self.local_port} (UPnP forwarded)")
                    else:
                        logger.warning(f"🌉 RTP Bridge on random port {self.local_port} (UPnP failed)")
                        logger.warning(f"⚠️  MANUAL SETUP: Forward UDP port {self.local_port} to {self.local_ip}:{self.local_port}")
                else:
                    logger.info(f"🌉 RTP Bridge listening on ALL INTERFACES::{self.local_port} (random port)")
                    logger.warning(f"⚠️  MANUAL SETUP: Forward UDP port {self.local_port} to {self.local_ip}:{self.local_port}")
            
            logger.info(f"🔧 NAT FIX: Bridge can receive packets sent to public IP")
            
            # Set remote endpoint if provided
            if remote_audio:
                self.remote_endpoint = AudioEndpoint(
                    ip=remote_audio.ip_address,
                    port=remote_audio.port
                )
                logger.info(f"🎯 Remote endpoint configured: {self.remote_endpoint.ip}:{self.remote_endpoint.port}")
            
            # Setup audio recording files - now as WAV files
            if self.record_audio:
                timestamp = int(time.time())
                
                # Create WAV recorders
                caller_filename = f"{self.audio_dir}/caller_audio_{timestamp}.wav"
                remote_filename = f"{self.audio_dir}/remote_audio_{timestamp}.wav"
                
                self.caller_wav_recorder = WavRecorder(caller_filename, sample_rate=8000)
                self.remote_wav_recorder = WavRecorder(remote_filename, sample_rate=8000)
                
                self.caller_wav_recorder.open()
                self.remote_wav_recorder.open()
                
                logger.info(f"🎵 WAV recording files created for session {timestamp}")
            
            # Start bridge loop
            self.running = True
            bridge_thread = threading.Thread(target=self._bridge_loop, daemon=True)
            bridge_thread.start()
            
            return self.local_port
            
        except Exception as e:
            logger.error(f"❌ Failed to start RTP bridge: {e}")
            return None
    
    def set_remote_endpoint(self, remote_audio: AudioParams) -> None:
        """Set the remote endpoint after receiving 200 OK."""
        self.remote_endpoint = AudioEndpoint(
            ip=remote_audio.ip_address,
            port=remote_audio.port
        )
        
        # CRITICAL FIX: Also set caller_endpoint so AI audio can be sent immediately
        # In our setup, the remote endpoint (Zoho server) is where we send AI audio
        if not self.caller_endpoint:
            self.caller_endpoint = AudioEndpoint(
                ip=remote_audio.ip_address,
                port=remote_audio.port
            )
            logger.info(f"🎯 Caller endpoint initialized from SDP: {self.caller_endpoint.ip}:{self.caller_endpoint.port}")
        
        logger.info(f"🎯 Remote endpoint updated: {self.remote_endpoint.ip}:{self.remote_endpoint.port}")
    
    def set_audio_callback(self, callback: Callable[[bytes, str], None]) -> None:
        """Set callback for captured audio."""
        self.audio_callback = callback
        logger.info("🎤 Audio capture callback registered")
    
    def enable_test_mode(self, test_audio_file: str = None) -> bool:
        """Enable test mode to inject known audio instead of AI audio."""
        try:
            if not test_audio_file:
                # Create a simple test tone
                self._create_test_tone()
            else:
                # Load audio file
                if not self._load_test_audio_file(test_audio_file):
                    return False
            
            self.test_mode = True
            logger.info(f"🧪 Test mode enabled - will inject test audio instead of AI audio")
            return True
            
        except Exception as e:
            logger.error(f"❌ Failed to enable test mode: {e}")
            return False
    
    def _create_test_tone(self) -> None:
        """Create a simple test tone for audio testing."""
        import math
        
        # Generate a 1kHz tone for 3 seconds at 8kHz sample rate
        sample_rate = 8000
        duration = 3.0
        frequency = 1000
        
        samples = []
        for i in range(int(sample_rate * duration)):
            # Generate sine wave
            sample = int(16000 * math.sin(2 * math.pi * frequency * i / sample_rate))
            samples.append(max(-32767, min(32767, sample)))  # Clamp to 16-bit range
        
        # Convert to PCM bytes
        pcm_data = struct.pack(f'<{len(samples)}h', *samples)
        
        # Convert PCM to μ-law and create RTP packets
        self._create_test_rtp_packets(pcm_data)
        logger.info(f"🎵 Created test tone: {len(self.test_audio_packets)} RTP packets")
    
    def _load_test_audio_file(self, filename: str) -> bool:
        """Load audio file and convert to RTP packets for testing."""
        try:
            import wave
            
            # Open WAV file
            with wave.open(filename, 'rb') as wav_file:
                if wav_file.getnchannels() != 1:
                    logger.error("❌ Test audio file must be mono")
                    return False
                
                if wav_file.getsampwidth() != 2:
                    logger.error("❌ Test audio file must be 16-bit")
                    return False
                
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                
                # Resample to 8kHz if needed
                if sample_rate != 8000:
                    from .audio_codec import resample_simple
                    frames = resample_simple(frames, sample_rate, 8000, 2)
                
                self._create_test_rtp_packets(frames)
                logger.info(f"🎵 Loaded test audio: {filename} -> {len(self.test_audio_packets)} RTP packets")
                return True
                
        except Exception as e:
            logger.error(f"❌ Failed to load test audio file {filename}: {e}")
            return False
    
    def _create_test_rtp_packets(self, pcm_data: bytes) -> None:
        """Convert PCM audio to RTP packets for testing."""
        from .audio_codec import pcm_to_ulaw
        
        # Convert PCM to μ-law
        ulaw_data = pcm_to_ulaw(pcm_data)
        
        # Split into RTP packet payloads (160 bytes each for 20ms at 8kHz)
        payload_size = 160
        self.test_audio_packets = []
        
        for i in range(0, len(ulaw_data), payload_size):
            payload = ulaw_data[i:i + payload_size]
            if len(payload) < payload_size:
                # Pad last packet with silence
                payload += b'\x7f' * (payload_size - len(payload))
            
            # Create RTP packet
            rtp_packet = self._create_rtp_packet_for_test_audio(payload, i // payload_size)
            if rtp_packet:
                self.test_audio_packets.append(rtp_packet)
    
    def _create_rtp_packet_for_test_audio(self, ulaw_payload: bytes, sequence: int) -> Optional[bytes]:
        """Create RTP packet for test audio."""
        try:
            # RTP header
            version = 2
            padding = 0
            extension = 0
            csrc_count = 0
            marker = 0
            payload_type = 0  # PCMU (μ-law)
            sequence_number = sequence & 0xFFFF
            timestamp = (sequence * 160) & 0xFFFFFFFF  # 160 samples per packet at 8kHz
            ssrc = 0x12345678  # Test SSRC
            
            # Pack RTP header (12 bytes)
            byte0 = (version << 6) | (padding << 5) | (extension << 4) | csrc_count
            byte1 = (marker << 7) | payload_type
            
            header = struct.pack('!BBHII', byte0, byte1, sequence_number, timestamp, ssrc)
            return header + ulaw_payload
            
        except Exception as e:
            logger.error(f"❌ Error creating test RTP packet: {e}")
            return None
    
    def get_test_audio_packet(self) -> Optional[bytes]:
        """Get next test audio packet for injection."""
        if not self.test_mode or not self.test_audio_packets:
            return None
        
        packet = self.test_audio_packets[self.test_packet_index]
        self.test_packet_index = (self.test_packet_index + 1) % len(self.test_audio_packets)
        return packet
    
    def start_test_audio_injection(self) -> None:
        """Start injecting test audio immediately (simpler approach)."""
        if not self.test_mode or not self.test_audio_packets:
            logger.error("❌ Test mode not enabled or no test audio packets")
            return
        
        import threading
        import time
        
        def inject_test_audio_loop():
            logger.info("🧪 Starting test audio injection loop...")
            packet_count = 0
            
            while self.running and self.test_mode:
                if self.caller_endpoint:  # Send to learned caller endpoint, not remote_endpoint
                    test_packet = self.get_test_audio_packet()
                    if test_packet:
                        try:
                            # Send directly to caller endpoint (where Zoho expects our audio)
                            self.socket.sendto(test_packet, (self.caller_endpoint.ip, self.caller_endpoint.port))
                            packet_count += 1
                            
                            if packet_count % 50 == 0:  # Log every 50 packets (1 second)
                                logger.info(f"🧪 Sent {packet_count} test audio packets to {self.caller_endpoint.ip}:{self.caller_endpoint.port}")
                            
                        except Exception as e:
                            logger.error(f"❌ Error sending test audio: {e}")
                            break
                
                time.sleep(0.02)  # 20ms intervals
            
            logger.info(f"🧪 Test audio injection ended after {packet_count} packets")
        
        test_thread = threading.Thread(target=inject_test_audio_loop, daemon=True)
        test_thread.start()
        logger.info("🧪 Test audio injection thread started")
    
    def _bridge_loop(self) -> None:
        """Main bridge loop - forwards RTP packets and captures for AI."""
        logger.info("🌉 RTP Bridge loop started")
        logger.info(f"🔍 Listening for RTP packets on ALL INTERFACES port {self.local_port}")
        logger.info(f"🎯 Will capture caller audio for AI (NO ECHO FORWARDING)")
        
        last_stats_time = time.time()
        packet_sources = set()  # Track unique packet sources
        
        while self.running:
            try:
                self.socket.settimeout(1.0)  # 1 second timeout
                data, addr = self.socket.recvfrom(4096)
                
                # Track packet sources for debugging
                source_key = f"{addr[0]}:{addr[1]}"
                if source_key not in packet_sources:
                    packet_sources.add(source_key)
                    logger.info(f"🆕 NEW RTP SOURCE detected: {source_key}")
                    
                    # Analyze the first packet from this source
                    self._analyze_rtp_packet(data, addr, "INCOMING")
                
                # Learn caller endpoint from first packet (this is actually Zoho sending caller audio to us)
                if not self.caller_endpoint:
                    self.caller_endpoint = AudioEndpoint(ip=addr[0], port=addr[1])
                    logger.info(f"📞 Audio source endpoint learned: {self.caller_endpoint.ip}:{self.caller_endpoint.port}")
                    logger.info(f"🔧 ECHO PREVENTION: Will NOT forward caller audio back to this endpoint")
                
                # Handle incoming RTP packets - these are the caller's voice from Zoho
                if addr[0] == self.caller_endpoint.ip and addr[1] == self.caller_endpoint.port:
                    # Packet from Zoho (containing caller's voice) → capture for AI only, DON'T echo back
                    logger.debug(f"📥 Received caller audio from Zoho: {len(data)} bytes")
                    self._capture_for_ai(data, "caller")
                    self._record_audio(data, "caller")
                    # 🚫 CRITICAL: Do NOT forward back to prevent echo!
                    
                elif self.remote_endpoint and addr[0] == self.remote_endpoint.ip and addr[1] == self.remote_endpoint.port:
                    # This shouldn't happen in our setup since Zoho is both endpoints
                    # But handle gracefully
                    logger.debug(f"📥 Received audio from alternate endpoint: {len(data)} bytes")
                    self._capture_for_ai(data, "remote")
                    self._record_audio(data, "remote")
                    
                else:
                    # Log unknown sources for debugging
                    if len(packet_sources) <= 5:  # Only log first few unknowns
                        logger.info(f"🤔 Unknown RTP source: {addr[0]}:{addr[1]} (may be NAT/proxy)")
                
                self.packets_forwarded += 1
                
                # Enhanced statistics every 10 seconds
                if time.time() - last_stats_time > 10:
                    logger.info(f"🌉 Bridge stats: {self.packets_forwarded} received, {self.packets_to_ai} to AI, {self.packets_from_ai} from AI")
                    logger.info(f"📊 Packet sources seen: {len(packet_sources)} unique endpoints")
                    if self.record_audio:
                        logger.info(f"🎵 WAV Recording stats: {self.caller_packets_recorded} caller packets, {self.remote_packets_recorded} remote packets saved to WAV")
                    if self.packets_forwarded > 0:
                        logger.info("✅ SUCCESS! Audio packets flowing - NO ECHO forwarding")
                    else:
                        logger.warning("⚠️  Still waiting for RTP packets...")
                    last_stats_time = time.time()
                
            except socket.timeout:
                # Normal timeout, continue
                continue
            except Exception as e:
                if self.running:
                    logger.error(f"❌ Bridge loop error: {e}")
                break
        
        logger.info("🌉 RTP Bridge loop ended")
    
    def _analyze_rtp_packet(self, data: bytes, addr: tuple, direction: str) -> None:
        """Analyze RTP packet for debugging."""
        try:
            if len(data) < 12:
                logger.warning(f"📦 {direction} packet too short: {len(data)} bytes from {addr[0]}:{addr[1]}")
                return
            
            # Parse RTP header
            version = (data[0] & 0xC0) >> 6
            padding = (data[0] & 0x20) >> 5
            extension = (data[0] & 0x10) >> 4
            csrc_count = data[0] & 0x0F
            marker = (data[1] & 0x80) >> 7
            payload_type = data[1] & 0x7F
            sequence = (data[2] << 8) | data[3]
            timestamp = (data[4] << 24) | (data[5] << 16) | (data[6] << 8) | data[7]
            ssrc = (data[8] << 24) | (data[9] << 16) | (data[10] << 8) | data[11]
            
            payload_size = len(data) - 12
            
            logger.info(f"📦 {direction} RTP ANALYSIS from {addr[0]}:{addr[1]}:")
            logger.info(f"   • Version: {version}, Payload Type: {payload_type} ({'PCMU' if payload_type == 0 else 'PCMA' if payload_type == 8 else 'OTHER'})")
            logger.info(f"   • Sequence: {sequence}, Timestamp: {timestamp}")
            logger.info(f"   • SSRC: 0x{ssrc:08x}, Payload: {payload_size} bytes")
            logger.info(f"   • Marker: {marker}, Padding: {padding}")
            
        except Exception as e:
            logger.error(f"❌ Error analyzing RTP packet: {e}")
    
    def _record_audio(self, data: bytes, source: str) -> None:
        """Record RTP packets as WAV audio files."""
        if not self.record_audio:
            return
            
        try:
            if source == "caller" and self.caller_packets_recorded < self.max_recording_packets:
                if self.caller_wav_recorder and self.caller_wav_recorder.write_rtp_packet(data):
                    self.caller_packets_recorded += 1
                    if self.caller_packets_recorded == 1:
                        logger.info(f"🎵 WAV RECORDING: First caller audio packet saved! ({len(data)} bytes RTP)")
                    elif self.caller_packets_recorded % 50 == 0:
                        logger.info(f"🎵 WAV RECORDING: {self.caller_packets_recorded} caller packets saved to WAV")
                        
            elif source == "remote" and self.remote_packets_recorded < self.max_recording_packets:
                if self.remote_wav_recorder and self.remote_wav_recorder.write_rtp_packet(data):
                    self.remote_packets_recorded += 1
                    if self.remote_packets_recorded == 1:
                        logger.info(f"🎵 WAV RECORDING: First remote audio packet saved! ({len(data)} bytes RTP)")
                    elif self.remote_packets_recorded % 50 == 0:
                        logger.info(f"🎵 WAV RECORDING: {self.remote_packets_recorded} remote packets saved to WAV")
                        
        except Exception as e:
            logger.error(f"❌ WAV recording error: {e}")
    
    def _forward_to_remote(self, data: bytes) -> None:
        """Forward RTP packet from caller to remote server."""
        if self.remote_endpoint:
            try:
                # Send to remote server (Zoho)
                self.socket.sendto(data, (self.remote_endpoint.ip, self.remote_endpoint.port))
                logger.debug(f"📤 Forwarded {len(data)} bytes to remote")
            except Exception as e:
                logger.error(f"❌ Failed to forward to remote: {e}")
    
    def _forward_to_caller(self, data: bytes) -> None:
        """Forward RTP packet from remote server to caller."""
        if self.caller_endpoint:
            try:
                # Send back to caller (phone)
                self.socket.sendto(data, (self.caller_endpoint.ip, self.caller_endpoint.port))
                logger.debug(f"📤 Forwarded {len(data)} bytes to caller")
            except Exception as e:
                logger.error(f"❌ Failed to forward to caller: {e}")
    
    def _capture_for_ai(self, rtp_data: bytes, source: str) -> None:
        """Capture and process RTP audio for AI."""
        try:
            if len(rtp_data) < 12:  # Minimum RTP header size
                return
                
            # Parse RTP header to get payload type and payload
            payload_type = rtp_data[1] & 0x7F  # Extract payload type
            payload = rtp_data[12:]  # Skip 12-byte RTP header
            
            if not payload:
                return
                
            # 🎵 Convert RTP payload to PCM audio for AI
            pcm_audio = self._convert_rtp_to_pcm(payload, payload_type)
            if pcm_audio and self.audio_callback:
                # Check if this audio contains voice (simple amplitude check)
                import struct
                samples = struct.unpack(f'<{len(pcm_audio)//2}h', pcm_audio)
                max_amplitude = max(abs(s) for s in samples) if samples else 0
                
                # Log voice detection for debugging
                if self.packets_to_ai <= 10 or max_amplitude > 800:  # First 10 packets or voice detected
                    voice_detected = "🗣️  VOICE" if max_amplitude > 800 else "🔇 silence"
                    logger.info(f"🎤 {source} audio #{self.packets_to_ai}: {len(payload)} bytes RTP → {len(pcm_audio)} bytes PCM (max: {max_amplitude}) {voice_detected}")
                
                self.audio_callback(pcm_audio, source)
                self.packets_to_ai += 1
                
                # Enhanced logging for voice activity
                if max_amplitude > 800:  # Voice threshold - reduced for better sensitivity
                    if not hasattr(self, '_last_voice_time'):
                        logger.info("🗣️  VOICE ACTIVITY DETECTED - AI should be hearing you now!")
                    self._last_voice_time = time.time()
                    
        except Exception as e:
            logger.error(f"Error capturing RTP for AI: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
    def _convert_rtp_to_pcm(self, rtp_payload: bytes, payload_type: int) -> Optional[bytes]:
        """Convert RTP audio payload to PCM format for AI processing."""
        try:
            from .audio_codec import ulaw_to_pcm, alaw_to_pcm, resample_simple
            
            # Map payload types to codecs (based on SDP we're advertising)
            # 0 = PCMU (μ-law), 8 = PCMA (A-law), 18 = G729
            if payload_type == 0:  # PCMU (μ-law)
                # Convert μ-law to PCM 8kHz
                pcm_8khz = ulaw_to_pcm(rtp_payload)
                # Apply AGC for consistent levels
                pcm_8khz = self._apply_agc_to_pcm(pcm_8khz)
                # Resample to 24kHz for AI (Gemini Live API requirement)
                pcm_24khz = resample_simple(pcm_8khz, 8000, 24000, 2)
                return pcm_24khz
                
            elif payload_type == 8:  # PCMA (A-law)
                # Convert A-law to PCM 8kHz
                pcm_8khz = alaw_to_pcm(rtp_payload)
                # Apply AGC for consistent levels
                pcm_8khz = self._apply_agc_to_pcm(pcm_8khz)
                # Resample to 24kHz for AI (Gemini Live API requirement)
                pcm_24khz = resample_simple(pcm_8khz, 8000, 24000, 2)
                return pcm_24khz
                
            elif payload_type == 18:  # G729
                logger.warning(f"G729 codec not yet supported for payload type {payload_type}")
                # TODO: Implement G729 decoder
                return None
                
            else:
                logger.warning(f"Unsupported RTP payload type: {payload_type}")
                return None
                
        except Exception as e:
            logger.error(f"Error converting RTP payload (type {payload_type}): {e}")
            return None
    
    def _enhance_audio_quality(self, pcm_data: bytes, sample_count: int) -> bytes:
        """
        Apply audio quality enhancement filters for better call quality.
        Includes normalization, noise reduction, and dynamic range optimization.
        """
        try:
            import struct
            import numpy as np
            
            # Convert to numpy array for processing
            samples = np.frombuffer(pcm_data, dtype=np.int16)
            samples_float = samples.astype(np.float32)
            
            # 1. Peak normalization to optimize dynamic range
            max_val = np.max(np.abs(samples_float))
            if max_val > 0:
                # Normalize to 85% of max range to prevent clipping but maintain clarity
                target_peak = 32767 * 0.85
                normalization_factor = target_peak / max_val
                samples_float *= normalization_factor
                
            # 2. Simple noise gate - reduce very low amplitude noise
            noise_threshold = 200  # Very low threshold to preserve quiet speech
            samples_float = np.where(np.abs(samples_float) < noise_threshold, 
                                   samples_float * 0.1, samples_float)
            
            # 3. Soft compression to improve clarity without artifacts
            # Apply gentle compression to loud sounds while preserving quiet ones
            def soft_compress(x, threshold=20000, ratio=0.7):
                abs_x = np.abs(x)
                compressed = np.where(abs_x > threshold,
                                    threshold + (abs_x - threshold) * ratio,
                                    abs_x)
                return np.sign(x) * compressed
            
            samples_float = soft_compress(samples_float)
            
            # 4. Final clipping protection
            samples_float = np.clip(samples_float, -32767, 32767)
            
            # Convert back to int16
            enhanced_samples = samples_float.astype(np.int16)
            
            logger.debug(f"🎵 Audio enhancement: {max_val:.0f} → {np.max(np.abs(enhanced_samples)):.0f} peak")
            
            return enhanced_samples.tobytes()
            
        except Exception as e:
            logger.warning(f"⚠️  Audio enhancement failed, using original: {e}")
            return pcm_data
            
    def _apply_agc_to_pcm(self, pcm_data: bytes) -> bytes:
        """ENHANCED AGC: Professional audio processing with clarity optimization."""
        try:
            import struct
            import math
            import numpy as np
            
            if len(pcm_data) < 2:
                return pcm_data
                
            # Unpack samples  
            sample_count = len(pcm_data) // 2
            samples = np.frombuffer(pcm_data, dtype=np.int16).astype(np.float32)
            
            if len(samples) == 0:
                return pcm_data
                
            # Calculate current audio levels
            max_amplitude = np.max(np.abs(samples))
            rms = np.sqrt(np.mean(samples**2))
            
            # ENHANCED: RMS-based AGC with reduced fuzziness 
            target_rms = 4000  # Optimal level for clarity without distortion
            
            if rms < 100:  # Very quiet
                gain = min(25.0, target_rms / max(rms, 50))  # Conservative gain
            elif rms < 500:  # Quiet  
                gain = min(10.0, target_rms / rms)  # Moderate boost
            elif rms < 1500:  # Low but audible
                gain = min(5.0, target_rms / rms)   # Gentle boost
            elif rms < 3000:  # Acceptable level  
                gain = min(2.0, target_rms / rms)   # Minimal boost
            else:  # Already good level
                gain = 1.0
                
            # Apply gain with soft limiting to prevent harsh clipping
            boosted_samples = []
            for sample in samples:
                # Apply gain
                boosted = int(sample * gain)
                
                # Soft limiting to prevent harsh clipping
                if boosted > 20000:  # Soft limit at ~60% of max
                    boosted = 20000 + int((boosted - 20000) * 0.3)
                elif boosted < -20000:
                    boosted = -20000 + int((boosted + 20000) * 0.3)
                    
                # Hard limit to prevent overflow
                boosted = max(-32767, min(32767, boosted))
                boosted_samples.append(boosted)
            
            # Log AGC activity for debugging (only for first few packets)
            if not hasattr(self, '_agc_log_count'):
                self._agc_log_count = 0
            
            final_max = max(abs(s) for s in boosted_samples)
            if gain > 1.0 and self._agc_log_count < 3:
                logger.debug(f"🔊 AGC applied: {max_amplitude} → {final_max} (gain: {gain:.1f}x)")
                self._agc_log_count += 1
            
            # Pack back to bytes
            return struct.pack(f'<{len(boosted_samples)}h', *boosted_samples)
            
        except Exception as e:
            logger.error(f"❌ AGC error: {e}")
            return pcm_data  # Return original if AGC fails
            
    def _stream_packets(self, rtp_packets: list[bytes], target_endpoint: AudioEndpoint) -> int:
        """Streams a list of RTP packets with precise timing, returns packets sent."""
        if not target_endpoint:
            logger.warning("⚠️ No target endpoint, cannot stream packets.")
            return 0

        if not rtp_packets:
            logger.warning("⚠️ No packets provided to stream.")
            return 0

        packet_interval = 0.010  # 10ms between packets (optimal)
        packets_sent = 0
        start_time = time.time()

        for i, packet in enumerate(rtp_packets):
            try:
                # Calculate when this packet should be sent
                target_time = start_time + (i * packet_interval)
                current_time = time.time()

                # If we're ahead of schedule, wait briefly
                if current_time < target_time:
                    delay = target_time - current_time
                    if delay > 0.0005:  # Sleep if delay > 0.5ms
                        time.sleep(delay)
                
                self.socket.sendto(packet, (target_endpoint.ip, target_endpoint.port))
                self.packets_from_ai += 1
                packets_sent += 1

                self._record_audio(packet, "remote")

                if i < 2:
                    self._analyze_rtp_packet(packet, (target_endpoint.ip, target_endpoint.port), f"AI_AUDIO_STREAM #{i+1}")
            
            except Exception as e:
                logger.error(f"❌ Error sending packet {i} during stream: {e}")
                break
        
        return packets_sent

    def send_ai_audio(self, audio_data: bytes, target: str = "caller") -> None:
        """Send AI-generated audio to the call by packetizing and streaming it."""
        # CRITICAL FIX: Use remote_endpoint as fallback if caller_endpoint not set
        target_endpoint = self.caller_endpoint or self.remote_endpoint
        
        if not target_endpoint:
            logger.warning("⚠️  No caller or remote endpoint available for AI audio")
            return
            
        # ROBUSTNESS: Validate AI audio data before processing
        if not audio_data:
            logger.warning("⚠️  Received empty AI audio data - skipping this chunk")
            return
            
        if len(audio_data) < 32:  # Less than ~1ms of audio at 16kHz
            logger.warning(f"⚠️  Received very small AI audio chunk ({len(audio_data)} bytes) - skipping")
            return
            
        try:
            # Create a list of RTP packets from the AI's audio chunk
            rtp_packets = self._create_rtp_packets_for_ai_audio(audio_data)
            
            if not rtp_packets:
                logger.warning(f"⚠️  Could not create RTP packets from {len(audio_data)}B AI audio - skipping this chunk")
                return  # Continue conversation, don't fail
                
            logger.info(f"🎤 Streaming {len(rtp_packets)} AI audio packets to {target_endpoint.ip}:{target_endpoint.port}")
            packets_sent = self._stream_packets(rtp_packets, target_endpoint)
            logger.info(f"✅ Sent {packets_sent}/{len(rtp_packets)} AI audio packets")
            
        except Exception as e:
            logger.warning(f"⚠️  Error processing AI audio chunk: {e} - continuing conversation")
            import traceback
            logger.debug(f"Stack trace: {traceback.format_exc()}")
            # Don't return or raise - continue the conversation even if one chunk fails
    
    def _create_rtp_packets_for_ai_audio(self, ai_audio_data: bytes) -> list[bytes]:
        """
        Create a list of RTP packets from AI-generated audio.
        ENHANCED: Validates audio format and ensures precise conversion.
        """
        packets = []
        try:
            from .audio_codec import pcm_to_alaw, resample_simple
            import struct
            
            logger.info(f"🎵 Processing AI audio: {len(ai_audio_data)} bytes from Gemini Live API")
            
            # ENHANCED: Validate and analyze input audio
            if len(ai_audio_data) % 2 != 0:
                logger.warning(f"⚠️  AI audio size {len(ai_audio_data)} is not even - may not be 16-bit PCM")
                # Pad with zero byte if odd
                ai_audio_data += b'\x00'
            
            sample_count = len(ai_audio_data) // 2
            logger.info(f"🔬 AI Audio Analysis: {sample_count} samples, assumed 16-bit PCM")
            
            # Calculate expected timing based on 24kHz assumption
            expected_duration_ms = (sample_count / 24000) * 1000
            logger.info(f"⏱️  Expected duration (24kHz): {expected_duration_ms:.1f}ms")
            
            # OPTIMIZED: Direct and precise audio processing pipeline
            # Step 1: Validate that this is really 24kHz, 16-bit PCM
            try:
                samples = struct.unpack(f'<{sample_count}h', ai_audio_data)
                max_amplitude = max(abs(s) for s in samples) if samples else 0
                avg_amplitude = sum(abs(s) for s in samples) / len(samples) if samples else 0
                
                logger.info(f"📊 Audio levels: max={max_amplitude}, avg={avg_amplitude:.1f}")
                
                if max_amplitude > 32767:
                    logger.warning(f"⚠️  AI audio has invalid amplitude ({max_amplitude}) - treating as silence")
                    # Replace with silence rather than failing
                    ai_audio_data = b'\x00' * len(ai_audio_data)
                    samples = [0] * sample_count
                    
            except Exception as e:
                logger.warning(f"⚠️  Could not validate AI audio PCM data: {e} - treating as silence")
                # Replace with silence rather than failing
                ai_audio_data = b'\x00' * len(ai_audio_data)
                sample_count = len(ai_audio_data) // 2
            
            # Step 2: High-quality resample from 24kHz to 8kHz (telephony standard)
            pcm_8khz_data = resample_simple(ai_audio_data, from_rate=24000, to_rate=8000)
            logger.info(f"🔄 PRECISE resample 24kHz→8kHz: {len(ai_audio_data)} → {len(pcm_8khz_data)} bytes")
            
            # Validate resampling result
            expected_8khz_samples = sample_count // 3  # Exact 3:1 ratio (24kHz -> 8kHz)
            expected_8khz_bytes = expected_8khz_samples * 2
            if len(pcm_8khz_data) != expected_8khz_bytes:
                logger.warning(f"⚠️  Resampling error: expected {expected_8khz_bytes} bytes, got {len(pcm_8khz_data)}")
            
            # Step 3: Convert to A-law for RTP transmission  
            from .audio_codec import pcm_to_alaw
            alaw_data = pcm_to_alaw(pcm_8khz_data)
            logger.info(f"🔄 PCM→A-law: {len(pcm_8khz_data)} → {len(alaw_data)} bytes")
            
            # Set codec parameters for A-law
            codec_data = alaw_data
            payload_type_to_use = 8    # A-law (PCMA)
            samples_per_byte = 1       # A-law: each byte = 1 sample
            sample_rate = 8000         # 8kHz
            
            # Step 4: Initialize precise timing for 8kHz audio stream
            if not hasattr(self, '_ai_timestamp_base') or self._ai_timestamp_base == 0:
                # Initialize with current time but convert to 8kHz sample units
                self._ai_timestamp_base = int(time.time() * 8000) % (2**32)
                self._ai_samples_sent = 0
                logger.info(f"🕐 Initialized AI audio stream timing (8kHz) - base timestamp: {self._ai_timestamp_base}")
            
            # Step 5: Create precise RTP packets - OPTIMAL TIMING
            payload_size = 80  # 80 samples = 10ms at 8kHz (optimal balance)
            packet_index = 0
            
            if len(codec_data) == 0:
                logger.warning(f"⚠️  No A-law data to packetize")
                return packets
            
            for i in range(0, len(codec_data), payload_size):
                payload = codec_data[i:i+payload_size]
                
                # Pad with proper A-law silence if needed
                if len(payload) < payload_size:
                    # A-law silence value (0x55 = 0 in A-law encoding)
                    silence_padding = b'\x55' * (payload_size - len(payload))
                    payload += silence_padding
                    logger.debug(f"Padded packet #{packet_index} with {len(silence_padding)} A-law silence bytes")
                
                # Create RTP header with sample-accurate timing  
                version = 2
                payload_type = 8  # PCMA (A-law) - telephony standard
                ssrc = 0x87654321  # Unique SSRC for our AI audio
                
                # Sequence number increments by 1 for each packet
                sequence_number = self._ai_sequence_number
                self._ai_sequence_number = (self._ai_sequence_number + 1) & 0xFFFF
                
                # FIXED: Sample-accurate timestamp calculation
                timestamp = (self._ai_timestamp_base + self._ai_samples_sent) & 0xFFFFFFFF
                self._ai_samples_sent += len(payload)  # Each byte = 1 sample in A-law
                
                # Pack the RTP header (12 bytes) with optimal settings
                header = struct.pack('!BBHII', 
                                     (version << 6) | 0,  # V=2, P=0, X=0, CC=0
                                     payload_type,         # M=0, PT=8 (A-law)
                                     sequence_number,
                                     timestamp,
                                     ssrc)
                
                packets.append(header + payload)
                packet_index += 1
            
            # Final validation
            total_samples_sent = sum(len(p) - 12 for p in packets)  # Subtract RTP header size
            logger.info(f"✅ Created {len(packets)} HD VOICE RTP packets (16kHz G.722)")
            logger.debug(f"📊 HD VOICE Pipeline: 24kHz({sample_count}s)→16kHz→G.722({total_samples_sent}bytes)→RTP")
            
        except Exception as e:
            logger.warning(f"⚠️  Error creating RTP packets for AI audio: {e} - creating silence packets instead")
            import traceback
            logger.debug(f"Stack trace: {traceback.format_exc()}")
            
            # Create silence packets as fallback to keep conversation going
            try:
                silence_data = b'\x00' * len(ai_audio_data)
                logger.info(f"🔇 Creating silence packets as fallback ({len(silence_data)} bytes)")
                
                # Simple RTP packet creation for silence
                from .audio_codec import pcm_to_alaw, resample_simple
                
                # Resample silence to 8kHz
                pcm_8khz_data = resample_simple(silence_data, from_rate=24000, to_rate=8000)
                alaw_data = pcm_to_alaw(pcm_8khz_data)
                
                # Create basic RTP packets
                chunk_size = 80  # 10ms at 8kHz
                for i in range(0, len(alaw_data), chunk_size):
                    chunk = alaw_data[i:i+chunk_size]
                    if len(chunk) == chunk_size:  # Only full chunks
                        # Create minimal RTP header
                        header = struct.pack('>BBHII', 0x80, 8, 
                                           self._ai_sequence_number & 0xFFFF,
                                           int(self._ai_timestamp_base + i * 10) & 0xFFFFFFFF,
                                           0x87654321)
                        packets.append(header + chunk)
                        self._ai_sequence_number += 1
                        
                logger.info(f"✅ Created {len(packets)} silence packets as fallback")
            except Exception as fallback_error:
                logger.warning(f"⚠️  Could not create silence packets either: {fallback_error}")
            
        return packets
    
    def get_bridge_port(self) -> Optional[int]:
        """Get the local bridge port."""
        return self.local_port
    
    def stop_bridge(self) -> None:
        """Stop the RTP bridge."""
        self.running = False
        
        # Clean up UPnP port forwarding
        self._cleanup_upnp()
        
        # Close WAV recording files
        if self.record_audio:
            if self.caller_wav_recorder:
                self.caller_wav_recorder.close()
                logger.info(f"🎵 Caller WAV recording closed: {self.caller_packets_recorded} packets")
            if self.remote_wav_recorder:
                self.remote_wav_recorder.close()
                logger.info(f"🎵 Remote WAV recording closed: {self.remote_packets_recorded} packets")
        
        if self.socket:
            self.socket.close()
        logger.info(f"🛑 RTP Bridge stopped - Final stats: {self.packets_forwarded} forwarded, {self.packets_to_ai} to AI, {self.packets_from_ai} from AI")
    
    def _cleanup_upnp(self) -> None:
        """Clean up UPnP port forwarding when bridge stops."""
        if self.upnp_enabled and self.local_port:
            try:
                from ..utils.network import upnp_manager
                upnp_manager.remove_port(self.local_port, 'UDP')
                logger.info(f"🧹 Cleaned up UPnP forwarding for port {self.local_port}")
            except Exception as e:
                logger.warning(f"⚠️  UPnP cleanup error: {e}") 

================================================================================

----- FILE: callie_caller/sip/sdp.py -----

"""
SDP (Session Description Protocol) parser for extracting audio parameters.
Handles parsing of SDP content from SIP responses to get RTP connection details.
"""

import logging
import re
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class AudioParams:
    """Audio parameters extracted from SDP."""
    ip_address: str
    port: int
    codecs: List[Dict[str, str]]  # [{"payload": "0", "codec": "PCMU", "rate": "8000"}]
    rtcp_port: Optional[int] = None

@dataclass 
class SdpSession:
    """Complete SDP session information."""
    session_name: str
    audio: Optional[AudioParams] = None
    video: Optional[AudioParams] = None

class SdpParser:
    """Parser for SDP content in SIP messages."""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def parse_sdp(self, sdp_content: str) -> Optional[SdpSession]:
        """
        Parse SDP content and extract session information.
        
        Args:
            sdp_content: Raw SDP content from SIP message body
            
        Returns:
            SdpSession object with parsed information or None if invalid
        """
        if not sdp_content or not sdp_content.strip():
            self.logger.warning("Empty SDP content provided")
            return None
            
        try:
            lines = sdp_content.strip().split('\n')
            session = SdpSession(session_name="")
            
            # Current connection info (applies to subsequent media)
            current_ip = None
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # Parse line type=value format
                if '=' not in line:
                    continue
                    
                line_type = line[0]
                content = line[2:]  # Skip "x="
                
                if line_type == 's':  # Session name
                    session.session_name = content
                    
                elif line_type == 'c':  # Connection information
                    # c=IN IP4 192.168.1.100
                    current_ip = self._parse_connection_line(content)
                    
                elif line_type == 'm':  # Media description
                    # m=audio 12345 RTP/AVP 0 8 18 101
                    media_type, port, protocol, codecs = self._parse_media_line(content)
                    
                    if media_type == 'audio':
                        audio_params = AudioParams(
                            ip_address=current_ip or "0.0.0.0",
                            port=port,
                            codecs=[]
                        )
                        
                        # Parse codec payload types
                        for codec_payload in codecs:
                            audio_params.codecs.append({
                                "payload": codec_payload,
                                "codec": "unknown",
                                "rate": "8000"
                            })
                            
                        session.audio = audio_params
                        
                elif line_type == 'a':  # Attributes
                    # a=rtpmap:0 PCMU/8000
                    # a=rtpmap:8 PCMA/8000
                    # a=rtcp:12346
                    self._parse_attribute_line(content, session)
            
            self.logger.info(f"Parsed SDP session: {session.session_name}")
            if session.audio:
                self.logger.info(f"Audio: {session.audio.ip_address}:{session.audio.port}")
                self.logger.info(f"Codecs: {len(session.audio.codecs)} available")
                
            return session
            
        except Exception as e:
            self.logger.error(f"Error parsing SDP: {e}")
            return None
    
    def _parse_connection_line(self, content: str) -> Optional[str]:
        """Parse connection line: IN IP4 192.168.1.100"""
        try:
            parts = content.split()
            if len(parts) >= 3 and parts[0] == 'IN' and parts[1] == 'IP4':
                ip_address = parts[2]
                self.logger.debug(f"Parsed connection IP: {ip_address}")
                return ip_address
        except Exception as e:
            self.logger.error(f"Error parsing connection line '{content}': {e}")
        return None
    
    def _parse_media_line(self, content: str) -> Tuple[str, int, str, List[str]]:
        """Parse media line: audio 12345 RTP/AVP 0 8 18 101"""
        try:
            parts = content.split()
            media_type = parts[0]  # audio, video
            port = int(parts[1])
            protocol = parts[2]    # RTP/AVP
            codec_payloads = parts[3:]  # [0, 8, 18, 101]
            
            self.logger.debug(f"Parsed media: {media_type} port {port} codecs {codec_payloads}")
            return media_type, port, protocol, codec_payloads
            
        except Exception as e:
            self.logger.error(f"Error parsing media line '{content}': {e}")
            return "", 0, "", []
    
    def _parse_attribute_line(self, content: str, session: SdpSession) -> None:
        """Parse attribute lines like rtpmap and rtcp."""
        try:
            if content.startswith('rtpmap:'):
                # rtpmap:0 PCMU/8000
                # rtpmap:8 PCMA/8000  
                # rtpmap:18 G729/8000
                match = re.match(r'rtpmap:(\d+)\s+([^/]+)/(\d+)', content)
                if match and session.audio:
                    payload_type = match.group(1)
                    codec_name = match.group(2)
                    sample_rate = match.group(3)
                    
                    # Update the codec info
                    for codec in session.audio.codecs:
                        if codec["payload"] == payload_type:
                            codec["codec"] = codec_name
                            codec["rate"] = sample_rate
                            break
                            
                    self.logger.debug(f"Mapped codec: payload {payload_type} = {codec_name}/{sample_rate}")
                    
            elif content.startswith('rtcp:'):
                # rtcp:12346
                match = re.match(r'rtcp:(\d+)', content)
                if match and session.audio:
                    session.audio.rtcp_port = int(match.group(1))
                    self.logger.debug(f"RTCP port: {session.audio.rtcp_port}")
                    
        except Exception as e:
            self.logger.error(f"Error parsing attribute '{content}': {e}")

def extract_audio_params_from_sip_response(sip_response_body: str) -> Optional[AudioParams]:
    """
    Convenience function to extract audio parameters from SIP response body.
    
    Args:
        sip_response_body: Body content of SIP 200 OK response
        
    Returns:
        AudioParams object or None
    """
    parser = SdpParser()
    session = parser.parse_sdp(sip_response_body)
    return session.audio if session else None 

================================================================================

----- FILE: callie_caller/utils/network.py -----

import subprocess
import logging
import socket
from typing import Optional, Tuple

logger = logging.getLogger(__name__)

def get_local_ip() -> str:
    """
    Get the local IP address of this machine.
    Used for SIP and RTP communication.
    """
    try:
        # Connect to a remote address to determine which local interface to use
        # We use Google's DNS (8.8.8.8) but don't actually send any data
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
            s.connect(("8.8.8.8", 80))
            local_ip = s.getsockname()[0]
            logger.info(f"🏠 Local IP determined: {local_ip}")
            return local_ip
    except Exception:
        # Fallback to localhost if the above fails
        logger.warning("Could not determine local IP, using localhost")
        return "127.0.0.1"


def get_public_ip() -> Optional[str]:
    """
    Retrieves the public IP address of the machine using an external service.
    This is crucial for NAT traversal, as this IP will be advertised in the SDP
    so the remote party knows where to send RTP (audio) packets.
    """
    try:
        # Using 'curl' to an external service is a common way to find the public IP.
        # We use a short timeout to prevent long delays.
        ip = subprocess.check_output(
            ['curl', '-s', '--max-time', '3', 'https://api.ipify.org'],
            stderr=subprocess.DEVNULL
        ).decode('utf-8').strip()
        
        # Basic validation of the result
        if ip and '.' in ip:
            logger.info(f"🌍 Public IP discovered: {ip}")
            return ip
        logger.warning("Failed to parse public IP from service response.")
        return None
    except FileNotFoundError:
        logger.warning("curl command not found, cannot determine public IP.")
        return None
    except subprocess.CalledProcessError:
        logger.warning("Calling public IP service failed.")
        return None
    except Exception as e:
        logger.error(f"An unexpected error occurred while getting public IP: {e}")
        return None


class UPnPManager:
    """Manages UPnP port forwarding for NAT traversal."""
    
    def __init__(self):
        self.upnp = None
        self.forwarded_ports = []
        self.enabled = False
        
    def initialize(self) -> bool:
        """Initialize UPnP and discover router."""
        try:
            import miniupnpc
            
            self.upnp = miniupnpc.UPnP()
            self.upnp.discoverdelay = 2000  # 2 seconds
            
            logger.info("🔍 Discovering UPnP devices...")
            device_count = self.upnp.discover()
            
            if device_count > 0:
                logger.info(f"📡 Found {device_count} UPnP device(s)")
                
                # Select the first valid IGD (Internet Gateway Device)
                self.upnp.selectigd()
                
                # Get external IP to verify connection
                external_ip = self.upnp.externalipaddress()
                local_ip = self.upnp.lanaddr
                
                logger.info(f"🌐 UPnP Router found:")
                logger.info(f"   • External IP: {external_ip}")
                logger.info(f"   • Local IP: {local_ip}")
                logger.info(f"   • Router: {getattr(self.upnp, 'statusinfo', 'Unknown')}")
                
                self.enabled = True
                return True
            else:
                logger.warning("⚠️  No UPnP devices found - router may not support UPnP")
                return False
                
        except ImportError:
            logger.error("❌ miniupnpc library not installed. Install with: pip install miniupnpc")
            return False
        except Exception as e:
            logger.error(f"❌ UPnP initialization failed: {e}")
            return False
    
    def forward_port(self, port: int, protocol: str = 'UDP', description: str = 'Callie RTP') -> bool:
        """
        Forward a specific port through UPnP.
        
        Args:
            port: Port number to forward
            protocol: Protocol (UDP/TCP)
            description: Description for the forwarding rule
            
        Returns:
            True if successful
        """
        if not self.enabled or not self.upnp:
            return False
            
        try:
            # Add port mapping
            success = self.upnp.addportmapping(
                port,           # external port
                protocol,       # protocol
                self.upnp.lanaddr,  # internal IP
                port,           # internal port
                description,    # description
                ''              # remote host (empty for all)
            )
            
            if success:
                logger.info(f"✅ UPnP port forwarding: {protocol} {port} → {self.upnp.lanaddr}:{port}")
                self.forwarded_ports.append((port, protocol))
                return True
            else:
                logger.warning(f"⚠️  UPnP port forwarding failed for {protocol} {port}")
                return False
                
        except Exception as e:
            logger.error(f"❌ UPnP port forwarding error: {e}")
            return False
    
    def forward_port_range(self, start_port: int, end_port: int, protocol: str = 'UDP') -> Tuple[int, int]:
        """
        Forward a range of ports through UPnP.
        
        Args:
            start_port: Start of port range
            end_port: End of port range
            protocol: Protocol (UDP/TCP)
            
        Returns:
            Tuple of (successful_forwards, total_attempted)
        """
        if not self.enabled:
            return (0, 0)
            
        successful = 0
        total = end_port - start_port + 1
        
        logger.info(f"🔄 Setting up UPnP port forwarding for {protocol} ports {start_port}-{end_port}")
        
        for port in range(start_port, end_port + 1):
            if self.forward_port(port, protocol, f'Callie RTP {port}'):
                successful += 1
            
        logger.info(f"📊 UPnP forwarding complete: {successful}/{total} ports configured")
        return (successful, total)
    
    def remove_port(self, port: int, protocol: str = 'UDP') -> bool:
        """Remove a port forwarding rule."""
        if not self.enabled or not self.upnp:
            return False
            
        try:
            success = self.upnp.deleteportmapping(port, protocol)
            if success:
                logger.info(f"🗑️  Removed UPnP forwarding for {protocol} {port}")
                self.forwarded_ports = [(p, prot) for p, prot in self.forwarded_ports if not (p == port and prot == protocol)]
            return success
        except Exception as e:
            logger.error(f"❌ Error removing UPnP forwarding: {e}")
            return False
    
    def cleanup(self) -> None:
        """Remove all port forwarding rules created by this session."""
        if not self.enabled or not self.upnp:
            return
            
        logger.info("🧹 Cleaning up UPnP port forwarding rules...")
        
        for port, protocol in self.forwarded_ports[:]:
            try:
                self.upnp.deleteportmapping(port, protocol)
                logger.info(f"🗑️  Removed {protocol} {port}")
            except Exception as e:
                logger.warning(f"⚠️  Failed to remove {protocol} {port}: {e}")
        
        self.forwarded_ports.clear()
        logger.info("✅ UPnP cleanup complete")
    
    def list_existing_mappings(self) -> list:
        """List existing port mappings (for debugging)."""
        if not self.enabled or not self.upnp:
            return []
            
        mappings = []
        try:
            i = 0
            while True:
                mapping = self.upnp.getgenericportmapping(i)
                if mapping is None:
                    break
                mappings.append(mapping)
                i += 1
        except Exception:
            pass  # End of list
            
        return mappings

# Global UPnP manager instance
upnp_manager = UPnPManager() 

================================================================================

----- FILE: cloudrun.yml -----

apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: callie-caller
  annotations:
    run.googleapis.com/ingress: all
    run.googleapis.com/execution-environment: gen2
spec:
  template:
    metadata:
      annotations:
        run.googleapis.com/cpu-boost: true
        autoscaling.knative.dev/maxScale: "10"
        autoscaling.knative.dev/minScale: "0"
    spec:
      containerConcurrency: 1000
      timeoutSeconds: 3600
      containers:
      - image: us-central1-docker.pkg.dev/yc-partners/callie-caller/callie-caller:latest
        ports:
        - name: http1
          containerPort: 8080
        env:
        # SIP Configuration
        - name: ZOHO_SIP_SERVER
          value: "us3-proxy2.zohovoice.com"
        - name: ZOHO_SIP_USERNAME
          valueFrom:
            secretKeyRef:
              key: latest
              name: zoho-sip-username
        - name: ZOHO_SIP_PASSWORD
          valueFrom:
            secretKeyRef:
              key: latest
              name: zoho-sip-password
        - name: ZOHO_SIP_BACKUP_SERVER
          value: "us4-proxy2.zohovoice.com"
        - name: ACCOUNT_LABEL
          value: "Troy Fortin"
        - name: CUSTOM_USER_AGENT
          value: "00:1a:2b:3c:4d:5e"
        
        # AI Configuration
        - name: GEMINI_API_KEY
          valueFrom:
            secretKeyRef:
              key: latest
              name: gemini-api-key
        
        # Cloud Run Specific Configuration
        - name: USE_UPNP
          value: "false"
        - name: CONTAINER_MODE
          value: "true"
        - name: CLOUD_RUN_MODE
          value: "true"
        - name: LOG_LEVEL
          value: "INFO"
        - name: PYTHONUNBUFFERED
          value: "1"
        
        # Port Configuration
        - name: FLASK_PORT
          value: "8080"
        - name: SERVER_PORT
          value: "8080"
        - name: SIP_PORT
          value: "5060"
        
        # Test Configuration
        - name: TEST_CALL_NUMBER
          value: "+16782960086"
        
        resources:
          limits:
            cpu: "2"
            memory: "2Gi"
          requests:
            cpu: "1"
            memory: "512Mi"
        
        # Health check
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
        
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5 

================================================================================

----- FILE: deploy-cloudrun.sh -----

#!/bin/bash

# Callie Caller - Cloud Run Deployment Script
# This script handles deployment to Google Cloud Run without UPnP

set -e

PROJECT_ID="yc-partners"
REGION="us-central1"
SERVICE_NAME="callie-caller"
REPOSITORY="callie-caller"
IMAGE_NAME="callie-caller"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Check if gcloud is authenticated
check_auth() {
    if ! gcloud auth list --filter=status:ACTIVE --format="value(account)" | grep -q .; then
        error "Not authenticated with gcloud. Run 'gcloud auth login'"
        exit 1
    fi
    success "Authenticated with gcloud"
}

# Enable required APIs
enable_apis() {
    log "Enabling required Google Cloud APIs..."
    gcloud services enable \
        cloudbuild.googleapis.com \
        run.googleapis.com \
        artifactregistry.googleapis.com \
        secretmanager.googleapis.com \
        --project=$PROJECT_ID
    success "APIs enabled"
}

# Create Artifact Registry repository if it doesn't exist
setup_registry() {
    log "Setting up Artifact Registry..."
    if ! gcloud artifacts repositories describe $REPOSITORY \
        --location=$REGION \
        --project=$PROJECT_ID &>/dev/null; then
        
        log "Creating Artifact Registry repository..."
        gcloud artifacts repositories create $REPOSITORY \
            --repository-format=docker \
            --location=$REGION \
            --description="Callie Caller AI Voice Agent" \
            --project=$PROJECT_ID
        success "Artifact Registry repository created"
    else
        success "Artifact Registry repository already exists"
    fi
}

# Configure Docker authentication
configure_docker() {
    log "Configuring Docker authentication..."
    gcloud auth configure-docker $REGION-docker.pkg.dev --quiet
    success "Docker authentication configured"
}

# Build and push Docker image
build_and_push() {
    VERSION=${1:-latest}
    IMAGE_URI="$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:$VERSION"
    
    log "Building Docker image..."
    docker build \
        --build-arg VERSION=$VERSION \
        --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
        --build-arg VCS_REF=$(git rev-parse --short HEAD 2>/dev/null || echo "unknown") \
        --tag $IMAGE_URI \
        .
    
    log "Pushing Docker image to Artifact Registry..."
    docker push $IMAGE_URI
    
    success "Image pushed: $IMAGE_URI"
    echo $IMAGE_URI
}

# Deploy to Cloud Run
deploy() {
    VERSION=${1:-latest}
    IMAGE_URI="$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:$VERSION"
    
    log "Deploying to Cloud Run..."
    
    # Create a temporary service configuration
    cat > /tmp/cloudrun-service.yaml << EOF
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: $SERVICE_NAME
  annotations:
    run.googleapis.com/ingress: all
    run.googleapis.com/execution-environment: gen2
spec:
  template:
    metadata:
      annotations:
        run.googleapis.com/cpu-boost: true
        autoscaling.knative.dev/maxScale: "10"
        autoscaling.knative.dev/minScale: "1"
    spec:
      containerConcurrency: 1000
      timeoutSeconds: 3600
      containers:
      - image: $IMAGE_URI
        ports:
        - name: http1
          containerPort: 8080
        env:
        # SIP Configuration
        - name: ZOHO_SIP_SERVER
          value: "us3-proxy2.zohovoice.com"
        - name: ZOHO_SIP_USERNAME
          valueFrom:
            secretKeyRef:
              key: latest
              name: zoho-sip-username
        - name: ZOHO_SIP_PASSWORD
          valueFrom:
            secretKeyRef:
              key: latest
              name: zoho-sip-password
        - name: ZOHO_SIP_BACKUP_SERVER
          value: "us4-proxy2.zohovoice.com"
        - name: ACCOUNT_LABEL
          value: "Troy Fortin"
        - name: CUSTOM_USER_AGENT
          value: "00:1a:2b:3c:4d:5e"
        
        # AI Configuration
        - name: GEMINI_API_KEY
          valueFrom:
            secretKeyRef:
              key: latest
              name: gemini-api-key
        
        # Cloud Run Specific - NO UPnP
        - name: USE_UPNP
          value: "false"
        - name: CONTAINER_MODE
          value: "true"
        - name: CLOUD_RUN_MODE
          value: "true"
        - name: LOG_LEVEL
          value: "INFO"
        - name: PYTHONUNBUFFERED
          value: "1"
        
        # Port Configuration
        - name: FLASK_PORT
          value: "8080"
        - name: SERVER_PORT
          value: "8080"
        - name: SIP_PORT
          value: "5060"
        
        # Test Configuration
        - name: TEST_CALL_NUMBER
          value: "+16782960086"
        
        resources:
          limits:
            cpu: "2"
            memory: "2Gi"
          requests:
            cpu: "1"
            memory: "512Mi"
        
        # Health checks
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
        
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
EOF

    # Deploy the service
    gcloud run services replace /tmp/cloudrun-service.yaml \
        --region=$REGION \
        --project=$PROJECT_ID
    
    # Clean up temp file
    rm /tmp/cloudrun-service.yaml
    
    # Get the service URL
    SERVICE_URL=$(gcloud run services describe $SERVICE_NAME \
        --region=$REGION \
        --project=$PROJECT_ID \
        --format="value(status.url)")
    
    success "Deployed to Cloud Run!"
    echo "Service URL: $SERVICE_URL"
    echo "Health Check: $SERVICE_URL/health"
    echo ""
    warning "Important for SIP without UPnP:"
    echo "- Cloud Run provides automatic public IP"
    echo "- No UPnP configuration needed"
    echo "- SIP traffic routes through Zoho's infrastructure"
    echo "- Test calls should work immediately"
}

# Test the deployment
test_deployment() {
    SERVICE_URL=$(gcloud run services describe $SERVICE_NAME \
        --region=$REGION \
        --project=$PROJECT_ID \
        --format="value(status.url)" 2>/dev/null)
    
    if [ -z "$SERVICE_URL" ]; then
        error "Service not found. Deploy first."
        exit 1
    fi
    
    log "Testing health endpoint..."
    if curl -s "$SERVICE_URL/health" | grep -q "healthy"; then
        success "Health check passed"
    else
        error "Health check failed"
        exit 1
    fi
    
    log "Making test call..."
    echo "You can test a call by visiting: $SERVICE_URL"
    echo "Or via API: curl -X POST $SERVICE_URL/call -d '{\"number\":\"+14044626406\",\"message\":\"Cloud Run test\"}'"
}

# Main execution
case "${1:-deploy}" in
    "setup")
        log "Setting up Cloud Run environment..."
        check_auth
        enable_apis
        setup_registry
        configure_docker
        success "Setup complete!"
        ;;
    "build")
        VERSION=${2:-latest}
        log "Building and pushing image..."
        check_auth
        setup_registry
        configure_docker
        build_and_push $VERSION
        ;;
    "deploy")
        VERSION=${2:-latest}
        log "Full deployment (build + deploy)..."
        check_auth
        enable_apis
        setup_registry
        configure_docker
        build_and_push $VERSION
        deploy $VERSION
        ;;
    "deploy-only")
        VERSION=${2:-latest}
        log "Deploying existing image..."
        check_auth
        deploy $VERSION
        ;;
    "test")
        log "Testing deployment..."
        test_deployment
        ;;
    "logs")
        log "Showing Cloud Run logs..."
        gcloud logs read "resource.type=cloud_run_revision AND resource.labels.service_name=$SERVICE_NAME" \
            --project=$PROJECT_ID \
            --limit=50
        ;;
    *)
        echo "Usage: $0 {setup|build|deploy|deploy-only|test|logs} [version]"
        echo ""
        echo "Commands:"
        echo "  setup      - Set up Google Cloud environment"
        echo "  build      - Build and push Docker image"
        echo "  deploy     - Full deployment (build + deploy)"
        echo "  deploy-only- Deploy existing image"
        echo "  test       - Test the deployment"
        echo "  logs       - Show recent logs"
        echo ""
        echo "Examples:"
        echo "  $0 setup"
        echo "  $0 deploy v1.0.0"
        echo "  $0 test"
        exit 1
        ;;
esac 

================================================================================

----- FILE: docker-compose.yml -----

version: '3.8'

services:
  callie-caller:
    build:
      context: .
      dockerfile: Dockerfile.cloudrun-full
      args:
        VERSION: ${VERSION:-1.0.0}
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
        BUILD_NUMBER: ${BUILD_NUMBER}
    image: callie-caller-full:${VERSION:-latest}
    container_name: callie-caller
    restart: unless-stopped
    
    # Load environment from file
    env_file:
      - docker.env
    
    # Additional environment configuration
    environment:
      # Container-specific settings
      - PYTHONUNBUFFERED=1
      # Force disable UPnP in containers
      - USE_UPNP=false
      # Set container-friendly networking
      - CONTAINER_MODE=true
    
    # Port mapping - critical for SIP/RTP
    ports:
      - "${SERVER_PORT:-8080}:8080"
      # SIP signaling port
      - "5060:5060/udp"
      # RTP port range for audio (wider range for container flexibility)
      - "10000-10100:10000-10100/udp"
    
    # Volume mounts
    volumes:
      # Persistent storage for logs and recordings
      - callie_logs:/app/logs
      - callie_audio:/app/captured_audio
      # Optional: Mount config file if needed
      - ./docker.env:/app/.env:ro
    
    # Network configuration - use host network for better SIP compatibility
    network_mode: "bridge"
    
    # DNS configuration for better SIP resolution
    dns:
      - 8.8.8.8
      - 1.1.1.1
    
    # Health check
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8080/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    
    # Resource limits (adjust based on needs)
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    
    # Security options
    security_opt:
      - no-new-privileges:true
    
    # For debugging - remove in production
    # Default command uses main-cloudrun-full.py for full SIP support
    # command: ["python", "main-cloudrun-full.py"]

# Named volumes for persistent data
volumes:
  callie_logs:
    driver: local
  callie_audio:
    driver: local

# Optional: Use host networking for maximum SIP compatibility (alternative approach)
# Uncomment this and comment out the ports section above if you have issues
# services:
#   callie-caller:
#     network_mode: "host"
#     # Remove ports section when using host networking 

================================================================================

----- FILE: main-cloudrun-full.py -----

#!/usr/bin/env python3
"""
Callie Caller - Cloud Run Full SIP Entry Point
This version uses the full SIP agent optimized for Cloud Run deployment.
"""

import os
import sys
import logging
from callie_caller.core.logging import setup_logging

# Configure logging first
setup_logging()
logger = logging.getLogger(__name__)

def main():
    """Main entry point for Cloud Run with full SIP capabilities."""
    logger.info("🤖 Callie Caller v1.0.0 - AI Voice Agent (Cloud Run Full SIP Mode)")
    
    # Set Cloud Run specific environment variables
    os.environ["USE_UPNP"] = "false"  # Disable UPnP in Cloud Run
    os.environ["CONTAINER_MODE"] = "true"
    os.environ["CLOUD_RUN_MODE"] = "true"
    
    # Ensure PORT is set correctly for Cloud Run
    if "PORT" not in os.environ:
        os.environ["PORT"] = "8080"
    
    try:
        # Import the full agent
        from callie_caller.core.agent import CallieAgent
        
        # Create and start the agent
        agent = CallieAgent()
        
        logger.info("🌐 Starting Cloud Run agent with full SIP capabilities...")
        logger.info("📋 Cloud Run Configuration:")
        logger.info("   • UPnP disabled (using fixed ports)")
        logger.info("   • VPC networking enabled")
        logger.info("   • Firewall rules configured for SIP/RTP")
        logger.info("   • API endpoints available for triggering calls")
        
        # Start the agent (this includes SIP client and web server)
        agent.start()
        
        # Get port from environment (Cloud Run sets PORT)
        port = int(os.getenv("PORT", "8080"))
        
        logger.info(f"🚀 Cloud Run agent started successfully!")
        logger.info(f"📞 SIP calling available via API endpoints")
        logger.info(f"🌐 Web interface: http://0.0.0.0:{port}")
        
        # Keep the application running
        try:
            # The agent's Flask server is already running in a thread
            # Just keep the main thread alive
            import time
            while True:
                time.sleep(60)
                logger.info("🔄 Cloud Run agent running...")
        except KeyboardInterrupt:
            logger.info("👋 Shutting down gracefully...")
            agent.stop()
        
    except KeyboardInterrupt:
        logger.info("👋 Shutting down gracefully...")
        sys.exit(0)
    except Exception as e:
        logger.error(f"❌ Fatal error: {e}")
        import traceback
        logger.error(f"Stack trace: {traceback.format_exc()}")
        sys.exit(1)

if __name__ == "__main__":
    main() 

================================================================================

----- FILE: main-cloudrun.py -----

#!/usr/bin/env python3
"""
Callie Caller - Cloud Run Entry Point
This version is optimized for Cloud Run deployment without direct SIP capabilities.
"""

import os
import sys
import logging
from callie_caller.core.logging import setup_logging

# Configure logging first
setup_logging()
logger = logging.getLogger(__name__)

def main():
    """Main entry point for Cloud Run deployment."""
    logger.info("🤖 Callie Caller v1.0.0 - AI Voice Agent (Cloud Run Mode)")
    
    # Check if running in Cloud Run mode
    cloud_run_mode = os.getenv("CLOUD_RUN_MODE", "false").lower() == "true"
    if not cloud_run_mode:
        logger.warning("⚠️  Not in Cloud Run mode, switching to local development")
    
    try:
        # Import the web-only application for Cloud Run
        from callie_caller.core.web_agent import create_app
        
        # Create Flask app (web-only mode)
        app = create_app()
        
        # Get port from environment (Cloud Run sets PORT)
        port = int(os.getenv("PORT", os.getenv("FLASK_PORT", "8080")))
        host = os.getenv("FLASK_HOST", "0.0.0.0")
        
        logger.info(f"🌐 Starting web server on {host}:{port}")
        logger.info("📋 Cloud Run Limitations:")
        logger.info("   • SIP calling requires external SIP infrastructure")
        logger.info("   • Use Cloud Functions or external services for SIP")
        logger.info("   • Web API available for call management")
        
        # Start the web server
        app.run(
            host=host,
            port=port,
            debug=False,
            threaded=True,
            use_reloader=False
        )
        
    except KeyboardInterrupt:
        logger.info("👋 Shutting down gracefully...")
        sys.exit(0)
    except Exception as e:
        logger.error(f"❌ Fatal error: {e}")
        import traceback
        logger.error(f"Stack trace: {traceback.format_exc()}")
        sys.exit(1)

if __name__ == "__main__":
    main() 

================================================================================

----- FILE: main.py -----

#!/usr/bin/env python3
"""
Main entry point for Callie Caller - AI Voice Agent.
Run this script to start the AI voice assistant.
"""

import argparse
import asyncio
import signal
import sys
import time
import logging
from pathlib import Path

from callie_caller.core.agent import CallieAgent
from callie_caller.config.settings import get_settings
from callie_caller.core.logging import setup_logging
from callie_caller import __version__, get_version_info

logger = logging.getLogger(__name__)

class GracefulShutdown:
    """Handle graceful shutdown of the agent."""
    def __init__(self):
        self.agent = None
        self.shutdown_requested = False

    def __call__(self, signum, frame):
        if self.shutdown_requested:
            logger.warning("Force shutdown requested")
            sys.exit(1)
        
        self.shutdown_requested = True
        logger.info("Shutdown signal received, stopping Callie Agent...")
        
        if self.agent:
            try:
                self.agent.stop()
            except Exception as e:
                logger.error(f"Error during shutdown: {e}")
        
        sys.exit(0)

def main():
    """Main entry point for the Callie Caller application."""
    parser = argparse.ArgumentParser(
        description="Callie Caller - AI Voice Agent for phone conversations",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python main.py                     # Start the agent in server mode
  python main.py --debug            # Start with debug logging
  python main.py --config-check     # Verify configuration
  python main.py --call +1234567890 # Make a test call
  python main.py --version          # Show version information
        """
    )
    
    parser.add_argument(
        '--version',
        action='store_true',
        help='Show version information and exit'
    )
    
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Enable debug logging'
    )
    
    parser.add_argument(
        '--config-check',
        action='store_true',
        help='Check configuration and exit'
    )
    
    parser.add_argument(
        '--call',
        type=str,
        help='Make a test call to the specified number and exit'
    )
    
    parser.add_argument(
        '--message',
        type=str,
        help='Custom message for test call (used with --call)'
    )
    
    parser.add_argument(
        '--log-file',
        type=str,
        help='Log file path (default: logs to console)'
    )
    
    args = parser.parse_args()
    
    # Handle version request
    if args.version:
        version_info = get_version_info()
        print(f"Callie Caller v{version_info['version']}")
        print(f"Build: {version_info['build']}")
        if version_info['commit'] != 'unknown':
            print(f"Commit: {version_info['commit']}")
        return 0
    
    # Setup logging
    log_level = "DEBUG" if args.debug else "INFO"
    setup_logging(level=log_level, log_file=args.log_file)
    
    # Setup graceful shutdown
    signal_handler = GracefulShutdown()
    
    logger.info(f"🤖 Callie Caller v{__version__} - AI Voice Agent")
    
    try:
        # Configuration check
        if args.config_check:
            logger.info("Checking configuration...")
            settings = get_settings()
            logger.info("Configuration validation successful:")
            logger.info(f"  SIP Server: {settings.zoho.sip_server}")
            logger.info(f"  Username: {settings.zoho.sip_username}")
            logger.info(f"  Device: {settings.device.user_agent}")
            logger.info(f"  AI Model: {settings.ai.model}")
            return 0
        
        # Initialize agent
        logger.info("Initializing Callie Agent...")
        agent = CallieAgent()
        signal_handler.agent = agent
        
        # Setup signal handlers
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        # Start agent
        logger.info("Starting AI voice agent...")
        agent.start()
        
        # Test call mode
        if args.call:
            logger.info(f"Making test call to {args.call}")
            success = agent.make_call(args.call, args.message)
            
            if success:
                logger.info("Call completed successfully")
                return 0
            else:
                logger.error("Call failed or was not answered")
                return 1
        
        # Normal operation mode
        logger.info("Callie Agent is running!")
        logger.info(f"Device emulation: {agent.settings.device.user_agent}")
        logger.info(f"Web interface: http://localhost:{agent.settings.server.port}")
        logger.info(f"Health check: http://localhost:{agent.settings.server.port}/health")
        
        if args.debug:
            logger.debug("Available endpoints:")
            logger.debug("  GET  /health        - Health check")
            logger.debug("  POST /call          - Make outbound call")
            logger.debug("  POST /sms           - SMS webhook")
            logger.debug("  GET  /conversations - Conversation history")
            logger.debug("  GET  /stats         - Agent statistics")
        
        logger.info("Press Ctrl+C to stop")
        
        # Keep running
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            signal_handler(signal.SIGINT, None)
            
    except KeyboardInterrupt:
        logger.info("Interrupted by user")
        return 1
    except Exception as e:
        logger.error(f"Application error: {e}")
        if args.debug:
            import traceback
            logger.debug(f"Stack trace: {traceback.format_exc()}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 

================================================================================

----- FILE: requirements.txt -----

# Production dependencies for Callie Caller

# Web server for SMS webhooks and API
Flask==3.0.0

# Google Generative AI SDK (new package)
google-genai==1.26.0

# Audio processing for real-time voice
pyaudio==0.2.11
numpy>=1.24.0
scipy>=1.10.0

# Environment variable management
python-dotenv==1.0.0

# HTTP requests for API calls
requests==2.31.0

# Optional: Better logging
structlog==23.2.0

# Optional: For enhanced CLI
click==8.1.7

# Development dependencies (optional)
# pytest==7.4.0
# black==23.3.0
# mypy==1.3.0 

google-generativeai>=0.8.0
flask>=2.3.0
pyaudio>=0.2.11
pydantic>=2.0.0
python-dotenv>=1.0.0
miniupnpc>=2.2.2 

================================================================================

