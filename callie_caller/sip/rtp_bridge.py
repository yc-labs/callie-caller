"""
RTP Bridge for bidirectional audio forwarding and AI integration.
Acts as a media proxy to capture and forward audio streams.
"""

import socket
import threading
import time
import logging
import os
import atexit
import struct
import wave
from dataclasses import dataclass
from typing import Optional, Callable, Any
from .sdp import AudioParams

logger = logging.getLogger(__name__)

@dataclass
class AudioEndpoint:
    """Represents an audio endpoint for RTP forwarding."""
    ip: str
    port: int
    socket: Optional[Any] = None

class WavRecorder:
    """Helper class for recording audio to WAV files."""
    
    def __init__(self, filename: str, sample_rate: int = 8000, channels: int = 1, sample_width: int = 2):
        self.filename = filename
        self.sample_rate = sample_rate
        self.channels = channels
        self.sample_width = sample_width
        self.wav_file = None
        self.packets_written = 0
        
    def open(self):
        """Open the WAV file for writing."""
        try:
            self.wav_file = wave.open(self.filename, 'wb')
            self.wav_file.setnchannels(self.channels)
            self.wav_file.setsampwidth(self.sample_width)
            self.wav_file.setframerate(self.sample_rate)
            logger.info(f"üéµ Opened WAV file: {self.filename} ({self.sample_rate}Hz, {self.channels}ch)")
        except Exception as e:
            logger.error(f"‚ùå Failed to open WAV file {self.filename}: {e}")
            
    def write_rtp_packet(self, rtp_data: bytes) -> bool:
        """Decode RTP packet and write PCM audio to WAV file."""
        try:
            if not self.wav_file or len(rtp_data) < 12:
                return False
                
            # Parse RTP header to get payload
            payload_type = rtp_data[1] & 0x7F
            payload = rtp_data[12:]  # Skip 12-byte RTP header
            
            if not payload:
                return False
                
            # Convert RTP payload to PCM
            pcm_data = self._convert_rtp_payload_to_pcm(payload, payload_type)
            if pcm_data:
                self.wav_file.writeframes(pcm_data)
                self.packets_written += 1
                return True
                
        except Exception as e:
            logger.error(f"‚ùå Error writing RTP to WAV: {e}")
            
        return False
        
    def _convert_rtp_payload_to_pcm(self, payload: bytes, payload_type: int) -> Optional[bytes]:
        """Convert RTP audio payload to PCM format with automatic gain control."""
        try:
            from .audio_codec import ulaw_to_pcm, alaw_to_pcm
            
            # Convert using standard G.711
            if payload_type == 0:  # PCMU (Œº-law)
                pcm_data = ulaw_to_pcm(payload)
            elif payload_type == 8:  # PCMA (A-law)  
                pcm_data = alaw_to_pcm(payload)
            else:
                logger.warning(f"Unsupported payload type {payload_type} for WAV recording")
                return None
                
            if not pcm_data:
                return None
                
            # ENHANCED: Apply Automatic Gain Control (AGC) for audible WAV recordings
            pcm_data = self._apply_agc_to_pcm(pcm_data)
            return pcm_data
                
        except Exception as e:
            logger.error(f"Error converting RTP payload: {e}")
            return None
            
    def _apply_agc_to_pcm(self, pcm_data: bytes) -> bytes:
        """Apply Automatic Gain Control (AGC) to make audio audible."""
        try:
            import struct
            import math
            
            if len(pcm_data) < 2:
                return pcm_data
                
            # Unpack samples
            sample_count = len(pcm_data) // 2
            samples = list(struct.unpack(f'<{sample_count}h', pcm_data))
            
            if not samples:
                return pcm_data
                
            # Calculate current audio levels
            max_amplitude = max(abs(s) for s in samples)
            rms = math.sqrt(sum(s*s for s in samples) / len(samples))
            
            # Only apply AGC if audio is too quiet (typical for G.711)
            if max_amplitude < 100:  # Very quiet, boost significantly
                gain = 150.0  # Increased from 50.0
            elif max_amplitude < 500:  # Quiet, boost moderately  
                gain = 60.0   # Increased from 20.0
            elif max_amplitude < 2000:  # Low but audible, boost gently
                gain = 20.0   # Increased from 8.0
            elif max_amplitude < 8000:  # Acceptable level, small boost
                gain = 5.0    # Increased from 3.0
            else:  # Already loud enough
                gain = 1.0
                
            # Apply gain with soft limiting to prevent harsh clipping
            boosted_samples = []
            for sample in samples:
                # Apply gain
                boosted = int(sample * gain)
                
                # Soft limiting to prevent harsh clipping
                if boosted > 20000:  # Soft limit at ~60% of max
                    boosted = 20000 + int((boosted - 20000) * 0.3)
                elif boosted < -20000:
                    boosted = -20000 + int((boosted + 20000) * 0.3)
                    
                # Hard limit to prevent overflow
                boosted = max(-32767, min(32767, boosted))
                boosted_samples.append(boosted)
            
            # Log AGC activity for debugging (only for first few packets)
            if not hasattr(self, '_agc_log_count'):
                self._agc_log_count = 0
            
            final_max = max(abs(s) for s in boosted_samples)
            if gain > 1.0 and self._agc_log_count < 3:
                logger.debug(f"üîä AGC applied: {max_amplitude} ‚Üí {final_max} (gain: {gain:.1f}x)")
                self._agc_log_count += 1
            
            # Pack back to bytes
            return struct.pack(f'<{len(boosted_samples)}h', *boosted_samples)
            
        except Exception as e:
            logger.error(f"‚ùå AGC error: {e}")
            return pcm_data  # Return original if AGC fails
            
    def close(self):
        """Close the WAV file."""
        if self.wav_file:
            try:
                self.wav_file.close()
                logger.info(f"üéµ Closed WAV file: {self.filename} ({self.packets_written} packets written)")
            except Exception as e:
                logger.error(f"‚ùå Error closing WAV file: {e}")
            finally:
                self.wav_file = None

class RtpBridge:
    """
    RTP bridge that forwards audio between two endpoints and captures for AI.
    Acts as a true media relay to intercept RTP packets.
    Enhanced with keepalive functionality to prevent network timeouts.
    """
    
    def __init__(self, local_ip: str):
        self.local_ip = local_ip
        self.local_port = None
        self.socket = None
        self.running = False
        self.upnp_enabled = False
        
        # **NEW: Keepalive functionality**
        self.keepalive_enabled = True
        self.keepalive_interval = 20.0  # Send keepalive every 20 seconds
        self.last_caller_packet_time = 0
        self.last_remote_packet_time = 0
        self.keepalive_thread: Optional[threading.Thread] = None
        self.keepalive_running = False
        self.keepalive_seq = 0
        
        # Test mode for debugging audio pipeline
        self.test_mode = False
        self.test_audio_file = None
        self.test_audio_data = None
        self.test_audio_packets = []
        self.test_packet_index = 0
        
        # AI audio streaming state - fixed for proper RTP timing
        self._ai_sequence_number = 0
        self._ai_timestamp_base = 0
        self._ai_samples_sent = 0  # Track samples sent for current stream
        self._is_first_ai_chunk = True # NEW: Flag to handle initial audio chunk
        
        # Silence injection to keep RTP stream alive
        self.silence_injection_thread: Optional[threading.Thread] = None
        self.silence_injection_running = False
        self.last_outgoing_rtp_time = 0
        
        # Endpoints - learned dynamically
        self.caller_endpoint: Optional[AudioEndpoint] = None  # Phone
        self.remote_endpoint: Optional[AudioEndpoint] = None  # Zoho server
        
        # Audio callbacks
        self.audio_callback: Optional[Callable] = None
        
        # Audio level callback for WebSocket updates
        self.audio_level_callback: Optional[Callable] = None
        
        # Transcription
        self.transcriber = None
        self.transcription_callback: Optional[Callable] = None
        
        # WAV recording for debugging
        # Only enable in debug mode since Zoho handles recording in production
        self.record_audio = os.getenv("ENABLE_WAV_RECORDING", "false").lower() == "true"
        self.audio_dir = "captured_audio"
        self.caller_wav_recorder: Optional[WavRecorder] = None
        self.remote_wav_recorder: Optional[WavRecorder] = None
        self.max_recording_packets = 500  # Increased limit for WAV files
        
        # Statistics
        self.packets_forwarded = 0
        self.packets_to_ai = 0
        self.packets_from_ai = 0
        self.caller_packets_recorded = 0
        self.remote_packets_recorded = 0
        
        # Setup recording directory
        if self.record_audio:
            os.makedirs(self.audio_dir, exist_ok=True)
        
        # Register cleanup function
        atexit.register(self._cleanup_upnp)
        
        logger.info(f"üåâ RTP Bridge initialized for {local_ip}")
        if self.record_audio:
            logger.info(f"üéµ WAV audio recording enabled - will save to {self.audio_dir}/")
    
    def start_bridge(self, remote_audio: Optional[AudioParams] = None) -> Optional[int]:
        """Start the RTP bridge and return the local listening port."""
        try:
            # Create UDP socket for RTP
            self.socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            
            # Try to bind to a specific port range for NAT traversal
            port_assigned = False
            from ..config import get_settings
            from ..utils.network import upnp_manager
            settings = get_settings()
            
            # Initialize UPnP if enabled
            try:
                if upnp_manager.initialize():
                    self.upnp_enabled = True
                    logger.info("üéØ UPnP enabled - will automatically configure port forwarding")
                else:
                    logger.warning("‚ö†Ô∏è  UPnP not available - manual port forwarding required")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  UPnP initialization failed: {e}")
            
            if hasattr(settings.calls, 'use_fixed_rtp_port') and settings.calls.use_fixed_rtp_port:
                # Try ports in the configured range
                port_min = getattr(settings.calls, 'rtp_port_min', 10000)
                port_max = getattr(settings.calls, 'rtp_port_max', 10100)
                
                logger.info(f"üîß NAT TRAVERSAL: Trying fixed port range {port_min}-{port_max}")
                
                for port in range(port_min, port_max + 1):
                    try:
                        self.socket.bind(("0.0.0.0", port))
                        self.local_port = port
                        port_assigned = True
                        
                        # Try UPnP port forwarding
                        if self.upnp_enabled:
                            if upnp_manager.forward_port(port, 'UDP', f'Callie RTP {port}'):
                                logger.info(f"üéØ RTP Bridge bound to FIXED PORT: 0.0.0.0:{port} (UPnP forwarded)")
                            else:
                                logger.info(f"üéØ RTP Bridge bound to FIXED PORT: 0.0.0.0:{port} (UPnP failed)")
                                logger.info(f"üìã MANUAL NAT SETUP: Forward UDP port {port} to {self.local_ip}:{port}")
                        else:
                            logger.info(f"üéØ RTP Bridge bound to FIXED PORT: 0.0.0.0:{port}")
                            logger.info(f"üìã MANUAL NAT SETUP: Forward UDP port {port} to {self.local_ip}:{port}")
                        break
                    except OSError:
                        continue  # Port in use, try next one
                        
                if not port_assigned:
                    logger.warning(f"‚ö†Ô∏è  All ports {port_min}-{port_max} in use, falling back to random port")
            
            if not port_assigned:
                # Fallback to random port (original behavior)
                self.socket.bind(("0.0.0.0", 0))  # Bind to all interfaces on any available port
                self.local_port = self.socket.getsockname()[1]
                
                # Try UPnP on random port
                if self.upnp_enabled:
                    if upnp_manager.forward_port(self.local_port, 'UDP', f'Callie RTP {self.local_port}'):
                        logger.info(f"üåâ RTP Bridge on random port {self.local_port} (UPnP forwarded)")
                    else:
                        logger.warning(f"üåâ RTP Bridge on random port {self.local_port} (UPnP failed)")
                        logger.warning(f"‚ö†Ô∏è  MANUAL SETUP: Forward UDP port {self.local_port} to {self.local_ip}:{self.local_port}")
                else:
                    logger.info(f"üåâ RTP Bridge listening on ALL INTERFACES::{self.local_port} (random port)")
                    logger.warning(f"‚ö†Ô∏è  MANUAL SETUP: Forward UDP port {self.local_port} to {self.local_ip}:{self.local_port}")
            
            logger.info(f"üîß NAT FIX: Bridge can receive packets sent to public IP")
            
            # Set remote endpoint if provided
            if remote_audio:
                self.remote_endpoint = AudioEndpoint(
                    ip=remote_audio.ip_address,
                    port=remote_audio.port
                )
                logger.info(f"üéØ Remote endpoint configured: {self.remote_endpoint.ip}:{self.remote_endpoint.port}")
            
            # Setup audio recording files - now as WAV files
            if self.record_audio:
                timestamp = int(time.time())
                
                # Create WAV recorders
                caller_filename = f"{self.audio_dir}/caller_audio_{timestamp}.wav"
                remote_filename = f"{self.audio_dir}/remote_audio_{timestamp}.wav"
                
                self.caller_wav_recorder = WavRecorder(caller_filename, sample_rate=8000)
                self.remote_wav_recorder = WavRecorder(remote_filename, sample_rate=8000)
                
                self.caller_wav_recorder.open()
                self.remote_wav_recorder.open()
                
                logger.info(f"üéµ WAV recording files created for session {timestamp}")
            
            # Initialize transcriber if callback is set
            if self.transcription_callback:
                try:
                    from callie_caller.audio.transcriber import AudioTranscriber
                    self.transcriber = AudioTranscriber(self.transcription_callback)
                    self.transcriber.start()
                    logger.info("üìù Audio transcription enabled")
                except Exception as e:
                    logger.error(f"Failed to initialize transcriber: {e}")
                    self.transcriber = None
            else:
                logger.warning("üìù No transcription callback set - transcription disabled")
            
            # Start bridge loop
            self.running = True
            bridge_thread = threading.Thread(target=self._bridge_loop, daemon=True)
            bridge_thread.start()
            
            # **NEW: Start keepalive thread**
            if self.keepalive_enabled:
                self.keepalive_running = True
                self.keepalive_thread = threading.Thread(target=self._keepalive_loop, daemon=True)
                self.keepalive_thread.start()
                logger.info("üîÑ RTP keepalive enabled - preventing network timeouts")
            
            # Start silence injection thread to maintain RTP stream
            self.silence_injection_running = True
            self.silence_injection_thread = threading.Thread(target=self._silence_injection_loop, daemon=True)
            self.silence_injection_thread.start()
            logger.info("üîá RTP silence injection enabled - maintaining continuous stream")
            
            return self.local_port
            
        except Exception as e:
            logger.error(f"‚ùå Failed to start RTP bridge: {e}")
            return None

    def set_remote_endpoint(self, remote_audio: AudioParams) -> None:
        """Set the remote endpoint after receiving 200 OK."""
        self.remote_endpoint = AudioEndpoint(
            ip=remote_audio.ip_address,
            port=remote_audio.port
        )
        
        # CRITICAL FIX: Also set caller_endpoint so AI audio can be sent immediately
        # In our setup, the remote endpoint (Zoho server) is where we send AI audio
        if not self.caller_endpoint:
            self.caller_endpoint = AudioEndpoint(
                ip=remote_audio.ip_address,
                port=remote_audio.port
            )
            logger.info(f"üéØ Caller endpoint initialized from SDP: {self.caller_endpoint.ip}:{self.caller_endpoint.port}")
        
        logger.info(f"üéØ Remote endpoint updated: {self.remote_endpoint.ip}:{self.remote_endpoint.port}")
    
    def set_audio_callback(self, callback: Callable[[bytes, str], None]) -> None:
        """Set callback for captured audio."""
        self.audio_callback = callback
        logger.info("üé§ Audio capture callback registered")
    
    def enable_test_mode(self, test_audio_file: str = None) -> bool:
        """Enable test mode to inject known audio instead of AI audio."""
        try:
            if not test_audio_file:
                # Create a simple test tone
                self._create_test_tone()
            else:
                # Load audio file
                if not self._load_test_audio_file(test_audio_file):
                    return False
            
            self.test_mode = True
            logger.info(f"üß™ Test mode enabled - will inject test audio instead of AI audio")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to enable test mode: {e}")
            return False
    
    def _create_test_tone(self) -> None:
        """Create a simple test tone for audio testing."""
        import math
        
        # Generate a 1kHz tone for 3 seconds at 8kHz sample rate
        sample_rate = 8000
        duration = 3.0
        frequency = 1000
        
        samples = []
        for i in range(int(sample_rate * duration)):
            # Generate sine wave
            sample = int(16000 * math.sin(2 * math.pi * frequency * i / sample_rate))
            samples.append(max(-32767, min(32767, sample)))  # Clamp to 16-bit range
        
        # Convert to PCM bytes
        pcm_data = struct.pack(f'<{len(samples)}h', *samples)
        
        # Convert PCM to Œº-law and create RTP packets
        self._create_test_rtp_packets(pcm_data)
        logger.info(f"üéµ Created test tone: {len(self.test_audio_packets)} RTP packets")
    
    def _load_test_audio_file(self, filename: str) -> bool:
        """Load audio file and convert to RTP packets for testing."""
        try:
            import wave
            
            # Open WAV file
            with wave.open(filename, 'rb') as wav_file:
                if wav_file.getnchannels() != 1:
                    logger.error("‚ùå Test audio file must be mono")
                    return False
                
                if wav_file.getsampwidth() != 2:
                    logger.error("‚ùå Test audio file must be 16-bit")
                    return False
                
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                
                # Resample to 8kHz if needed
                if sample_rate != 8000:
                    from .audio_codec import resample_simple
                    frames = resample_simple(frames, sample_rate, 8000, 2)
                
                self._create_test_rtp_packets(frames)
                logger.info(f"üéµ Loaded test audio: {filename} -> {len(self.test_audio_packets)} RTP packets")
                return True
                
        except Exception as e:
            logger.error(f"‚ùå Failed to load test audio file {filename}: {e}")
            return False
    
    def _create_test_rtp_packets(self, pcm_data: bytes) -> None:
        """Convert PCM audio to RTP packets for testing."""
        from .audio_codec import pcm_to_ulaw
        
        # Convert PCM to Œº-law
        ulaw_data = pcm_to_ulaw(pcm_data)
        
        # Split into RTP packet payloads (160 bytes each for 20ms at 8kHz)
        payload_size = 160
        self.test_audio_packets = []
        
        for i in range(0, len(ulaw_data), payload_size):
            payload = ulaw_data[i:i + payload_size]
            if len(payload) < payload_size:
                # Pad last packet with silence
                payload += b'\x7f' * (payload_size - len(payload))
            
            # Create RTP packet
            rtp_packet = self._create_rtp_packet_for_test_audio(payload, i // payload_size)
            if rtp_packet:
                self.test_audio_packets.append(rtp_packet)
    
    def _create_rtp_packet_for_test_audio(self, ulaw_payload: bytes, sequence: int) -> Optional[bytes]:
        """Create RTP packet for test audio."""
        try:
            # RTP header
            version = 2
            padding = 0
            extension = 0
            csrc_count = 0
            marker = 0
            payload_type = 0  # PCMU (Œº-law)
            sequence_number = sequence & 0xFFFF
            timestamp = (sequence * 160) & 0xFFFFFFFF  # 160 samples per packet at 8kHz
            ssrc = 0x12345678  # Test SSRC
            
            # Pack RTP header (12 bytes)
            byte0 = (version << 6) | (padding << 5) | (extension << 4) | csrc_count
            byte1 = (marker << 7) | payload_type
            
            header = struct.pack('!BBHII', byte0, byte1, sequence_number, timestamp, ssrc)
            return header + ulaw_payload
            
        except Exception as e:
            logger.error(f"‚ùå Error creating test RTP packet: {e}")
            return None
    
    def get_test_audio_packet(self) -> Optional[bytes]:
        """Get next test audio packet for injection."""
        if not self.test_mode or not self.test_audio_packets:
            return None
        
        packet = self.test_audio_packets[self.test_packet_index]
        self.test_packet_index = (self.test_packet_index + 1) % len(self.test_audio_packets)
        return packet
    
    def start_test_audio_injection(self) -> None:
        """Start injecting test audio immediately (simpler approach)."""
        if not self.test_mode or not self.test_audio_packets:
            logger.error("‚ùå Test mode not enabled or no test audio packets")
            return
        
        import threading
        import time
        
        def inject_test_audio_loop():
            logger.info("üß™ Starting test audio injection loop...")
            packet_count = 0
            
            while self.running and self.test_mode:
                if self.caller_endpoint:  # Send to learned caller endpoint, not remote_endpoint
                    test_packet = self.get_test_audio_packet()
                    if test_packet:
                        try:
                            # Send directly to caller endpoint (where Zoho expects our audio)
                            self.socket.sendto(test_packet, (self.caller_endpoint.ip, self.caller_endpoint.port))
                            packet_count += 1
                            
                            if packet_count % 50 == 0:  # Log every 50 packets (1 second)
                                logger.info(f"üß™ Sent {packet_count} test audio packets to {self.caller_endpoint.ip}:{self.caller_endpoint.port}")
                            
                        except Exception as e:
                            logger.error(f"‚ùå Error sending test audio: {e}")
                            break
                
                time.sleep(0.02)  # 20ms intervals
            
            logger.info(f"üß™ Test audio injection ended after {packet_count} packets")
        
        test_thread = threading.Thread(target=inject_test_audio_loop, daemon=True)
        test_thread.start()
        logger.info("üß™ Test audio injection thread started")
    
    def _bridge_loop(self) -> None:
        """Main bridge loop - forwards RTP packets and captures for AI."""
        logger.info("üåâ RTP Bridge loop started")
        logger.info(f"üîç Listening for RTP packets on ALL INTERFACES port {self.local_port}")
        logger.info(f"üéØ Will capture caller audio for AI (NO ECHO FORWARDING)")
        
        last_stats_time = time.time()
        packet_sources = set()  # Track unique packet sources
        
        while self.running:
            try:
                self.socket.settimeout(1.0)  # 1 second timeout
                data, addr = self.socket.recvfrom(4096)
                current_time = time.time()
                
                # Track packet sources for debugging
                source_key = f"{addr[0]}:{addr[1]}"
                if source_key not in packet_sources:
                    packet_sources.add(source_key)
                    logger.info(f"üÜï NEW RTP SOURCE detected: {source_key}")
                    
                    # Analyze the first packet from this source
                    self._analyze_rtp_packet(data, addr, "INCOMING")
                
                # Learn inbound source but DO NOT overwrite the SDP-configured outbound endpoint
                if not hasattr(self, 'inbound_audio_source'):
                    self.inbound_audio_source = AudioEndpoint(ip=addr[0], port=addr[1])
                    logger.info(f"üìû Inbound audio source: {addr[0]}:{addr[1]}")
                    logger.info(f"üì§ Outbound audio target (from SDP): {self.caller_endpoint.ip}:{self.caller_endpoint.port}")
                    logger.info(f"üîß CRITICAL: Sending audio to SDP endpoint, not source!")
                    # Initialize keepalive timing
                    self.last_caller_packet_time = current_time
                
                # Handle incoming RTP packets - these are the caller's voice from Zoho
                if addr[0] == self.caller_endpoint.ip and addr[1] == self.caller_endpoint.port:
                    # Packet from Zoho (containing caller's voice) ‚Üí capture for AI only, DON'T echo back
                    logger.debug(f"üì• Received caller audio from Zoho: {len(data)} bytes")
                    self._capture_for_ai(data, "caller")
                    self._record_audio(data, "caller")
                    # üö´ CRITICAL: Do NOT forward back to prevent echo!
                    # **NEW: Update packet timing for keepalive**
                    self.last_caller_packet_time = current_time
                    
                elif self.remote_endpoint and addr[0] == self.remote_endpoint.ip and addr[1] == self.remote_endpoint.port:
                    # This shouldn't happen in our setup since Zoho is both endpoints
                    # But handle gracefully
                    logger.debug(f"üì• Received audio from alternate endpoint: {len(data)} bytes")
                    self._capture_for_ai(data, "remote")
                    self._record_audio(data, "remote")
                    # **NEW: Update packet timing for keepalive**
                    self.last_remote_packet_time = current_time
                    
                else:
                    # Log unknown sources for debugging
                    if len(packet_sources) <= 5:  # Only log first few unknowns
                        logger.info(f"ü§î Unknown RTP source: {addr[0]}:{addr[1]} (may be NAT/proxy)")
                
                self.packets_forwarded += 1
                
                # Enhanced statistics every 10 seconds
                if time.time() - last_stats_time > 10:
                    logger.info(f"üåâ Bridge stats: {self.packets_forwarded} received, {self.packets_to_ai} to AI, {self.packets_from_ai} from AI")
                    logger.info(f"üìä Packet sources seen: {len(packet_sources)} unique endpoints")
                    if self.record_audio:
                        logger.info(f"üéµ WAV Recording stats: {self.caller_packets_recorded} caller packets, {self.remote_packets_recorded} remote packets saved to WAV")
                    if self.packets_forwarded > 0:
                        logger.info("‚úÖ SUCCESS! Audio packets flowing - NO ECHO forwarding")
                    else:
                        logger.warning("‚ö†Ô∏è  Still waiting for RTP packets...")
                    last_stats_time = time.time()
                
            except socket.timeout:
                # Normal timeout, continue
                continue
            except Exception as e:
                if self.running:
                    logger.error(f"‚ùå Bridge loop error: {e}")
                break
        
        logger.info("üåâ RTP Bridge loop ended")

    def _analyze_rtp_packet(self, data: bytes, addr: tuple, direction: str) -> None:
        """Analyze RTP packet for debugging."""
        try:
            if len(data) < 12:
                logger.warning(f"üì¶ {direction} packet too short: {len(data)} bytes from {addr[0]}:{addr[1]}")
                return
            
            # Parse RTP header
            version = (data[0] & 0xC0) >> 6
            padding = (data[0] & 0x20) >> 5
            extension = (data[0] & 0x10) >> 4
            csrc_count = data[0] & 0x0F
            marker = (data[1] & 0x80) >> 7
            payload_type = data[1] & 0x7F
            sequence = (data[2] << 8) | data[3]
            timestamp = (data[4] << 24) | (data[5] << 16) | (data[6] << 8) | data[7]
            ssrc = (data[8] << 24) | (data[9] << 16) | (data[10] << 8) | data[11]
            
            payload_size = len(data) - 12
            
            logger.info(f"üì¶ {direction} RTP ANALYSIS from {addr[0]}:{addr[1]}:")
            logger.info(f"   ‚Ä¢ Version: {version}, Payload Type: {payload_type} ({'PCMU' if payload_type == 0 else 'PCMA' if payload_type == 8 else 'OTHER'})")
            logger.info(f"   ‚Ä¢ Sequence: {sequence}, Timestamp: {timestamp}")
            logger.info(f"   ‚Ä¢ SSRC: 0x{ssrc:08x}, Payload: {payload_size} bytes")
            logger.info(f"   ‚Ä¢ Marker: {marker}, Padding: {padding}")
            
        except Exception as e:
            logger.error(f"‚ùå Error analyzing RTP packet: {e}")
    
    def _record_audio(self, data: bytes, source: str) -> None:
        """Record RTP packets as WAV audio files."""
        if not self.record_audio:
            return
            
        try:
            if source == "caller" and self.caller_packets_recorded < self.max_recording_packets:
                if self.caller_wav_recorder and self.caller_wav_recorder.write_rtp_packet(data):
                    self.caller_packets_recorded += 1
                    if self.caller_packets_recorded == 1:
                        logger.info(f"üéµ WAV RECORDING: First caller audio packet saved! ({len(data)} bytes RTP)")
                    elif self.caller_packets_recorded % 50 == 0:
                        logger.info(f"üéµ WAV RECORDING: {self.caller_packets_recorded} caller packets saved to WAV")
                        
            elif source == "remote" and self.remote_packets_recorded < self.max_recording_packets:
                if self.remote_wav_recorder and self.remote_wav_recorder.write_rtp_packet(data):
                    self.remote_packets_recorded += 1
                    if self.remote_packets_recorded == 1:
                        logger.info(f"üéµ WAV RECORDING: First remote audio packet saved! ({len(data)} bytes RTP)")
                    elif self.remote_packets_recorded % 50 == 0:
                        logger.info(f"üéµ WAV RECORDING: {self.remote_packets_recorded} remote packets saved to WAV")
                        
        except Exception as e:
            logger.error(f"‚ùå WAV recording error: {e}")
    
    def _forward_to_remote(self, data: bytes) -> None:
        """Forward RTP packet from caller to remote server."""
        if self.remote_endpoint:
            try:
                # Send to remote server (Zoho)
                self.socket.sendto(data, (self.remote_endpoint.ip, self.remote_endpoint.port))
                logger.debug(f"üì§ Forwarded {len(data)} bytes to remote")
            except Exception as e:
                logger.error(f"‚ùå Failed to forward to remote: {e}")
    
    def _forward_to_caller(self, data: bytes) -> None:
        """Forward RTP packet from remote server to caller."""
        if self.caller_endpoint:
            try:
                # Send back to caller (phone)
                self.socket.sendto(data, (self.caller_endpoint.ip, self.caller_endpoint.port))
                logger.debug(f"üì§ Forwarded {len(data)} bytes to caller")
            except Exception as e:
                logger.error(f"‚ùå Failed to forward to caller: {e}")
    
    def _capture_for_ai(self, rtp_data: bytes, source: str) -> None:
        """Capture and process RTP audio for AI."""
        try:
            if len(rtp_data) < 12:  # Minimum RTP header size
                return
                
            # Parse RTP header to get payload type and payload
            payload_type = rtp_data[1] & 0x7F  # Extract payload type
            payload = rtp_data[12:]  # Skip 12-byte RTP header
            
            if not payload:
                return
                
            # üéµ Convert RTP payload to PCM audio for AI
            pcm_audio = self._convert_rtp_to_pcm(payload, payload_type)
            if pcm_audio and self.audio_callback:
                # Check if this audio contains voice (simple amplitude check)
                import struct
                samples = struct.unpack(f'<{len(pcm_audio)//2}h', pcm_audio)
                max_amplitude = max(abs(s) for s in samples) if samples else 0
                
                # Log voice detection for debugging
                if self.packets_to_ai <= 10 or max_amplitude > 1000:  # First 10 packets or voice detected
                    voice_detected = "üó£Ô∏è  VOICE" if max_amplitude > 1000 else "üîá silence"
                    logger.info(f"üé§ {source} audio #{self.packets_to_ai}: {len(payload)} bytes RTP ‚Üí {len(pcm_audio)} bytes PCM (max: {max_amplitude}) {voice_detected}")
                
                self.audio_callback(pcm_audio, source)
                self.packets_to_ai += 1
                
                # Enhanced logging for voice activity
                if max_amplitude > 1000:  # Voice threshold
                    if not hasattr(self, '_last_voice_time'):
                        logger.info("üó£Ô∏è  VOICE ACTIVITY DETECTED - AI should be hearing you now!")
                    self._last_voice_time = time.time()
                    
                # Emit audio level if callback is set
                if self.audio_level_callback:
                    try:
                        self.audio_level_callback(pcm_audio, source == 'caller')
                    except Exception as e:
                        logger.error(f"Error in audio level callback: {e}")
                
                # Send to transcriber if enabled
                if self.transcriber and pcm_audio:
                    try:
                        logger.debug(f"üìù Sending {len(pcm_audio)} bytes of {'caller' if source == 'caller' else 'remote'} audio to transcriber")
                        self.transcriber.add_audio_chunk(pcm_audio, is_caller=(source == 'caller'))
                    except Exception as e:
                        logger.error(f"Error adding audio to transcriber: {e}")
                elif not self.transcriber:
                    logger.debug("üìù Transcriber not initialized - skipping audio capture")
                    
        except Exception as e:
            logger.error(f"Error capturing RTP for AI: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
    def _convert_rtp_to_pcm(self, rtp_payload: bytes, payload_type: int) -> Optional[bytes]:
        """Convert RTP audio payload to PCM format for AI processing."""
        try:
            from .audio_codec import ulaw_to_pcm, alaw_to_pcm, resample_simple
            
            # Map payload types to codecs (based on SDP we're advertising)
            # 0 = PCMU (Œº-law), 8 = PCMA (A-law), 18 = G729
            if payload_type == 0:  # PCMU (Œº-law)
                # Convert Œº-law to PCM 8kHz
                pcm_8khz = ulaw_to_pcm(rtp_payload)
                # Apply AGC for consistent levels
                pcm_8khz = self._apply_agc_to_pcm(pcm_8khz)
                # Resample to 16kHz for AI
                pcm_16khz = resample_simple(pcm_8khz, 8000, 16000, 2)
                return pcm_16khz
                
            elif payload_type == 8:  # PCMA (A-law)
                # Convert A-law to PCM 8kHz
                pcm_8khz = alaw_to_pcm(rtp_payload)
                # Apply AGC for consistent levels
                pcm_8khz = self._apply_agc_to_pcm(pcm_8khz)
                # Resample to 16kHz for AI
                pcm_16khz = resample_simple(pcm_8khz, 8000, 16000, 2)
                return pcm_16khz
                
            elif payload_type == 18:  # G729
                logger.warning(f"G729 codec not yet supported for payload type {payload_type}")
                # TODO: Implement G729 decoder
                return None
                
            else:
                logger.warning(f"Unsupported RTP payload type: {payload_type}")
                return None
                
        except Exception as e:
            logger.error(f"Error converting RTP payload (type {payload_type}): {e}")
            return None
    
    def _enhance_audio_quality(self, pcm_data: bytes, sample_count: int) -> bytes:
        """
        Apply audio quality enhancement filters for better call quality.
        Includes normalization, noise reduction, and dynamic range optimization.
        """
        try:
            import struct
            import numpy as np
            
            # Convert to numpy array for processing
            samples = np.frombuffer(pcm_data, dtype=np.int16)
            samples_float = samples.astype(np.float32)
            
            # 1. Peak normalization to optimize dynamic range
            max_val = np.max(np.abs(samples_float))
            if max_val > 0:
                # Normalize to 85% of max range to prevent clipping but maintain clarity
                target_peak = 32767 * 0.85
                normalization_factor = target_peak / max_val
                samples_float *= normalization_factor
                
            # 2. Simple noise gate - reduce very low amplitude noise
            noise_threshold = 200  # Very low threshold to preserve quiet speech
            samples_float = np.where(np.abs(samples_float) < noise_threshold, 
                                   samples_float * 0.1, samples_float)
            
            # 3. Soft compression to improve clarity without artifacts
            # Apply gentle compression to loud sounds while preserving quiet ones
            def soft_compress(x, threshold=20000, ratio=0.7):
                abs_x = np.abs(x)
                compressed = np.where(abs_x > threshold,
                                    threshold + (abs_x - threshold) * ratio,
                                    abs_x)
                return np.sign(x) * compressed
            
            samples_float = soft_compress(samples_float)
            
            # 4. Final clipping protection
            samples_float = np.clip(samples_float, -32767, 32767)
            
            # Convert back to int16
            enhanced_samples = samples_float.astype(np.int16)
            
            logger.debug(f"üéµ Audio enhancement: {max_val:.0f} ‚Üí {np.max(np.abs(enhanced_samples)):.0f} peak")
            
            return enhanced_samples.tobytes()
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Audio enhancement failed, using original: {e}")
            return pcm_data
            
    def _apply_agc_to_pcm(self, pcm_data: bytes) -> bytes:
        """ENHANCED AGC: Professional audio processing with clarity optimization."""
        try:
            import struct
            import math
            import numpy as np
            
            if len(pcm_data) < 2:
                return pcm_data
                
            # Unpack samples  
            sample_count = len(pcm_data) // 2
            samples = np.frombuffer(pcm_data, dtype=np.int16).astype(np.float32)
            
            if len(samples) == 0:
                return pcm_data
                
            # Calculate current audio levels
            max_amplitude = np.max(np.abs(samples))
            rms = np.sqrt(np.mean(samples**2))
            
            # ENHANCED: RMS-based AGC with reduced fuzziness 
            target_rms = 4000  # Optimal level for clarity without distortion
            
            if rms < 100:  # Very quiet
                gain = min(25.0, target_rms / max(rms, 50))  # Conservative gain
            elif rms < 500:  # Quiet  
                gain = min(10.0, target_rms / rms)  # Moderate boost
            elif rms < 1500:  # Low but audible
                gain = min(5.0, target_rms / rms)   # Gentle boost
            elif rms < 3000:  # Acceptable level  
                gain = min(2.0, target_rms / rms)   # Minimal boost
            else:  # Already good level
                gain = 1.0
                
            # Apply gain with soft limiting to prevent harsh clipping
            boosted_samples = []
            for sample in samples:
                # Apply gain
                boosted = int(sample * gain)
                
                # Soft limiting to prevent harsh clipping
                if boosted > 20000:  # Soft limit at ~60% of max
                    boosted = 20000 + int((boosted - 20000) * 0.3)
                elif boosted < -20000:
                    boosted = -20000 + int((boosted + 20000) * 0.3)
                    
                # Hard limit to prevent overflow
                boosted = max(-32767, min(32767, boosted))
                boosted_samples.append(boosted)
            
            # Log AGC activity for debugging (only for first few packets)
            if not hasattr(self, '_agc_log_count'):
                self._agc_log_count = 0
            
            final_max = max(abs(s) for s in boosted_samples)
            if gain > 1.0 and self._agc_log_count < 3:
                logger.debug(f"üîä AGC applied: {max_amplitude} ‚Üí {final_max} (gain: {gain:.1f}x)")
                self._agc_log_count += 1
            
            # Pack back to bytes
            return struct.pack(f'<{len(boosted_samples)}h', *boosted_samples)
            
        except Exception as e:
            logger.error(f"‚ùå AGC error: {e}")
            return pcm_data  # Return original if AGC fails
            
    def _stream_packets(self, rtp_packets: list[bytes], target_endpoint: AudioEndpoint) -> int:
        """Streams a list of RTP packets with precise timing, returns packets sent."""
        if not target_endpoint:
            logger.warning("‚ö†Ô∏è No target endpoint, cannot stream packets.")
            return 0

        if not rtp_packets:
            logger.warning("‚ö†Ô∏è No packets provided to stream.")
            return 0

        packet_interval = 0.010  # 10ms between packets (optimal)
        packets_sent = 0
        start_time = time.time()

        for i, packet in enumerate(rtp_packets):
            try:
                # Calculate when this packet should be sent
                target_time = start_time + (i * packet_interval)
                current_time = time.time()

                # If we're ahead of schedule, wait briefly
                if current_time < target_time:
                    delay = target_time - current_time
                    if delay > 0.0005:  # Sleep if delay > 0.5ms
                        time.sleep(delay)
                
                self.socket.sendto(packet, (target_endpoint.ip, target_endpoint.port))
                self.last_outgoing_rtp_time = time.time()  # Update timestamp for silence injection
                self.packets_from_ai += 1
                packets_sent += 1

                self._record_audio(packet, "remote")

                if i < 2:
                    self._analyze_rtp_packet(packet, (target_endpoint.ip, target_endpoint.port), f"AI_AUDIO_STREAM #{i+1}")
            
            except Exception as e:
                logger.error(f"‚ùå Error sending packet {i} during stream: {e}")
                break
        
        return packets_sent

    def send_ai_audio(self, audio_data: bytes, target: str = "caller") -> None:
        """Send AI-generated audio to the call by packetizing and streaming it."""
        # CRITICAL FIX: Use remote_endpoint as fallback if caller_endpoint not set
        target_endpoint = self.caller_endpoint or self.remote_endpoint
        
        if not target_endpoint:
            logger.warning("‚ö†Ô∏è  No caller or remote endpoint available for AI audio")
            return
            
        try:
            # Emit audio level for AI audio
            if self.audio_level_callback:
                try:
                    self.audio_level_callback(audio_data, False)  # False = AI audio
                except Exception as e:
                    logger.error(f"Error in audio level callback for AI: {e}")
            
            # Send to transcriber for AI audio
            if self.transcriber and audio_data:
                try:
                    logger.debug(f"üìù Sending {len(audio_data)} bytes of AI audio to transcriber at 24kHz")
                    # AI audio is 24kHz
                    self.transcriber.add_audio_chunk(audio_data, is_caller=False, sample_rate=24000)
                except Exception as e:
                    logger.error(f"Error adding AI audio to transcriber: {e}")
            elif not self.transcriber:
                logger.debug("üìù Transcriber not initialized for AI audio")
            
            # FIX: Pre-send silence to warm up the RTP stream and prevent initial choppiness
            if self._is_first_ai_chunk:
                logger.info("üî• WARMING UP RTP STREAM with 100ms of silence...")
                # 100ms of silence at 24kHz, 16-bit PCM
                warmup_audio_data = b'\x00' * (24000 * 2 // 10)
                
                # Create and stream silence packets
                warmup_packets = self._create_rtp_packets_for_ai_audio(warmup_audio_data)
                if warmup_packets:
                    packets_sent = self._stream_packets(warmup_packets, target_endpoint)
                    logger.info(f"üî• Sent {packets_sent} silence packets to prime the connection.")
                
                self._is_first_ai_chunk = False

            # Create a list of RTP packets from the AI's audio chunk
            rtp_packets = self._create_rtp_packets_for_ai_audio(audio_data)
            
            if not rtp_packets:
                logger.error("‚ùå Failed to create any RTP packets for AI audio")
                return
                
            logger.info(f"üé§ Streaming {len(rtp_packets)} AI audio packets to {target_endpoint.ip}:{target_endpoint.port}")
            packets_sent = self._stream_packets(rtp_packets, target_endpoint)
            logger.info(f"‚úÖ Sent {packets_sent}/{len(rtp_packets)} AI audio packets")
            
        except Exception as e:
            logger.error(f"‚ùå Error in send_ai_audio: {e}")
            import traceback
            logger.error(traceback.format_exc())
    
    def _create_rtp_packets_for_ai_audio(self, ai_audio_data: bytes) -> list[bytes]:
        """
        Create a list of RTP packets from AI-generated audio.
        ENHANCED: Validates audio format and ensures precise conversion.
        """
        packets = []
        try:
            from .audio_codec import pcm_to_alaw, resample_simple
            import struct
            
            logger.info(f"üéµ Processing AI audio: {len(ai_audio_data)} bytes from Gemini Live API")
            
            # ENHANCED: Validate and analyze input audio
            if len(ai_audio_data) % 2 != 0:
                logger.warning(f"‚ö†Ô∏è  AI audio size {len(ai_audio_data)} is not even - may not be 16-bit PCM")
                # Pad with zero byte if odd
                ai_audio_data += b'\x00'
            
            sample_count = len(ai_audio_data) // 2
            logger.info(f"üî¨ AI Audio Analysis: {sample_count} samples, assumed 16-bit PCM")
            
            # Calculate expected timing based on 24kHz assumption
            expected_duration_ms = (sample_count / 24000) * 1000
            logger.info(f"‚è±Ô∏è  Expected duration (24kHz): {expected_duration_ms:.1f}ms")
            
            # Step 1: Validate that this is really 24kHz, 16-bit PCM
            try:
                samples = struct.unpack(f'<{sample_count}h', ai_audio_data)
                max_amplitude = max(abs(s) for s in samples) if samples else 0
                avg_amplitude = sum(abs(s) for s in samples) / len(samples) if samples else 0
                
                logger.info(f"üìä Audio levels: max={max_amplitude}, avg={avg_amplitude:.1f}")
                
                if max_amplitude > 32767:
                    logger.error(f"‚ùå Invalid PCM data - amplitude exceeds 16-bit range!")
                    return packets
                    
            except Exception as e:
                logger.error(f"‚ùå Failed to validate PCM audio: {e}")
                return packets
            
            # Step 2: High-quality resample from 24kHz to 8kHz (telephony standard)
            # Simplified - skip pydub filters that may be causing distortion
            pcm_8khz_data = resample_simple(ai_audio_data, from_rate=24000, to_rate=8000)
            logger.info(f"üîÑ PRECISE resample 24kHz‚Üí8kHz: {len(ai_audio_data)} ‚Üí {len(pcm_8khz_data)} bytes")
            
            # Validate resampling
            expected_8khz_samples = sample_count // 3  # Exact 3:1 ratio (24kHz -> 8kHz)
            actual_8khz_samples = len(pcm_8khz_data) // 2
            logger.info(f"‚úÖ Resampled: {actual_8khz_samples} samples (expected ~{expected_8khz_samples})")
            
            # Step 3: Convert to A-law (telephony codec)
            codec_data = pcm_to_alaw(pcm_8khz_data)
            logger.info(f"üîÑ PCM‚ÜíA-law: {len(pcm_8khz_data)} ‚Üí {len(codec_data)} bytes")
            
            # Step 4: Package into RTP packets with A-law payload type
            # RTP packet size for 20ms of 8kHz A-law audio
            payload_size = 160  # 20ms * 8kHz = 160 samples = 160 bytes in A-law
            packet_index = 0
            
            # Check if codec conversion resulted in valid data
            if not codec_data:
                logger.error("‚ùå A-law conversion failed - no data")
                return packets
            
            for i in range(0, len(codec_data), payload_size):
                payload = codec_data[i:i+payload_size]
                
                # Pad with proper A-law silence if needed
                if len(payload) < payload_size:
                    # A-law silence value (0x55 = 0 in A-law encoding)
                    silence_padding = b'\x55' * (payload_size - len(payload))
                    payload += silence_padding
                    logger.debug(f"Padded packet #{packet_index} with {len(silence_padding)} A-law silence bytes")
                
                # Create RTP header with sample-accurate timing  
                version = 2
                payload_type = 8  # PCMA (A-law) - telephony standard
                ssrc = 0x87654321  # Unique SSRC for our AI audio
                
                # Sequence number increments by 1 for each packet
                sequence_number = self._ai_sequence_number
                self._ai_sequence_number = (self._ai_sequence_number + 1) & 0xFFFF
                
                # FIXED: Sample-accurate timestamp calculation
                timestamp = (self._ai_timestamp_base + self._ai_samples_sent) & 0xFFFFFFFF
                self._ai_samples_sent += len(payload)  # Each byte = 1 sample in A-law
                
                # Pack the RTP header (12 bytes) with optimal settings
                header = struct.pack('!BBHII', 
                                     (version << 6) | 0,  # V=2, P=0, X=0, CC=0
                                     payload_type,         # M=0, PT=8 (A-law)
                                     sequence_number,
                                     timestamp,
                                     ssrc)
                
                packets.append(header + payload)
                packet_index += 1
            
            # Final validation
            total_samples_sent = sum(len(p) - 12 for p in packets)  # Subtract RTP header size
            logger.info(f"‚úÖ Created {len(packets)} A-law RTP packets")
            logger.debug(f"üìä Audio Pipeline: 24kHz({sample_count}s)‚Üí8kHz‚ÜíA-law({total_samples_sent}bytes)‚ÜíRTP")
            
        except Exception as e:
            logger.error(f"‚ùå Error creating RTP packets for AI audio: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
        return packets
    
    def get_bridge_port(self) -> Optional[int]:
        """Get the local bridge port."""
        return self.local_port
    
    def stop_bridge(self) -> None:
        """Stop the RTP bridge."""
        self.running = False
        
        # **NEW: Stop keepalive thread**
        self.keepalive_running = False
        if self.keepalive_thread and self.keepalive_thread.is_alive():
            self.keepalive_thread.join(timeout=2.0)
        
        # Stop silence injection thread
        self.silence_injection_running = False
        if self.silence_injection_thread and self.silence_injection_thread.is_alive():
            self.silence_injection_thread.join(timeout=2.0)
        
        # Stop transcriber
        if self.transcriber:
            try:
                self.transcriber.stop()
                logger.info("üìù Transcriber stopped")
            except Exception as e:
                logger.error(f"Error stopping transcriber: {e}")
            self.transcriber = None
        
        # Clean up UPnP port forwarding
        self._cleanup_upnp()
        
        # Close WAV recording files
        if self.record_audio:
            if self.caller_wav_recorder:
                self.caller_wav_recorder.close()
                logger.info(f"üéµ Caller WAV recording closed: {self.caller_packets_recorded} packets")
            if self.remote_wav_recorder:
                self.remote_wav_recorder.close()
                logger.info(f"üéµ Remote WAV recording closed: {self.remote_packets_recorded} packets")
        
        if self.socket:
            self.socket.close()
        logger.info(f"üõë RTP Bridge stopped - Final stats: {self.packets_forwarded} forwarded, {self.packets_to_ai} to AI, {self.packets_from_ai} from AI")
    
    def _cleanup_upnp(self) -> None:
        """Clean up UPnP port forwarding when bridge stops."""
        if self.upnp_enabled and self.local_port:
            try:
                from ..utils.network import upnp_manager
                upnp_manager.remove_port(self.local_port, 'UDP')
                logger.info(f"üßπ Cleaned up UPnP forwarding for port {self.local_port}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  UPnP cleanup error: {e}") 

    def _keepalive_loop(self):
        """Send RTP keepalive packets to prevent NAT/firewall timeouts."""
        logger.info("üîÑ RTP keepalive thread started")
        
        while self.keepalive_running and self.running:
            try:
                current_time = time.time()
                
                # Send keepalive to caller if no recent traffic
                if (current_time - self.last_caller_packet_time > self.keepalive_interval and 
                    self.caller_endpoint and self.socket):
                    self._send_keepalive_packet(self.caller_endpoint, "caller")
                
                # Send keepalive to remote endpoint if no recent traffic  
                if (current_time - self.last_remote_packet_time > self.keepalive_interval and
                    self.remote_endpoint and self.socket):
                    self._send_keepalive_packet(self.remote_endpoint, "remote")
                
                # Sleep for 5 seconds before checking again
                time.sleep(5.0)
                
            except Exception as e:
                if self.keepalive_running:
                    logger.error(f"‚ùå Error in keepalive loop: {e}")
                time.sleep(1.0)
        
        logger.info("üîÑ RTP keepalive thread stopped")

    def _send_keepalive_packet(self, endpoint: AudioEndpoint, target: str):
        """Send a minimal RTP keepalive packet."""
        try:
            # Create minimal RTP packet with silence payload
            rtp_packet = self._create_keepalive_rtp_packet()
            
            self.socket.sendto(rtp_packet, (endpoint.ip, endpoint.port))
            logger.debug(f"üîÑ Sent RTP keepalive to {target} ({endpoint.ip}:{endpoint.port})")
            
            # Update last packet time to prevent immediate re-send
            if target == "caller":
                self.last_caller_packet_time = time.time()
            else:
                self.last_remote_packet_time = time.time()
                
        except Exception as e:
            logger.error(f"‚ùå Failed to send keepalive to {target}: {e}")

    def _create_keepalive_rtp_packet(self) -> bytes:
        """Create a minimal RTP packet for keepalive purposes."""
        # RTP header (12 bytes) + minimal payload (silence)
        version = 2
        padding = 0
        extension = 0
        csrc_count = 0
        marker = 0
        payload_type = 0  # PCMU
        sequence_number = self.keepalive_seq
        timestamp = int(time.time() * 8000) % (2**32)
        ssrc = 0x12345678
        
        # Pack RTP header
        byte0 = (version << 6) | (padding << 5) | (extension << 4) | csrc_count
        byte1 = (marker << 7) | payload_type
        
        header = struct.pack('!BBHII', byte0, byte1, sequence_number, timestamp, ssrc)
        
        # Add minimal silence payload (20ms of PCMU silence = 160 bytes of 0xFF)
        silence_payload = b'\xFF' * 160
        
        self.keepalive_seq = (self.keepalive_seq + 1) % 65536
        
        return header + silence_payload
    
    def _silence_injection_loop(self):
        """Continuously send silence packets to maintain RTP stream."""
        logger.info("üîá RTP silence injection thread started")
        log_counter = 0
        
        while self.silence_injection_running and self.running:
            try:
                current_time = time.time()
                
                # Log status every 50 iterations (1 second)
                log_counter += 1
                if log_counter % 50 == 0:
                    logger.info(f"üîá Silence loop check: caller_endpoint={self.caller_endpoint is not None}, "
                              f"socket={self.socket is not None}, "
                              f"time_since_last={current_time - self.last_outgoing_rtp_time:.3f}s")
                
                # Only inject silence if we haven't sent audio recently
                if (self.caller_endpoint and self.socket and 
                    current_time - self.last_outgoing_rtp_time > 0.015):  # 15ms threshold
                    
                    # Create and send silence packet
                    silence_packet = self._create_silence_rtp_packet()
                    self.socket.sendto(silence_packet, (self.caller_endpoint.ip, self.caller_endpoint.port))
                    self.last_outgoing_rtp_time = current_time
                    
                    # Log periodically
                    if not hasattr(self, '_silence_log_count'):
                        self._silence_log_count = 0
                    self._silence_log_count += 1
                    if self._silence_log_count % 100 == 0:  # Log every 2 seconds
                        logger.info(f"üîá Sent {self._silence_log_count} silence packets to maintain stream")
                
                # Send packets every 20ms
                time.sleep(0.020)
                
            except Exception as e:
                if self.silence_injection_running:
                    logger.error(f"‚ùå Error in silence injection loop: {e}")
                time.sleep(0.1)
        
        logger.info("üîá RTP silence injection thread stopped")
    
    def _create_silence_rtp_packet(self) -> bytes:
        """Create an RTP packet with silence payload."""
        # RTP header
        version = 2
        padding = 0
        extension = 0
        csrc_count = 0
        marker = 0
        payload_type = 8  # PCMA (A-law)
        
        # Use the same sequence and timestamp tracking as AI audio
        sequence_number = self._ai_sequence_number
        self._ai_sequence_number = (self._ai_sequence_number + 1) & 0xFFFF
        
        timestamp = (self._ai_timestamp_base + self._ai_samples_sent) & 0xFFFFFFFF
        self._ai_samples_sent += 160  # 20ms at 8kHz
        
        ssrc = 0x87654321  # Same SSRC as AI audio
        
        # Pack RTP header
        byte0 = (version << 6) | (padding << 5) | (extension << 4) | csrc_count
        byte1 = (marker << 7) | payload_type
        
        header = struct.pack('!BBHII', byte0, byte1, sequence_number, timestamp, ssrc)
        
        # A-law silence is 0xD5 (not 0x55)
        silence_payload = b'\xD5' * 160  # 20ms of A-law silence
        
        return header + silence_payload 